---
title: 'Assessing reliability of an online behavioural laterality battery: a pre-registered
  study.'
output:
  html_notebook: default
  pdf_document: default
  word_document: default
---

## Authors
Adam J. Parker, Zoe V. J., Woodhead, Paul A. Thompson, and Dorothy V. M. Bishop

Department of Experimental Psychology, University of Oxford, Anna Watts Building, Radcliffe Observatory Quarter, Woodstock Road, Oxford, OX2 6GG.

<!--- Leaving blank for now as not sure how corresponding authorship works in OSCCI lab --->
*Correspondence regarding this article should be addressed to XXXXXX, Department of Experimental Psychology, University of Oxford, Anna Watts Building, Woodstock Road, Oxford, OX2 6GG. Email: XXXXXX

## Abstract

**Needs filling in**

## Introduction

Hemispheric specialisation, or lateralisation, is a ubiquitous characteristic of the human brain, yet many questions remain unanswered as to its causes and consequences. Much of the ambiguity in the published literature may arise from unreliable measures of lateralisation and underpowered studies. Without well powered experiments that use reliable tasks, it becomes difficult to address many research questions regarding the relationship between laterality indices and their stability over time. With respect to the relationship between indices, unless a task is reliable, the absence of a correlation cannot be interpreted as evidence for independence of function (Bishop, 2017). The best way to determine a task’s reliability is to test it twice. Here, the variation between participants should be larger than the variation within subjects. Taking this into consideration, the current work introduces an online behavioural laterality battery for which we established the test-retest reliability using a sample of 390 participants. The behavioural tasks included were: a novel rhyme decision task, a dichotic listening task (Hugdahl et al., 2009), a chimeric faces task (Burt & Perret, 1997), and a novel finger tapping task. We subsequently use this battery to we examine two pre-registered questions: (1) do extreme left-handers show a higher rate of atypical laterality than right handers on each behavioural laterality task; (2) do the laterality indices produced on each measure correlate.

### Behavioural laterality tasks and their reliability.

Behavioural laterality tasks have long been used to establish hemispheric dominance for certain cognitive functions. Rather consistently, visual half-field and dichotic listening paradigms agree that the left hemisphere plays the dominant role in language processing  (Hugdhal, 2000; Ocklenburg & Güntürkün, 2018). Here we review how each paradigm has been implemented to study language lateralisation. 

Evidence from the visual half-field paradigm (see Bourne, 2006, for a review), strongly points towards advantageous processing for letter strings presented in the right, relative to the left, visual field. As information in the right visual field projects contralaterally and arrives directly at the language dominant left hemisphere, it is thought to reflect an absence in callosal transfer that is required for the processing of information initially arriving at the right hemisphere.

Despite wide reporting of a right visual field advantage at the population level when using visual half-field tasks, the paradigm is not without critique. In particular, the validity of visual half-field tasks has been questioned. Krach, Chen, and Hartje (2006) compared the laterality indices (LIs) produced during a visual half-field experiment with those produced using functional Transcranial Doppler Sonography (fTCD). The visual half-field experiment itself consisted of lexical decisions made towards abstract nouns presented in the left and right visual-fields. During the experiment, the blood flow to left and right hemispheres of 58 participants was measured. In addition, blood flow was measured during a word generation task—the gold standard task for assessing hemispheric dominance for language. Despite showing the expected right visual field advantage on the visual half-field task, the behavioural LIs produced on the visual half-field paradigm did not correlate with the fTCD LIs produced during word generation (r= .18) or the visual half-field task itself (r -.004). The 
lack of validity here likely reflects the poor reliability of the visual field task as Krach et al. report the split-half reliability for the correct response rates and reaction times during the behavioural visual half-field paradigm were r= .14 and r= .20 respectively. Thus, with such low split-half reliability it is unclear whether the task was able to accurately measure language lateralisation to start with.

In recent years it has become clear that the reliability and validity of visual half-field tasks to identify the language-dominant hemisphere is largely dependent on several methodological aspects. For example, Hunter and Brysbaert (2008) noted stronger and more stable visual-field differences when stimuli were presented bilaterally relative to those where only one stimulus was presented either in the LVF or in the RVF (Boles, 1987, 1990, 1994; see also Iacoboni & Zaidel, 1996). Brysbaert and Hunter argued that this is the result of stimuli competing during bilateral presentation, which is easier when the stimulus is presented in the language dominant hemisphere. Reliability and validity also depend on there being a sufficient number of observations and brief stimulus presentation. When accounting for these methodological aspects, the validity of visual half-field tasks seems promising. For example, Hunter and Brysbaert (2008) reported that LIs from visual half-field paradigms correlated positively with those from functional Magnetic Resonance Imaging (fMRI): word naming (r= .63), picture naming (r= .77). Here 192 trials were used during word naming and 160 trials during picture naming while stimuli were bilaterally presented and masked at offset. Furthermore, a promising visual half-field paradigm developed by Hausmann and colleagues (Hausmann et al., 2019; Willemin et al., 2016) which adhered to several of the methodological aspects outline by Brysbaert and Hunter has reported a right visual-field advantage at the population level with little variation occurring between languages. The authors, however, have not yet reported reliability measures for this task. 

While the visual half-field technique measures lateralisation for visual stimuli, dichotic listening tasks examine hemispheric dominance for the processing of auditory stimuli. Like the visual half-field technique, the dichotic listening task makes use of the crossing of fibres at the corpus callosum. In this task, different streams of auditory linguistic stimuli (i.e. words, syllables) are presented to each ear and participants are either asked simply to report as many words as they can or to attend to one ear selectively. In either case, a right ear advantage has been demonstrated; typically, participants report more verbal stimuli presented to the right ear (Hugdahl, 2011; Kimura, 1961). Again, this advantage has been attributed to stimuli being projected to the language dominant hemisphere without callosal transfer.

Over the years, various dichotic listening paradigms have been used (Bryden, 1988; Westerhausen, 2019). The test-retest reliability of these paradigms have been far from optimal (Voyer, 1998; Kelley & Littenberg, 2019). However, recent data from Westerhausen and Samuelsen (2020) indicated that when designed well, the dichotic listening paradigm can be reliable. First, based on a review of the published literature, Westerhausen and Samuelsen outlined eight design features that should be used in an optimal dichotic listening paradigm and explain their justification for each. The criteria are as follows: (1) stop consonant-vowel (CV) syllables as stimulus materials, (2) pair only CV stimuli from the same voicing category, (3) Alternating trials of voiced and unvoiced stimulus pairs, (4) free-recall instruction, (5) single-stimulus pair per trial, (6) paradigm length of 120 dichotic trials, (7) all stimulus pairs are presented in both orientations in identical frequency, and (8) includes binaural (homonymic) trials. Putting these criteria into practice, Westerhausen and Samuelsen administered a modified dichotic listening paradigm using both a verbal and manual response format to 50 right-handers. Interestingly, the full paradigm yielded a test-retest reliability of r= .93 for verbal responses and r= .91 for manual responses. Thus, the dichotic listening task provides a promising paradigm for those wanting to investigate language lateralisation without reliance on visual stimuli. 

So far, the studies reviewed have been interested in language lateralisation. That is not to say that behavioural tasks are limited to linguistic materials. For instance, the visual half-field paradigm has been used to measure lateralisation for the processing of facial similarity (e.g. Gilbert & Bakan, 1973), face emotionality (e.g. Levy, Heller, Banich, & Burton, 1983), and local information (Sergent, 1982). In a recent review of the reproducibility of visual-field asymmetries, Brederoo, Nieuwenstein, Cornelissen, and Lorist (2019) reported that they were able to replicate five out nine perceptual asymmetries using the visual half-field paradigm. 

Of importance to the current work is the use of the visual half-field paradigm to measure the lateralisation of face emotionality, in particular the chimeric faces task. In this task participants are presented with vertically split chimeric faces, where each half displays a different emotion. Depending on how the task is implemented, participants will either view a single chimeric face and report the emotion being expressed (e.g. Drebing, Federman, Edington, & Terzian, 1997; Kucharska-Pieture, & David, 2003) or view two faces, one above the other, and decide which of the two faces looks more emotive (e.g., Bourne, 2005; Levy, Heller, Banich, & Burton, 1983). Here the images will be identical, mirror images and typically include a neutral and emotive hemiface (i.e. Happiness-Neutral vs Neutral-Happiness). Regardless of implementation, participants’ responses point towards a bias for the processing of emotion in the left visual field. In the single face version, participants will more often report the emotion shown in the left hemiface. In the two-face version, participants show a bias in selecting the face with an emotion depicted in the left hemiface. 

In terms of its reliability, the chimeric faces tasks seem promising. In Levy et al.’s (1983) early study, they reported good split-half reliability for the two faces version of the chimeric faces task, where the left and right handers both showed a split-half reliability of .93. The validity of the chimeric faces task has been demonstrated using behavioural and fMRI data.  In Yovel, Tambini, and Brandman’s (2008) study, participants performed a behavioural experiment where they had to recognize centrally presented chimeric faces, which presented different identities in the right- and left-visual-field. Interestingly, the behavioural measure significantly correlated with the LI calculated based on activation in the fusiform face area (r= .49). However, it is of importance to note the sample size used here was small, but at face value the results seem promising. 

### Behavioural laterality tasks and (a)typical lateralisation

The studies reviewed so far have all focused on lateralisation at the population level. That is not to say that lateralisation does not vary between individuals. One factor that has been associated with the degree of lateralisation is handedness. Neuroimaging data strongly indicates that these differences in lateralisation are the result of a group of left-handers who are right language dominant rather than inidciateing that this relationship operates on a continuum (Mazoyer et al., 2014This increased departure from typical lateralisation in left-handers is not only present in neuroimaging studies, it is also reflected in behavioural tasks. Thus it will be important for our battery to replicate the findings regarding handedness and lateralisation summarised below.

With regards to visual half-field techniques for studying language lateralisation, there is evidence to suggest that the visual field advantage varies with handedness (Elias, Bulman-Fleming, &McManus, 1999; Nicholls, 1994, 1998; Weekes, Capetillo-Cuncliffe, Rayman, Iacoboni, & Zaidel, 1999). However, a relatively well powered study, involving 100 participants conducted by Willemin et al. (2016) reported no effect of handedness (when coded as left and right) on the visual field advantaged during lexical decision task. At first, this finding may seem odd. However, it may reflect underlying issues with the task rather than represent strict evidence for a null effect of handedness on visual half-field task. Here, Willemin et al. asked participants to respond via manual response. This contrasts several studies that have reported increased variability when responding aloud. Thus, a task that lacks some active speech production component may not yield such strong visual field advantages that enable provide enough variation to detect subtle differences in handedness (Hunter & Brysbaert, 2008). This, of course, is something that we kept in mind when developing the visual half-field paradigm used in the current study.

When dichotic listening paradigms to study language lateralisation, the evidence is clear that non-right-handers differ in terms of their laterality. While a clear right ear (i.e. left hemisphere) advantage is noted at the population level (see Hugdahl et al., 2009, and Westerhausen, 2019, for a review), there is evidence to suggest that this is reduced in left- relative to right-handers (Bethmann, Tempelmann, De Bleser, Scheich, & Brechmann, 2007; Bryden, 1970, 1988; Hugdahl, 2003); although handedness alone does not predict this difference (Van der Haegen, Westerhausen, Hugdahl, & Brysbaert, 2013). Across two studies Karlsson, Johnstone, and Carey (2019) provided a clear, yet comprehensive explanation of how performance on the dichotic listening task differed as a function of hand preference. Here, Karlsson et al. employed a consonant-vowel version of the dichotic listening task where participants reported which one of six syllables that they heard the clearest. For study 1, a clear right ear advantage was reported at the population level. Furthermore, right-handers were on average more lateralised than non-right-handers—87% of right-handers and 78% of non-right-handers showed a right ear advantage. For study 2, a similar pattern of results emerged. Again, right-handers were more lateralised with 85% of right-handers and 79% of non-right-handers showing an advantage. Together these results indicate that non-right-handers show a larger departure from the ‘typical’ lateralisation during dichotic listening tasks.

Recall that, for the chimeric faces, there is typically a left visual field advantage at the population level— indicating right hemisphere dominance. As with other laterality tasks, there appears to be a greater departure from this typical pattern of laterality for left-handers (e.g. Gilbert & Bakan, 1973; Heller & Levy, 1983; Karlsson et al., 2019; Levy et al., 1983; Rozkowski & Snelbecker, 1982). Again, this departure is well described by Karlsson et al. (2019). This departure was examined for two version of the chimeric faces task. The first involve participants viewing a single face with a different emotion shown in either hemiface. Participants then reported the emotion that they felt was most strongly displayed. The second was a two faces version where participants viewed two a face with an emotion on one side and the mirror version. Here participants had to decide which of the two faces showed a target emotion. For the first task, right-handers showed a bias for reporting information presented in the left visual field (i.e. right hemisphere); however, left-handers did not show a population bias. Specifically, 75% of right-handers and 60% of non-right-handers showed a leftwards bias. For the second chimeric faces task, a similar pattern emerged. 73% of right-handers and 57% of non-right-handers here showed a leftwards bias. Based on the above finding, a good laterality task must not only be reliable, but should be able to replicate a departure from typical lateralisation in those who are left-handed.

From the above reviewed studies, it appears that handedness is related to laterality across a range of tasks. This relationship points towards a a general laterality factor which governs lateralisation across tasks and behaviours. This has been argued in several hypotheses (Behrmann & Plaut, 2015; Cook, 1984; Hellige, 1983; Kosslyn, 1987). Common to all hypotheses is the assumption that there would be a correlation between the degree of laterality across complementary tasks. While studies do report significant correlations between measures of lateralisation, these are often small (Bradzakova-Trajkov, Haberling, Roberts, & Corballis, 2010). Furthermore, there are a large number of studies which report no correlation between laterality indices (Bryden, Hecaen, & Deagostini, 1983; Rosch, Bishop, & Badcock, 2012; Whitehouse & Bishop, 2009; van der Haegen & Brysbaert, 2018). This has led to the conclusion that there are multiple independent biases across tasks which lead to hemispheric lateralisation of different cognitive domains.

### The current study

Our principle goal for the current study was to maximise the test-retest reliability of an online laterality battery. Specifically, we examined whether it is possible to achieve a test-retest reliability of .65 or above using online behaviour research methods, and, if so, whether this reliability could be achieved more efficiently by using fewer trials in each test. The tasks included in the battery were a novel rhyme decision visual half-field tasks, a consonant-vowel dichotic listening tasks, a chimeric faces visual half-field task, and a novel finger tapping tasks. As we were primarily interested in establishing test-retest reliability, the behavioural tasks included in the battery were completed twice on two different occasions. In addition to establishing the test-retest reliability for the battery, we tested several predictions about the relationship between laterality on the four behavioural tasks. We describe these predictions below. 

Our first set of predictions related to participants’ performance at a population level on each task. Based on previous work, we predicted that:
(1)	the laterality indices for Rhyme Decision will show a right visual field advantage (indicating left hemisphere dominance for language processing); 
(2)	the laterality indices for the Dichotic Listening task will show a right ear advantage (indicating left hemisphere dominance for language); 
(3)	the laterality indices for Chimeric Faces will show a left visual field advantage (indicating right hemisphere dominance for face or emotion processing); and 
(4)	the Finger Tapping task will show a right-hand advantage.

Our second prediction related to the inter-relationships between laterality indices. With online testing, there is the opportunity to test inter-relationships between laterality indices with an adequately powered sample using measures of known reliability.  Prior studies have been inconclusive because it has been difficult gather large amounts of data to establish test-retest reliability. For instance, Van der Haegen and Brysbaert (2018), found that language laterality did not correlate with face laterality in visual half-field tasks. However, their study was restricted to left-handers, who may be atypical in this regard, and they noted that lack of association was hard to interpret because it may be due to unreliability of measurement. Originally, we predicted that for right-handers, a model (a) where the two language tasks are correlated with each other but not with the chimeric faces will provide better fit to the data than a model (b) in which laterality indices are correlated between the language and chimeric face tasks, or a base model (c) where each task is independently lateralised. For left-handers, we anticipated that that model (c) may be a better fit to the data, indicating that laterality is dissociated across the different tasks. However, we were not able to test this planned analysis with the current data set as one task had low reliability. Thus, we instead examined the relationship between laterality tasks using correlation analysis.

Our final prediction that we examined relates to handedness and atypical lateralisation. We predicted that strong left-handers (i.e. those with laterality quotient of -90 or less on the Edinburgh Handedness Inventory) will be more likely to show atypical laterality (i.e. laterality in the opposite direction to our population level predictions) than right-handers. This prediction follows from observations by Mazoyer et al (2014, p. 1) who studied a large group of left- and right-handers using fMRI to measure language laterality. They concluded "concordance of hemispheric dominance for hand and for language occurs barely above the chance level, except in a group of rare individuals (less than 1% in the general population) who exhibit strong right hemisphere dominance for both language and their preferred hand”.

## Method

This project was pre-registered on the Open Science Framework (OSF) prior to the commencement of data collection. The registration form along with the analysis scripts and anonymised data can be found on the OSF at https://osf.io/qsxcv/.

### Participants

As our ultimate goal is to use these measures in individual differences research, we aimed to optimise the task to achieve observed test-retest reliability of at least .65. To achieve sufficient precision of the estimate of reliability, we estimated we needed 300 participants. With this sample size, if the true correlation is .58, then the 95% confidence interval around the estimate will be .50-.65. Thus with this sample size, if we observe a correlation of .65, then the true correlation is unlikely to be lower than .58.

Out of the 300 participants, we originally specified that we'd collected data for least 80 left-handers. We had examined the power that a sample of 80 participants would provide to make the originally planned model comparisons outlined under hypothesis 3. By comparing model fit using a likelihood test, 80 participants would provide 100% power for model (a) and 97% power for model (b). Thus, we would have sufficient power to assess the fit of each model using Akaike weights, which are more conservative than likelihood tests. 

Despite setting out to recruit 300 participants, our final sample exceeded this target (we say more about this below). In total, 441 native English speakers were initially recruited through Prolific Academic. Participants had normal or corrected-to-normal vision and reported no history of neurological disease (e.g. head injury, brain tumour, stroke) or significant hearing loss/impairment. 

This study was approved by the Medical Sciences Inter-Divisional Research Ethics Committee (reference number: R66638/RE002) and conducted in accordance with the principles of the Declaration of Helsinki. Participants gave informed consent and received compensation for their participation.

<!--Dorothy, just a note that all Ps came from Prolific in the end-->

### Online behavioural laterality battery

The battery consisted of eight tasks and was administered via Gorilla (Anwyl-Irvine, Massonnié, Flitton, Kirkham, & Evershed, 2020), a cloud-based tool for collecting data in the behavioural sciences. Each task is described below.

#### Basic demographics questionnaire

The basic demographics questionnaire asked participants to report handedness, years in education, and whether they were bilingual. We also asked participnats a question about footedness: which foot do you normally use to step up on a ladder/step? Participants could answer "left", "right", or "don't know".

#### Test of ocular dominance

Adapted versions of the Miles test (Miles, 1929) and the Porta test (Porac & Coren, 1976) were used to determine each participant’s eye dominance in central gaze (i.e., when looking straight ahead). Each test classified participants as being either left or right eye dominant. 

#### Edinburgh handedness inventory

The Edinburgh Handedness Inventory (Oldfield, 1971) was administered to quantify handedness on a continuum. For 10 everyday activities, participants indicated their preferred hand use on a 5-step scale (right hand strongly preferred, right hand preferred, no preference, left hand preferred, left hand strongly preferred). The Edinburgh handedness inventory was scored in the standard way, which involves combining information about direction and exclusiveness of hand preference across ten tasks. For simple contrast between left- and right-handers, we treated indices greater than 0 as right handed, and indices less than 0 as left handed. For analysis of extreme left-handers, we focussed on left-handers with an index of -90 or less, which corresponds to near-exclusive use of the left hand. 

#### LexTALE

The Test for Advanced Learners of English (Lemhöfer & Broersma, 2012) was used to assess participants’ vocabulary knowledge. Participants saw 60 letter strings and had to indicate which word they knew. Of the 60 strings, 40 were actual English words and 20 were non-words. LexTALE scores were corrected the unequal proportion of words and non-word by averaging the percentages corrected for these two item types (e.g., ((number of words correct/40 x 100) + (number of nonwords correct/20 x 100))/2). Accordingly, the LexTALE scores ranged from 0 to 100. 

#### Rhyme decision task

The rhyme decision task is a novel visual half-field technique which requires participants decide whether a foveally present letter string rhymed with an image shown in either the left or right hemifield. 

##### Materials

Twenty-six monosyllabic words were presented in foveal vision. Each word was 3-4 letters in length (*mean*= 3.8; *SD*= 0.40) and had an average Zipf frequency [log10(frequency per million words) + 3] of 4.4 (*SD*= 0.72) when using the SUBTLEX-UK database (van Heuven, Mandera, Keuleers, & Brysbaert, 2014). Each foveal word was paired with an image that corresponded to one of 26 monosyllabic words which had a mean Zipf frequency of 4.5 (*SD*= 0.48). For example, the word “bite” was paired with the image “kite” and the word “more” was paired with the image “door”. Each word-image pair was then paired with another word-image pair for which there was no inter-pair rhyme (i.e. bite-kite was paired with more-door). This resulted in 13 word-image couplets. For each of the foveally presented words in a given word-image couplet, the corresponding images could appear in either the LVF or RVF. Thus, for each of the 13 couplets, four combinations were possible. For the pairing of bite-kite and more-door the following stimuli were created: kite – bite – door, door – bite – kite, door – more – kite, kite – more – door. In total, there were 52 unique stimuli. On a given trial, each image was displayed at 2.5 deg. eccentricity of the foveal word (see Figure 1).


![Figure 1. Schematic illustration of a trial on the rhyme decision task. In the example, the word “bite” is presented along with the two images “kite” and “door”. When making the correct judgement, participants would respond with by pressing ‘S’ to indicate that the rhyme was on the left.](Picture1.png)


##### Procedure

Each of the 52 unique stimuli were shown five times. The 260 stimuli were then displayed across four blocks (65 items per block). Each of the four blocks also contained five items for which there was no rhyme. For example, the word “moon” was displayed with the images for kite and door: kite – moon – door. These foil items were included in attempt to prevent participants from preferentially responding to items in either the LVF or RVF. These items were then pseudo-randomised such that image pairs could not appear one after the other. 

Each trial began with a fixation cross presented centrally for 800 ms. Participants were instructed to keep their eyes on the central fixation point. Then a foveally presented word would appear for 200 ms. Word stimuli were presented in black lowercase Tahoma font on a white background. Font was scaled to 250% equating to 28pt font. The foveally presented word was replaced with bilaterally presented images at approximately 2.5 of visual angle either side of fixation. The eccentricity of images was maintained using Gorilla’s scaling tool. The bilaterally presented images were then presented for 150 ms. Brief bilateral presentation has guaranteed adequate control for eye movements in previous VHF experimental with verbal naming (Beaumont, 1982). Studies that directly monitored eye movements reported failures of fixation on only 0.5% of trials (Geffen, Bradshaw & Nettleton, 1972, but see also Bourne, 2006). At stimulus offset, participants indicated whether the image in the LVF or RVF rhymed with the foveally presented word. Participants were instructed to press ‘S’ to indicate that the foveally presented word rhyme with the image in the LVF and ‘K’ if it rhymed with the image in the RVF. If participants did not detect a rhyme, they were instructed to press the space bar. The response triggered the next trial.

#### Dichotic listening task

The consonant-vowel dichotic stimuli were kindly provided by Dr Emma Karlsson, and were used with the permission of Professor Kenneth Hugdahl. The stimuli have been used in prior research and reported elsewhere (Hugdahl et al., 2009; Karlsson et al., 2019).

##### Materials

The consonant-vowel stimuli were formed by pairing six stop-consonants (/b/, /d/, /g/, /p/, /t/, /k/) with the vowel /a/. Each of the six consonant-vowel stimuli (/ba/, /da/, /ga/, /pa/, /ta/, /ka/) were paired and played in each sound channel (e.g. /ba/-/da/), resulting in 36 pairings including homonyms. 

##### Procedure

Participants completed four blocks of the dichotic listening task. In each block, participants heard each of the 36 stimuli once. Across the four blocks, they responded to 144 stimuli. Participants were instructed to wear headphones when completing the dichotic listening task. We included two headphone checks to ensure that participants were using stereo-headphones, which we describe further in the General Procedure. At the start of each trial, participants saw a fixation cross for 250 ms, after which a stimulus was played. After hearing each stimulus, participants were instructed to report the syllable they heard or, if it seemed like they heard two different sounds, the one they heard best or most clearly by clicking a button corresponding to one of the six syllables. The response triggered the start of the next trial.

#### Chimeric faces task

The chimeric faces stimuli were kindly provided by Dr Michael Burt, and have been reported elsewhere (Burt & Perrett, 1997; Innes et al., 2016; Karlsson et al., 2019). 

##### Materials

The faces consisted of symmetrical averaged images created from four male and four female faces. Four emotional expressions were used: anger, disgust, happiness, and sadness. The faces were split vertically down the middle of the face and paired so that one emotive hemifaces was attached to another and blended at the midline (see Figure 2 for an example). These were paired in all possible combinations creating 16 individual stimuli. Four stimuli showed identical emotions in each hemiface.


![Figure 2. An example stimulus from the chimeric faces task. In the example, “happiness” is shown on the left and “sadness” on the right. For a participant who is right lateralised, they might be expected to have stronger emotion processing for the left hemiface. As such, they will likely report seeing “happiness”.](chim_example.png)


##### Procedure

Participants completed four blocks of the chimeric faces task. In each block, participants viewed each stimulus twice. Thus, they viewed 32 stimuli per block and 128 in total. At the start of each trial, participants fixated a cross for 1000 ms. A chimeric face was then displayed for 400 ms. Participants then reported the emotion seen in the face by clicking a button corresponding to one of the four emotions. The response triggered the start of the next trial.

#### Finger tapping task

The Finger Tapping task is a novel behavioural task to classify handedness. Participants were required to either press the ‘W’, ‘R’, ‘V’, and ‘X’ keys with their left hand or the ‘Y’, ‘I’, ‘M’, ‘B’ keys with their right hands in sequence as many times as possible within a 30 second window. Participants completed four blocks of the finger tapping task in total. Each block contained required participants to complete the task for both their dominant and non-dominant hand. 

#### General Procedure

The current study implemented a test-retest, within-subjects design across two sessions. During session 1, participants completed the full battery of tasks. Self -report measures were completed first, followed by the behavioural laterality tasks. During session 2, participants completed only the behavioural laterality tasks. Hence, each participant provided data for the rhyme decision, dichotic listening, chimeric faces, and finger tapping tasks twice. Each session lasted approximately 45 minutes and 35 minutes respectively.

As the dichotic listening task demands the use of stereo-headphones, participants were screened at the start of each session. Screening consisted of two tasks. The first involved participants judging which of three pure tones is quietest, and is described by Woods, Siegel, Traer, and McDermott (2017) in full detail. Sound discrimination is designed to be easy to achieve when using headphones but difficult over loudspeakers due to phase-cancellation. Participants were removed from the study if they failed to correctly discriminate the quietest sound on at least five out of six trials, indicating that they were unlikely using headphones. The second involve participants hearing a sound presented in only one of the two channels. Participants were removed if they failed to correctly identify which channel the sound was played on five out of six trials, indicating that they were not using stereo-headphones.

When completing the behavioural tasks participants were instructed to sit approximately 50 cm from the screen. Gorilla’s scaling tool was utilised such that stimuli size and eccentricity was maintained across tasks and participants. Stimuli were from each task were repeated across four blocks. Within each block participants completed 70 trials of the rhyme detection task (R); 36 trials of the dichotic listening task (D); 32 trials of the chimeric face task (C); and 2 trials of the finger tapping task (F) for both their dominant and non-dominant hand. The order of tasks with each block were determined as follows RDCF, DCFR, CFRD, FRDC, and the order of tasks remained consistent across blocks for each participant. For each task, trial order was randomised, except for the finger tapping task where participants responded with their dominant hand followed by their non-dominant hand.

#### Data analysis

```{r read_dat, echo- FALSE, include= FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)

# read in data from csv
LIs <- read.csv('https://osf.io/x5jd2/download',stringsAsFactors = F)
```

```{r prepdat,echo=FALSE,include=FALSE}
# remove those without day 2
# reformat NA
LIs$day2.complete <- ifelse(is.na(LIs$day2.complete), 0, LIs$day2.complete)
# remove
LIs_c <- LIs[LIs$day2.complete == 1,]
LIs <- LIs[LIs$day2.complete == 1,]
# lextale out df
LIs_no <- LIs[LIs$lexOut != "keep",]
# now remove them from LI
LIs <- LIs[LIs$lexOut == "keep",]
# table of counts for footed and sigh
short_dat <- dplyr::select(LIs, "subject", "handedness", "footedness", "miles", "porta")
long_dat <- gather(short_dat, task, response, footedness:porta, factor_key=TRUE)
# make table
tab <- as.data.frame(table(long_dat$handedness, long_dat$task, long_dat$response))
tab <- tab %>% 
  rename(
    Handedness = Var1,
    Task = Var2,
    Response= Var3,
    Count= Freq
    )
split <- ggplot(data=tab, aes(x=Response, y=Count, fill=Handedness)) +
  geom_bar(stat="identity", position=position_dodge()) + facet_grid(.~Task) +
    geom_text(aes(label=Count), vjust=-0.3, position = position_dodge(0.9), size=3.5)+
  theme_classic() + theme(legend.position = "top") + ylab("Count") + xlab("") + ylim(0,220)
ggsave(
  "handed_sight.png",
  plot = split,
  width = 6, height = 4,
  dpi = 300
)
#Add a category of handedness that distinguishes extreme left from other left-handers
#In preregistration, extreme left defined as EHI laterality -90 or less.
LIs$handed3 <- LIs$handedness
w<-which(LIs$index_EHI<(-89))
LIs$handed3[w]<-'Extreme.left'
```

Out of the 441 partiipants recuited via Prolific, `r nrow(LIs_c)` (`r round(nrow(LIs_c)/441*100, 1)`%) complete both sessions. We then removed `r nrow(LIs_no)` participants (`r round(nrow(LIs_no)/nrow(LIs_c)*100, 1)`%) from our final sample as their lexTALE score was below 80, indicating that a participant’s level of vocabulary knowledge was below the cut off for lower advanced proficiency. This left a final sample of `r nrow(LIs)` participants. 

For each task we adaopted the following data cleaning procedures. Applying each of these procedures meant that the number of participants left in the final analyses could vary by task. First, for all tasks, we removed trials in which reaction times were shorter than 200 ms. Outlier reaction times were identified using Hoaglin and Iglewicz’s (1987) procedure, whereby outliers are defined as reaction times that are 1.65 times the difference between the first and third quantiles (1.65 * (Q3-Q1)) below or above the first and third quantile values (e.g: lower limit = Q1 – 1.65 x (Q3-Q1); upper limit = Q3 + 1.65 x (Q3-Q1)). Our differences criterion was set to 1.65 instead of the typical 2.2 because we expected to obtain asymmetric distributions for reaction time, since reaction time is always non-negative, and so most outliers would be in one tail of the distribution. The Hoaglin and Iglewicz procedure was applied to each participants’ data separately. After applying each data trimming procedure, participants left with less than 80% of trials were removed. 

Next, for the chimeric faces task, we removed partcipants data if they scored lower than 75% on trials in which an identical emotion was shown in each hemisface. These data trimming procedures left data for `r nrow(LIs)-nrow(LIs[LIs$exclude== 1 | LIs$exclude== 12,])` participants on the chimeric faces. For the dichotic listening task, we removed those who scored less than 75% correct on trials where the same sound was played to each ear. These data trimming procedures left data for `r nrow(LIs)-nrow(LIs[LIs$exclude== 2 | LIs$exclude== 12,])` participants on the dichotic listening task.

With regards to the rhyme task, we removed participants who scored less than 50% accuracy in either visual field. Furthermore, we removed particpants who scored less than 75% accuracy on the catch trials (trials in which there was no rhyme). These trimming procedures left data for `r nrow(LIs[LIs$exRDT== 0,])` participants on the rhyme decision task. Seeing as we were removing a relatively high portion of participants, want wanted to check whether this task was yielding reliably results. With `r nrow(LIs[LIs$exRDT== 0,])` participants, the test-retest reliability was *r*= `r round(cor(LIs[LIs$exRDT== 0,]$Day1.RDT_RT_LI, LIs[LIs$exRDT== 0,]$Day2.RDT_RT_LI, use = "complete.obs"),3)`, which is smaller than the *r*= 0.65 that we pre-registered as our criteria for a reliable task. Thus, rather than collect further participants so that we would have our pre-registered 300 participants for the rhyme decision task, we chose to end data collection here and analyse the `r nrow(LIs)` participants that we had collected under the assumption that the rhyme decision is not reliable. The final group of `r nrow(LIs)` participants (`r nrow(LIs[LIs$gender== "Female",])` female) had a mean age of `r round(mean(LIs$age, na.rm= TRUE), 1)` years (*SD*= `r round(sd(LIs$age, na.rm= TRUE), 2)` and included `r nrow(LIs[LIs$handedness== "Left",])` left handers (`r nrow(LIs[LIs$handedness== "Left" & LIs$gender== "Female",])` female). `r nrow(LIs[LIs$handedness== "Right" & LIs$bilingual== "Yes",])` right-handers were bilingual and `r nrow(LIs[LIs$handedness== "Left" & LIs$bilingual== "Yes",])` left-handers were bilingual. The division of footedness and ocular dominance in left- and right-handers are shown in Figure 3. Below we describe the analysis procedures used to examine our research questions and hypotheses. 

![Figure 3. Count of left- and right-handers who report left, right, or don’t know on self-reported footedness, the Miles test, and the Porta test.](handed_sight.png)

##### Calculations of laterality indices

For the rhyme task, we pre-registered that we would calculate LIs based on reaction time data, as accuracy during piloting was at ceiling. We specified that we would calculate LIs in two ways: (1) LIs would be calculated in the traditional fashion (100 x (Right – Left)/(Right + Left)); (2) LIs would be calculated in a way that corresponded to a *t*-value. This was achieved by conducting a *t*-test for each participant where accuracy response times are the dependent variable and visual field is the independent variable. This would estimate the sensitivity to stimuli presented in either visual field and equate to a laterality index. One benefit of this approach is that we could identify participants who show a statistically significant reaction time advantage for one side, i.e. where the *t*-value on a 2-sided test has *p*< .05. Based on considerations from pilot data, we planned to transform RT data from the RDT task by log-transformation before computing *t*-values. 

For the dichotic listening and chimeric faces, we specified that LI calculated would be based on trials in which participants correctly identified a stimulus. The count of correct responses that corresponded to each side would be used to generate an accuracy LI in two ways: (1) LIs would be calculated in the traditional fashion (100 x (Right – Left)/(Right + Left)); (2) LIs would be computed as a *z*-statistic for each participant, using z = (pR-.5)/sqrt(pR x pL/n), where pR is the proportion of correct responses in the RVF, pL is proportion of L responses in the LVF, and n is total LVF and RVF responses. LIs for the finger tapping task would be calculated in the same manner, but using the number of sequences generated by the left and right hand as opposed to the proportion of correct responses in each visual field.

##### Reliability assessment

For the reliability assessment, we plotted the distributions of LIs and checked them for normality using a Shapiro-Wilk test. As the LIs were non-normal, we used a series of Spearman’s correlations to examine the correlation of coefficients for session 1 versus session 2. 

For tasks where the test-retest reliability was above .75 with the existing test length, we reanalysed the data using just the first N trials, reducing N until reliability becomes unsatisfactory (below *r*= .75)^1^. This will allow us to identify the most efficient way to administer these tasks in future, while retaining good reliability. However, the full data (including all trials) was used for all subsequent analyses.

##### Population level analysis

To address hypothesis 1 and examine the laterality of each task at the population level, we conducted a series of one-sample *t*-tests for each task using session 1 data. 

##### Atypicality

To address hypothesis 2, that extreme left-handers will be more likely to show atypical laterality than right-handers, we first identified participants as being atypical. Here participants were defined as left-handed if they scored less than -90 on the Edinburgh Handedness Inventory and right-handed if they scored more than 90 of the Edinburgh Handedness Inventory. Atypicality was first defined in participants where their *t*- or *z*-score was significantly laterality in the opposite direction from that expected. If there were less than 20 cases defined as atypical using this method, we adjusted the cut-off on that task until we acquired 20 atypical participants. Once typicality was defined, we first analysed atypicality on the Rhyme Decision and Chimeric Faces task. Participants were categorised into four groups: typical on both; atypical on Rhyme Decision only; atypical on Chimeric Faces only, and atypical on both. A chi-square test was then used to test for association with the number of people in each of the four groups and the handedness classification from the Edinburgh Handedness Inventory. This was then be repeated for the Dichotic Listening and the Chimeric Faces tasks. A Bonferroni correction was applied to the outcome of each of the two chi-squared tests.

##### Relationship between language and non-language LIs

We had originally intended to examine the relationship between LIs on the Rhyme Decision, Dichotic Listening, and Chimeric faces by modelling covariances. This would have allowed us to compare (1) a model where the two language tasks are correlated with each other but not with the chimeric faces, (2) a model where all LIs are correlated, and (3) a base model where the LIs are unrelated. This would have been done separately for right- and left-handers. However, due to the Rhyme Decision task having poor reliability, we decided that this analysis would not be appropriate. Instead, we examine the correlation coefficient for LIs on the Dichotic Listening and Chimeric Faces tasks. For completeness, we include the proposed analysis as a supplementary materials but do not draw conclusions based on this. 

## Results

```{r descriptives, echo=FALSE,include=FALSE}
# here we present the raw count and RT scores for each task
# read CF data
for_figs <- read.csv("./data/for_figs.csv", na.strings = "NA")
# get CF
CF.short.dat <- for_figs[for_figs$exclude== 0 | for_figs$exclude== 2,]
  CF.short.dat <-CF.short.dat[CF.short.dat$task== "CF",]
# read Dichotic data
DL.short.dat <- for_figs[for_figs$exclude== 0 | for_figs$exclude== 1,]
  DL.short.dat <- DL.short.dat[DL.short.dat$task== "DL",]
# read rhyme data
RD.short.dat <- for_figs[for_figs$exRDT== 0,]
  RD.short.dat <- RD.short.dat[RD.short.dat$task== "RD",]
# read finger data
finger.short.dat <- read.csv("./data/finger.csv", na.strings = "NA")

# plots
CF <- ggplot(CF.short.dat, aes(x = side, y = accurate)) +
        ggpirate::geom_pirate(aes(colour = side)) +
        theme_classic() + ylab("Count of correct responses") + xlab("") + facet_wrap(.~Session)+ 
        ggtitle("C") + theme(plot.title = element_text(hjust = 0.5))
DL <- ggplot(DL.short.dat, aes(x = side, y = accurate)) +
        ggpirate::geom_pirate(aes(colour = side)) +
        theme_classic() + ylab("Count of correct responses") + xlab("") + facet_wrap(.~Session)+ 
        ggtitle("B") + theme(plot.title = element_text(hjust = 0.5))
RD <- ggplot(RD.short.dat, aes(x = side, y = RT)) +
        ggpirate::geom_pirate(aes(colour = side)) +
        theme_classic() + ylab("Reaction time (ms)") + xlab("") + facet_wrap(.~Session) + 
        ggtitle("A") + theme(plot.title = element_text(hjust = 0.5))
FT <- ggplot(finger.short.dat, aes(x = side, y = sequences)) +
        ggpirate::geom_pirate(aes(colour = side)) +
        theme_classic() + ylab("Count of correct sequences") + xlab("") + facet_wrap(.~Session)+ 
        ggtitle("D") + theme(plot.title = element_text(hjust = 0.5))
all.plot <- suppressMessages(suppressWarnings(ggpubr::ggarrange(RD, DL, CF, FT)))
all.plot
# save
ggsave(
  "all.vf.png",
  plot = all.plot,
  width = 6, height = 6,
  dpi = 300
)
```

##### Calculations of laterality indices

Participants' average reaction times on the rhyme decision task are shown in Figure 4 broken down by visual field and session. While we do not analyse accuracy, accuracy on the rhyme task was high  (*M*= `r round(mean(RD.short.dat$p.corr, na.rm= TRUE),1)`%, *SD*= `r round(sd(RD.short.dat$p.corr, na.rm= TRUE),2)`%). The count of correct answers on the dichotic listening and chimeric faces tasks are also shown in Figure 4, along with the number of sequences gerated by the left and right hand. LIs were computed in several ways. For all tasks, we computed LIs in the typical way: (100 x (Right – Left)/(Right + Left)). It is important to note, however, that we present LIs such that they are reported to be consistent with lateralisation at the brain level (i.e. by multiplying LIs by -1). A negative LI indicates left lateralisation at the brain level while a positive LI indicates right lateralisation at the brain level. For the rhyme decision task, we then computed an LI using a *t*-test for inidiviaul participants fit to log-tranformed reaction time data. For the reamining tasks (which made use of count data) we computed a *z*-statistic for each participant using count data. 

![Figure 4. Mean scorees across the two sessions of the behavioural laterality tasks. (A) Reaction times in each visual field on the rhyme decision tasks. (B) Count of correctly identified sounds played to the left or right ear. (C) Count of correctly identified emotions in each hemiface. (D) Count of sequences generated by the left and right hand.](all.vf.png)

For each measure, LIs and their test-retest correlation coefficients are reported in Table 1. In addition, Table 1 inlcudes the *p*-values for a one-sampled test and Shapiro-Wlk test for each measure  As the distirbution of each LI was non-normal, spearman's rank correlations were used to estimate the test-retest reliability. Confidence intervals were estimated using bootstapping with 10,000 iterations. From Table 1, it is clear that we are able to obtain good test-retest reliability when calculating LIs in a typical manner. For all but the rhyme decision task, we see good test-retest reliability that exceeds our pre-registered thresold of *r*= .65. Furthermore, LIs for each task across the two sessions are lateralised at the participant level (all *p*s< .001). Specifically, the rhyme decision, dichotic listening, and finger tapping tasks were all lateralised to the left hemisphere (showing a left visual field advantage). The chimeric faces task was lateralised to the right hemipshere (showing a left visual field advantage). A highly similar pattern of results emerges for the *t*- and *z*-score measures, where each is lateralised at the population level (all *p*s< .001). The test-retest correlations are shown visually in Figure 5.

```{r make.combotable,echo=FALSE,include=TRUE}
#Make a table to summarise results for all 4 tasks
#This will gradually get populated as we go through each task
#Cells for each task are filled in course of plots.function chunk
combotable <- data.frame(matrix(NA,nrow=7,ncol=17))
colnames(combotable)<-c('.','RD 1','RD 2','DL 1','DL 2','CF 1','CF 2','FT 1','FT 2', 
                            'RD t 1','RD t 2','DL z 1','DL z 2','CF z 1','CF z 2','FT z 1','FT z 2')
combotable[,1]<-c('N','mean','SD','p-lateralised','p-normal','test-retest r','CI r')
```

```{r plots.function, echo=FALSE,include=TRUE}
# Adam's code here turned into generic function
# While we have the relevant columns specified here, I have added steps to populate combotable as we go.
# Also saving the scatterplots as png
densplots <- function(dat, time1,time2,name1,name2,scattername,combotable,combocolumn, y1, y2, x1, x2, ax, ay){

# plots
dens1<-ggplot(dat, aes(x=time1))+geom_density(linetype="dashed")+theme_classic()+ggtitle(name1)
  dens1 <- dens1+ geom_vline(xintercept = 0)
# normality
shap1<-shapiro.test(time1)
ttest1 <- t.test(time1) #Check if significantly lateralised
Nt1 <- length(time1)-length(which(is.na(time1)))
combotable[1,combocolumn]<-Nt1
combotable[2,combocolumn]<-round(mean(time1,na.rm=T),2)
combotable[3,combocolumn]<-round(sd(time1,na.rm=T),2)
combotable[4,combocolumn]<-round(ttest1$p.value,3)
combotable[5,combocolumn]<-round(shap1$p.value,3)

# day 2
# plot denisty
dens2<-ggplot(dat, aes(x=time2))+geom_density(linetype="dashed")+theme_classic()+ggtitle(name2)
  dens2 <- dens2+ geom_vline(xintercept = 0)
# normality
shap2<-shapiro.test(time2)
ttest2 <- t.test(time2)
Nt2 <- length(time2)-length(which(is.na(time2)))
myN<-min(Nt1,Nt2)
combotable[2,(combocolumn+1)]<-round(mean(time2,na.rm=T),2)
combotable[3,(combocolumn+1)]<-round(sd(time2,na.rm=T),2)
combotable[4,(combocolumn+1)]<-round(ttest2$p.value,3)
combotable[5,(combocolumn+1)]<-round(shap2$p.value,3)

# conduct Spearman's wth bootstrapped CI
myspear<-RVAideMemoire::spearman.ci(time1, time2, nrep = 10000, conf.level = 0.95)
  combotable[6,combocolumn]<-round(myspear$estimate,2)
  myci <- paste0(round(myspear$conf.int[1],2),' - ',round(myspear$conf.int[2],2))
  combotable[7,combocolumn]<-myci
# scatterplot time1 x time2
# position for label set to 50%x and 90%y
xpos <- max(time1,na.rm=T)*.5
ypos <- max(time2,na.rm=T)*.9

mycor<-cor.test(time1, time2, method = "spearman", alternative = "greater")$estimate

#Make a label to show the correlation with 95%CI and N on the plot
mycorlabel<-paste0('r = ',round(mycor,2),'\n(95% CI: ',round(myspear$conf.int[1],2),'-',round(myspear$conf.int[2],2),')\nN = ',myN)
#Find position in top L corner for legend
legposx <- .2 #not working - needs tweaking!
legposy <- .85
myscatter <- ggplot(dat, aes(x= time1, y= time2)) +
  geom_hline(yintercept=0, color = "black") +
  geom_vline(xintercept=0, color = "black") +
  geom_point(aes(color= handed3)) + 
  geom_rug(aes(color= handed3)) +
  theme_classic() +
  ylab(name2) + 
  xlab(name1) +
  annotate("text", x = ax, y = ay, label = mycorlabel) +
  theme(legend.position = c(legposx,legposy), legend.title = element_blank()) + ylim(y1, y2) + xlim(x1, x2)
# Set relative size of marginal plots (main plot 10x bigger than marginals)
bigplot<-ggExtra::ggMarginal(myscatter, groupColour = TRUE, groupFill = TRUE)
scattername<-paste0(scattername,".png")
ggsave(scattername,plot=bigplot,dpi = 300, width = 6, height = 6,)

return(combotable)
}
```
<!--- We start by completing combotable for the 4 main measures. NB need to check polarity of tasks - also oddity re RDT distributions needs checking, and we said we'd do log transform , not sure we did--->
```{r do.plots,LI,echo=FALSE,include=TRUE}
# RHYME DECISION
# remove bad cases
RD.dat <- LIs[LIs$exRDT == 0,]
# now plot
dat <- RD.dat
time1<-RD.dat$Day1.RDT_RT_LI
time2<-RD.dat$Day2.RDT_RT_LI
name1<-"Rhyme decision LI (day 1)"
name2<-"Rhyme decision LI (day 2)"
scattername<-"RhymeDecisionScatter"
combocolumn<-2 #column to write day 1 summary for this task in combotable
y1= -12
y2= 12
x1= -12
x2= 12
ax= 8
ay= -8
combotable<-densplots(RD.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# DICHOTIC LISTENING
# remove bad cases
DL.dat <- LIs[LIs$exclude == 0 | LIs$exclude == 1,]
# now plot
dat <- DL.dat
time1<-DL.dat$Day1_DL_acc_LI
time2<-DL.dat$Day2_DL_acc_LI
name1<-"Dichotic listening LI acc (day 1)"
name2<-"Dichotic listening LI acc (day 2)"
scattername<-"DichoticScatter"
combocolumn<-4 #column to write day 1 summary for this task in combotable
y1= -100
y2= 100
x1= -100
x2= 100
ax= 75
ay= -75
combotable<-densplots(DL.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# CHIMERIC FACES
# remove bad cases
CF.dat <- LIs[LIs$exclude == 0 | LIs$exclude == 2,]
# now plot
dat <- CF.dat
time1<-CF.dat$Day1_CF_acc_LI
time2<-CF.dat$Day2_CF_acc_LI
name1<-"Chimeric faces LI acc (day 1)"
name2<-"Chimeric faces LI acc (day 2)"
scattername<-"ChimericScatter"
combocolumn<-6 #column to write day 1 summary for this task in combotabley1= -100
y1= -100
y2= 100
x1= -100
x2= 100
ax= 75
ay= -75
combotable<-densplots(CF.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# FINGER TAPPING
dat <- LIs
time1<-LIs$Day1_finger_LI
time2<-LIs$Day2_finger_LI
name1<-"Finger tapping LI (day 1)"
name2<-"Finger tapping LI (day 2)"
scattername<-"FingerScatter"
combocolumn<-8 #column to write day 1 summary for this task in combotabley2= 100
y1= -35
y2= 35
x1= -35
x2= 35
ax= 26.25
ay= -26.25
combotable<-densplots(dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)
```

```{r do.plot.t,echo=FALSE,include=TRUE}
# RHYME T-TEST
# now plot
dat <- RD.dat
time1<-RD.dat$logt1
time2<-RD.dat$logt2
name1<-"Rhyme decision t-score (day 1)"
name2<-"Rhyme decision t-score (day 2)"
scattername<-"rhyme.t"
combocolumn<-10 #column to write day 1 summary for this task in combotable
y1= -8
y2= 8
x1= -8
x2= 8
ax= 6
ay= -6
combotable<-densplots(RD.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# DICHOTIC Z-TEST
# now plot
dat <- DL.dat
time1<-DL.dat$Day1_Dich_acc_Z
time2<-DL.dat$Day2_Dich_acc_Z
name1<-"Dichotic listening z-score (day 1)"
name2<-"Dichotic listening z-score (day 2)"
scattername<-"dichotic.z"
combocolumn<-12 #column to write day 1 summary for this task in combotable
y1= -20
y2= 20
x1= -20
x2= 20
ax= 15
ay= -15
combotable<-densplots(DL.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# CHIMERIC FACES Z-TEST
# now plot
dat <- CF.dat
time1<-CF.dat$Day1_CF_acc_Z
time2<-CF.dat$Day2_CF_acc_Z
name1<-"Chimeric faces z-score (day 1)"
name2<-"Chimeric faces z-score (day 2)"
scattername<-"chimeric.z"
combocolumn<-14 #column to write day 1 summary for this task in combotable
y1= -20
y2= 20
x1= -20
x2= 20
ax= 15
ay= -15
combotable<-densplots(CF.dat, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)

# FINGER TAPPING Z-TEST
# now plot
dat <- LIs
time1<-LIs$Day1_Finger_acc_Z
time2<-LIs$Day2_Finger_acc_Z
name1<-"Finger tapping z-score (day 1)"
name2<-"Finger tapping z-score (day 2)"
scattername<-"finger.z"
combocolumn<-16 #column to write day 1 summary for this task in combotable
y1= -8
y2= 8
x1= -8
x2= 8
ax= 6
ay= -6
combotable<-densplots(LIs, time1,time2,name1,name2,scattername, combotable,combocolumn, y1, y2, x1, x2, ax, ay)
```

Table 1. LIs and test-retest correlations for each taks.
```{r Table1,echo=FALSE}
#Needs more formatting. For word output may need to use flextable. See https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
kable(combotable) %>%
  kable_styling(c("bordered")) %>%
  add_header_above(c(" " = 1, "Typical LI" = 8, "t/z-score" = 8))
```
Note. LIs are transformed such that a negtaive value equates to a left lateralisation at the brain level. A positive value equates to right lateralisation at the brain level. RD= rhyme decision, DL= dichotic listening, CF: chimeric faces, and FT: finger tapping.

![Figure 5. Scatter plots for day 1 and day 2 data on each laterality task. The left column shows LIs calculated in the typical way. The right column shows LIs calculated using *t*- and *z*-scores. Here, distributions are shown for left and right handers, and an additional group of extreme left-handers who had a score below -90 on the Edinburgh Handedness Inventory.](combined_LI_cor.png)

Moving forward, we chose to use LIs calculated in a typical manner to address each remaining research question. To dtermine the smallest number of trials needed to achieve a test-retest reliabilty of *r*= .75, we recaclauted LIs by dropping one trial at a time for each participant...

##### Atypicality

We defined 'atypical laterality' as laterality that is in the opposite direction to the majority, and which has an absolute z-score or t-score value greater than 1.96. These z and t-scores indicate whether there is significant bias to the left or right within an individual. Based on our pre-registered analysis, we divided left-handers into two groups (1) those with a score of -90 or below on the Edinburgh Handedness Inventory (c.f. Mazoyer et al., 2014), (2) the remaining left handers. While our analyses inlcude only right handers and extreme left handers, we include the remaining left-handers in Table 2 for completeness. 

```{r makecontingencies,echo=FALSE}
#We start by using z-scores to make a 3-way categorisation into:
#1 sig bias in typical direction; 2: NS bias 3: in atypical direction with sig bias.
LIs$rhyme1.cut <- cut(LIs$Day1.RDT_p.corr_LI, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("TypLat", "NonLat", "AtypLat"), 
                       right = FALSE)
LIs$dichotic1.cut <- cut(LIs$Day1_Dich_acc_Z, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("TypLat", "NonLat", "AtypLat"), 
                       right = FALSE)
LIs$chimeric1.cut <- cut(LIs$Day1_CF_acc_Z, 
                       breaks =  c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("AtypLat", "NonLat", "TypLat"), 
                       right = FALSE)
mytabr <- table(LIs$rhyme1.cut)
mytabd <- table(LIs$dichotic1.cut)
mytabc <- table(LIs$chimeric1.cut)
mytabc<-mytabc[c(3,2,1)]
mytab2 <-rbind(mytabr,mytabd,mytabc)
row.names(mytab2)<-c('Rhyme decision','Dichotic','Chimeric Faces')
mytab2<-data.frame(mytab2)
# combine tables for printing
mytab3 <- cbind(tabr, tabd, tabc)
# now do chi-squared tests
# rhyme
tabr <- table(LIs$handed3,LIs$rhyme1.cut)
rhy.chi <- chisq.test(tabr)
# dichotic
tabd <- table(LIs$handed3,LIs$dichotic1.cut)
dic.chi <- chisq.test(tabd)
# chimeric
tabc <- table(LIs$handed3,LIs$chimeric1.cut)
chim.chi <- chisq.test(tabc)
# BUT these don't actually run the planed tests. We run these by removing lefties here
#Planned test omitted group 'Left' and column Nonlat.
chi.r<-chisq.test(tabr[c(1,3),c(1,3)])
chi.d<-chisq.test(tabd[c(1,3),c(1,3)])
chi.c<-chisq.test(tabc[c(1,3),c(1,3)])
```

Table 2. Counts of laterality patterns for right-, left-, and extreme geft-handers acorss the Rhyme decision, Dichotic listening, and Chimeric faces tasks.
```{r Table 2}
# plot group table
mytab3%>%
  kable() %>%  
  kable_styling(c("bordered")) %>%
  add_header_above(c(" " = 1, "Rhyme decision" = 3, "Dichotic listening" = 3, "Chimeric faces"= 3))
```
Note. TypLat: lateralised in the expected direction, Nonlat: no lateralisation, and AtypLat: show lateralisation in the opposite direction.

It is evident that the Rhyme Judgement task has few individuals who are significantly lateralised in either direction. We will therefore not consider it further, as our analyses are only justified if the task is an indicator of cerebral lateralisation. Both Dichotic Listening and Chimeric Faces, on the other hand, are strongly lateralised.  The planned analyses, comparing typically lateralised with atypically lateralised individuals, and extreme left vs right-handed individuals, show significant association between extreme left-handedness and atypical laterality on chi square test. For dichotic listening, chi squared = `r round(chi.d$statistic,2)`, d.f. = 1, *p* = `r round(p.adjust(chi.d$p.value, method= "bonferroni", n=2),3)`; for chimeric faces, chi squared = `r round(chi.c$statistic,2)`, d.f. = 1, *p* = `r round(p.adjust(chi.c$p.value, method= "bonferroni", n=2),3)`.  

With all participants included, on the dichotic listening task, `r round(100*tabd[1,3]/sum(tabd[,3]),1)`% of those with atypical laterality were extreme left-handers, `r round(100*tabd[3,3]/sum(tabd[,3]),1)`% were right-handers, and the remainder less extreme left-handers. For those with typical lateralisation, the corresponding figures were `r round(100*tabd[1,1]/sum(tabd[,1]),1)`% extreme left-handers, `r round(100*tabd[3,1]/sum(tabd[,1]),1)`% right-handers, and the remainder less extreme left-handers. For chimeric faces, the association was even more extreme.  `r round(100*tabc[1,1]/sum(tabc[,1]),1)`% of those with Atypical laterality were extreme left-handers, `r round(100*tabc[3,1]/sum(tabc[,1]),1)`% were right-handers, and the remainder less extreme left-handers. For those with typical lateralisation, `r round(100*tabc[1,3]/sum(tabc[,3]),1)`% were extreme left-handers, `r round(100*tabc[3,3]/sum(tabc[,3]),1)`% were right-handers, and the remainder less extreme left-handers.  

```{r contingency2tasks,echo=FALSE,include=TRUE}
tab2task <- table(LIs$dichotic1.cut,LIs$chimeric1.cut)
chi2task<-chisq.test(tab2task)
w1<-which(LIs$chimeric1.cut=='AtypLat')
w2<-which(LIs$dichotic1.cut=='AtypLat')
w3<-intersect(w1,w2)
#LIs$handed3[w3]
```

The planned analysis looking at cases who were atypical on both dichotic listening and chimeric faces was hampered by the fact that the two tasks were not associated (see below), and consequently there were only four cases in this category. Nevertheless, it was noteworthy that two of these were extreme left-handers and the other two were less extreme left-handers.

##### Relationship between language and non-language LIs

```{r LI-link,echo=FALSE,include=TRUE}
# make sure we have good cases
interR <- LIs[LIs$exclude == 0,]
# now run analysis
DL.CF<-RVAideMemoire::spearman.ci(interR$Day1_CF_acc_LI, interR$Day1_DL_acc_LI, nrep = 10000, conf.level = 0.95)
DL.CF.est<-cor.test(interR$Day1_CF_acc_LI, interR$Day1_DL_acc_LI, method = "spearman")
# run Bayes factor
BF1 <- BayesFactor::correlationBF(y = interR$Day1_CF_acc_LI, x= interR$Day1_DL_acc_LI, iterations = 10000)
# day 2
# now run analysis
DL.CF.2<-RVAideMemoire::spearman.ci(interR$Day2_CF_acc_LI, interR$Day2_DL_acc_LI, nrep = 10000, conf.level = 0.95)
DL.CF.est.2<-cor.test(interR$Day2_CF_acc_LI, interR$Day2_DL_acc_LI, method = "spearman")
# run Bayes factor
BF2 <- BayesFactor::correlationBF(y = interR$Day2_CF_acc_LI, x= interR$Day2_DL_acc_LI, iterations = 10000)
```

Using data from session 1, we examined the correlation between LIs on the dichotic listening and chimeric faces task to examine whether the perceptual biases on these tasks are governed by a single laterality factor. A spearman's rank order correlation indicated a extrenely small, non-singificant relationship, *rs*= `r round(DL.CF.est$estimate, 2)`, *95% CI* [`r round(DL.CF$conf.int[1], 2)`, `r round(DL.CF$conf.int[2], 2)`] *p*= `r round(DL.CF.est$p.value[1], 3)`.Based on this analysis, there is no evidence of a relationship between laterality indicies on the dichotic listening and chimeric faces tasks. To infer the extent to which our data reflect a null relationship, as opposed to a Type II error, we computed a Bayes factor (Rouder, Morey, Speckman, & Province, 2012). We computed the Bayes factor in R using the BayesFactor package (Version 0.9.12–4.2; Morey & Rouder, 2018) with 10,000 Monte Carlo iterations. We assumed the default Cauchy prior for the effect size. The Bayes factor for the alterative model, as opposed to the null model, was .150. According to Jeffreys' (1961) inference criteria, this provides moderate evidence for the null hypothesis. To validate these findings, we repeated these analysis with session 2 data. Again the correlation was small and not significantly different from zero *rs*= `r round(DL.CF.est.2$estimate, 2)`, *95% CI* [`r round(DL.CF.2$conf.int[1], 2)`, `r round(DL.CF.2$conf.int[2], 2)`] *p*= `r round(DL.CF.est.2$p.value[1], 3)`. Again the Bayes Factor favoured the null hypothesis, *BF*= .138. 

##### Exploratory analyses

```{r fingerEHI,echo=FALSE,include=TRUE }
spearCI <- RVAideMemoire::spearman.ci(LIs$Day1_finger_LI, -LIs$index_EHI, nrep = 10000, conf.level = 0.95)
# spearman's test
speartest <- cor.test(LIs$Day1_finger_LI, -LIs$index_EHI, method = "spearman", alternative = "greater")
```

The finger tapping task produced reliable results, but the extent to which it correlated with existing measures of handedness is not clear. Thus, we used a spearman's rank correlation to obtain an estimate of the relationship between LIs produced on the finger tapping task and the Edinburgh Handedness Inventory using session 1 data. The relationship between the tasks was moderate,*rs*= `r round(speartest$estimate, 2)`, *95% CI* [`r round(spearCI$conf.int[1], 2)`, `r round(spearCI$conf.int[2], 2)`] *p*= `r round(speartest$p.value[1], 3)`. Thus it indicates that the task likely represents a component of hand preference in conjunction with some aspect of motor planning or sequencing. 

## Notes

1. While we pre-registered that we would reduce the number of trails until *r*= .65 for tasks where the initial test-retest relaibility was *r*= .75, we chose to reduce the trials down until *r*= .75. We decided to do this to maintain a higher level of relaibaility when using shorter version of the battery in inidividual differences research.

## Supplemental Material

We had originally intended to examine the relationship between LIs on the Rhyme Decision, Dichotic Listening, and Chimeric faces by modelling covariances. This would have allowed us to compare (1) a model where the two language tasks are correlated with each other but not with the chimeric faces, (2) a model where all LIs are correlated, and (3) a base model where the LIs are unrelated. This would have been done separately for right- and left-handers. However, due to the Rhyme Decision task having poor reliability, we decided that this analysis would not be appropriate to base our conlcusions on. Instead, we report them as a supplmental material. The models were fit using a subset of SEM that dos not include any latent variables or directional paths. It only looks to constrain particular covariance patterns and report 'best' model according AIC weights. Model fit was evaluated using AIC model selection using Akaike weights (Wagenmakers & Farrell, 2004). Akaike weights are transformations of the AIC values, which can be directly interpreted as conditional probabilities for each model. The best fitting model to the data for right- and left-handers will be selected as the final model.

```{r Roger_mod_left,echo=FALSE}
library(lavaan)
library(tidyverse)
library(MASS)
library(qpcR)
# created handedness data
# now create subset of data frame for analysis
interRR <- dplyr::select(interR, 'Day1.RDT_RT_LI', 'Day1_CF_acc_LI', 'Day1_DL_acc_LI', "handedness")
# rename
interRR <- interRR %>% 
  rename(
    "rhyme1" = Day1.RDT_RT_LI,
    "chimeric1" = Day1_CF_acc_LI,
    "dichotic1" = Day1_DL_acc_LI)
# subset into right and left handers
left_dat <- subset(interRR, handedness== "Left")
right_dat <- subset(interRR, handedness== "Right")
# set up model 1
model1<-"
dichotic1~~0*rhyme1
dichotic1~~0*chimeric1 
rhyme1~~0*chimeric1 
"
# set up model 2
model2<-"
dichotic1~~rhyme1 
dichotic1~~0*chimeric1
rhyme1~~0*chimeric1 
"
# set up model 3
model3<-"
dichotic1~~rhyme1 
dichotic1~~chimeric1 
rhyme1~~chimeric1
"
# now fit model
fit1A <- cfa(model1, data=left_dat)
fit2A <- cfa(model2, data=left_dat)
fit3A <- cfa(model3, data=left_dat)
# get the aic
aic_vector1 <- c(fitMeasures(fit1A, "aic"),fitMeasures(fit2A, "aic"),fitMeasures(fit3A, "aic"))
#summary(fit1A, fit.measures=TRUE)
#summary(fit2A, fit.measures=TRUE)
#summary(fit3A, fit.measures=TRUE)
# get weights
AICweights1<-akaike.weights(aic_vector1)$weights
# populat df
IC_objectweights1<-data.frame(Model=factor(rep(c('Model 1','Model 2','Model 3'))), IC = factor(rep('AIC',each=3)),values=AICweights1)
# now print weights
left.weights <- ggplot(IC_objectweights1,aes(Model,values))+
  geom_bar(stat='identity',position="dodge")+
  ylab('Akaike weights') + xlab("") + theme_classic() + ylim(0, .7) + ggtitle("A") + 
  theme(plot.title = element_text(hjust = 0.5))

# NOW DO RIGHT HANDERS
#We now repeat this for right handers. 
fit1B <- cfa(model1, data=right_dat)
fit2B <- cfa(model2, data=right_dat)
fit3B <- cfa(model3, data=right_dat)

aic_vector2 <- c(fitMeasures(fit1B, "aic"),fitMeasures(fit2B, "aic"),fitMeasures(fit3B, "aic"))

#summary(fit1B, fit.measures=TRUE)
#summary(fit2B, fit.measures=TRUE)
#summary(fit3B, fit.measures=TRUE)

AICweights2<-akaike.weights(aic_vector2)$weights

IC_objectweights2<-data.frame(Model=factor(rep(c('Model 1','Model 2','Model 3'))), IC = factor(rep('AIC',each=3)),values=AICweights2)

right.weights <- ggplot(IC_objectweights2,aes(Model,values)) +
  geom_bar(stat='identity',position="dodge")+
  ylab('Akaike weights') + xlab("") + theme_classic() + ylim(0,.7) + ggtitle("B") + 
  theme(plot.title = element_text(hjust = 0.5))

model.comp <- ggpubr::ggarrange(left.weights, right.weights, ncol = 2)
# save
ggsave(
  "model.comp.png",
  plot = model.comp,
  width = 6, height = 3,
  dpi = 300
)
```

![Figure S1. Plot of Akaike weights for each model for (A) left-handers and (B) right-handers.](model.comp.png) 

As shown in Figure S1, the akaike weights favoured a different model for left- and right-handers. For left-handers model 2, where all LIs were correlated, was preferred. For right-handers model 1, were languge tasks were correlated with eachother but not the chimeric faces was preffered. The pattern of results for left handers was surprising given that in the main article we reported no correlation between the dichotic listening and chimeric faces tasks. Furthermore, for left-handers, the fact that the prefered model is one where language tasks are related seems to contrast previous work reporting that language tasks fractionate in left-handers (Woodhead et al., 2019). This is likely to reflect that the poor reliability of the rhyme decision task. For right-handers we see that a model where language tasks are related. This is as predicted but it is of course likely that this estimate also represents noise from the rhyme decision task. 
























# Pre-reg info

To do: 
- reduce numbers of items in the task. 

## Exploratory analysis

As noted above, we will use the z- or t-statistics to index laterality, but we will have a large dataset that might be used subsequently to explore different approaches to measuring a laterality index, and to consider how choice of measure affects test-retest reliability.  

While the role of the LexTALE in the current research is largely for the purpose of data exclusion, we plan to explore correlations between LexTALE score and the laterality index on the Rhyme Decision task. This will enable us to examine whether vocabulary knowledge is related to rhyme judgement when information is displayed in each hemifield. We will similarly explore the influence of sight dominance, handedness/footedness, and the Finger Tapping Task on the laterality index for rhyme decision.  

Finally, we will investigate whether the method for measuring handedness has an impact on the associations between handedness and laterality on the Rhyme Decision and Chimeric Faces tests. In our main planned analyses, handedness will be coded using a binary categorisation of the Edinburgh Handedness Inventory scores, where > 0 indicates right handedness and < 0 indicates left handedness. There are many alternative ways of coding handedness: e.g. using three categories (right handed, ambidextrous and left handed); as a continuous measure; using self-report handedness; or using performance on the Finger Tapping test as an objective, continuous measure. We will explore which of these coding systems gives the strongest associations with laterality indices on the Rhyme Decision and Chimeric Faces. To do this we will select half the data at random to explore associations, and then aim to replicate on the second half.  

## Results

<!---I'm not sure how to weave this in as it stands, so leaving here for now--->

*Still to be done: consider reliabilities with fewer trials. How short a test is feasible without loss of reliability?*

## Question 4
Our final question was whether the laterality indices from the language and faces laterality tasks correlate? Specifically we had predicted that in right-handers the two language tasks would correlate together, but the chimeric faces would form a separate factor, but in left-handers, the language tasks might fractionate.

This analysis was handicapped by the fact that one of the language indices, the rhyme judgement task, lacked both reliability and validity. Therefore we present the planned analysis in supplementary material, just for completeness. Here we consider the intercorrelations between the reliable tasks, including finger tapping instead of rhyme judgement. This is motivated by the prior observations that on both dichotic listening and chimeric faces, there was some association between handedness and lateralised task performance.

We had planned to use a structural equation modelling framework to compare the covariances of the laterality statistics between the two language tasks and chimeric faces to test between three models, separately for left- and right-handers. However, in neither handedness group were there any meaningful correlations between laterality indices.


```{r prep_dat,echo=FALSE}
# now create subset of data frame for analysis
mycols <- c('Day1.RDT_RT_LI', 'Day2.RDT_RT_LI',
            'Day1_CF_acc_LI', 'Day2_CF_acc_LI',
            'Day1_DL_acc_LI', 'Day2_DL_acc_LI',
            'Day1_finger_LI', 'Day2_finger_LI',
            'handedness')
colnums<- which(colnames(LIs) %in% mycols)
M <- LIs[,colnums]
M <- M %>% 
  rename(
    "rhyme1" = Day1.RDT_RT_LI,
    "rhyme2" = Day2.RDT_RT_LI,
    "chimeric1" = Day1_CF_acc_LI,
    "chimeric2" = Day2_CF_acc_LI,
    "dichotic1" = Day1_DL_acc_LI,
    "dichotic2" = Day2_DL_acc_LI,
    "finger1" = Day1_finger_LI,
    "finger2" = Day2_finger_LI)
# subset into right and left handers
left_dat <- subset(M, handedness== "Left")
right_dat <- subset(M, handedness== "Right")
```

```{r showcorrs,echo=FALSE}
#Will focus just on Day1
#Had considered showing as correlation heatmap - but values so small it wouldn't be worth doing!
#http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
# day 1
corrL<-round(cor(left_dat[,c(2,4,6,8)],use='complete.obs'),2)
corrR<-round(cor(right_dat[,c(2,4,6,8)],use='complete.obs'),2)
corr1 <- cbind(corrR, corrL)
# day 2
corrL2<-round(cor(left_dat[,c(3,5,7,9)],use='complete.obs'),2)
corrR2<-round(cor(right_dat[,c(3,5,7,9)],use='complete.obs'),2)
corr2 <- cbind(corrR2, corrL2)
```

### Table 3: Intratask correlations using session 1 data.
```{r dotab5,echo=FALSE}
corr1%>%
  kable() %>%
  kable_styling(c("bordered")) %>%
  add_header_above(c(" " = 1, "Session 1" = 4, "Session 2" = 4))
```

The correlations between tasks are all very low. To check if this pattern is robust, this analysis was repeated for time 2 data.

### Table 4: Intratask correlations using session 2 data.
```{r dotab7,echo=FALSE}
corr2%>%
  kable() %>%
  kable_styling(c("bordered")) %>%
  add_header_above(c(" " = 1, "Session 1" = 4, "Session 2" = 4))
```