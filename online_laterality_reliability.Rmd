
  
---
title: 'Assessing the reliability of an online behavioural laterality battery: A pre-registered study.'
output:
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

<!--- updated 20/7/20 to change 'select' to 'dplyr::select' to avoid conflicts-->

<!--- updated 3/8/20 to add ZW feedback--->

Adam J. Parker*, Zoe V. J. Woodhead, Paul A. Thompson, Dorothy V. M. Bishop

Department of Experimental Psychology, University of Oxford, Anna Watts Building, Radcliffe Observatory Quarter, Woodstock Road, Oxford, OX2 6GG.

*Correspondence regarding this article should be addressed to Adam J. Parker, Department of Experimental Psychology, University of Oxford, Anna Watts Building, Woodstock Road, Oxford, OX2 6GG. Email: adam.parker@psy.ox.ac.uk.

\newpage
## Abstract

Studies of cerebral lateralisation often involve participants completing a series of perceptual tasks under laboratory conditions. This has constrained the number of participants recruited in such studies. Online testing can allow for much larger sample sizes but limits the amount of experimental control that is feasible. Here we considered whether online testing could give valid and reliable results on four tasks: a rhyme decision visual half-field task, a dichotic listening task, a chimeric faces task, and a finger tapping task. We recruited 392 participants, oversampling left-handers, who completed the battery twice. Three of the tasks showed evidence of both validity and reliability, insofar as they showed hemispheric advantages in the expected direction and test-retest reliability of at least *r*= .75. The reliability of the rhyme decision task was less satisfactory (*r*= .63). We also found that extreme left-handers were more likely to depart from typical lateralisation. Lateralisation across the two language tasks (dichotic listening and rhyme judgement) was weakly correlated, but unrelated to lateralisation on the chimeric faces task. We conclude that three of the tasks, dichotic listening, chimeric faces and finger tapping, show considerable promise for online evaluation of cerebral lateralisation. The results do not support the notion of a common underlying cause of lateralisation for language and face processing.

*Keywords*: cerebral lateralisation, hemispheric asymmetry, language, online behaviour research methods, reliability

\newpage
Hemispheric specialisation, or lateralisation, is a ubiquitous characteristic of the human brain, yet many questions remain unanswered as to its causes and consequences. Much of the ambiguity in the published literature may arise from unreliable measures of lateralisation and underpowered studies. Without well-powered experiments that use reliable tasks, it becomes difficult to address many research questions regarding the relationship between laterality indices and their stability over time. Concerning the relationship between indices, unless a task is reliable, the absence of a correlation cannot be interpreted as evidence for independence of function (Parsons, Kruijt & Fox, 2019). Reliability can either be assessed within a test session (e.g. split-half reliability, from correlations between odd and even items) or from repeated assessments on different occasions (test-retest reliability). The latter is generally preferred as it includes all test items and will incorporate fluctuations in performance due to changes in state or test conditions from one occasion to another. Assessment of test-retest reliability, however, requires large samples of people who undergo repeated testing, and this is seldom feasible for in-person testing. Online testing allows for the recruitment of much larger samples but raises questions about test validity when opportunities for experimental control are reduced. Here we introduce an online behavioural laterality battery for which we established the test-retest reliability using a sample of 392 participants. The behavioural tasks included were: a novel rhyme decision task, a dichotic listening task (Hugdahl et al., 2009), a chimeric faces task (Burt & Perret, 1997), and a novel finger tapping task. The validity of the tasks was assessed in terms of whether lateralisation was observed in the predicted direction, based on prior literature with in-person testing on analogous tasks. We also examined two pre-registered questions: (1) do extreme left-handers show a higher rate of atypical laterality than right-handers on each behavioural laterality task? (2) do the laterality indices from different tasks correlate?

### Behavioural laterality tasks and their reliability

Behavioural laterality tasks have long been used to establish hemispheric dominance for certain cognitive functions. Results from visual half-field and dichotic listening paradigms support the view that the left hemisphere plays the dominant role in language processing (Hugdahl, 2000; Ocklenburg & Güntürkün, 2018). By contrast, visual half-field paradigms indicate that the right hemisphere is involved in the processing of faces, global feature processing, and visuo-spatial attention (Brederoo, Nieuwenstein, Cornelissen, & Lorist, 2019). Below, we review how each paradigm has been implemented to study language lateralisation and the detection of emotion in faces, and what is known about reliability and validity.

#### Lateralised visual word processing

Lateralised visual word processing has been studied using the visual half-field paradigm. In this paradigm, visual stimuli are briefly presented to the left or right of a central fixation stimulus. The visual pathways from the left and right sides of space to the visual cortex are crossed for non-foveal viewing, and so the right visual-field (RVF) projects directly to the left hemisphere and the left visual-field (LVF) to the right hemisphere. The corpus callosum allows for transfer between hemispheres, but the rationale of the method is that there will be a processing advantage for language stimuli that are directly projected to the language-dominant hemisphere. This method has been used since the 1950s (Mishkin & Forgays, 1952). Bourne (2006) reviewed the literature, which consistently shows advantageous processing for letter strings presented in the RVF, relative to the LVF, in most people. 

Despite wide reporting of a RVF advantage at the population level, the validity of visual half-field language tasks has been questioned. Krach, Chen, and Hartje (2006) compared the laterality indices (LIs) produced during a visual half-field experiment with those produced using functional Transcranial Doppler Sonography (fTCD). The visual half-field task consisted of lexical decisions made towards abstract nouns presented in the LVF and RVF. During the experiment, the blood flow to the left and right hemispheres of 58 participants was measured. In addition, blood flow was measured during a word generation task— the gold standard task for assessing hemispheric dominance for language. Despite showing the expected RVF advantage on the visual half-field task, the behavioural LIs produced on the visual half-field paradigm did not correlate with the fTCD LIs produced during word generation (*r*= .18) or the visual half-field task itself (r -.004). The lack of validity here likely reflects the poor reliability of the visual field task as split-half reliability was very low (response time split-half: *r*= .14; accuracy split-half: *r*= .20). This illustrates the difficulty of interpreting associations between laterality indices when the reliability of measurement is so low. 

In recent years it has become clear that the reliability and validity of visual half-field tasks to identify the language-dominant hemisphere is largely dependent on several methodological aspects. For example, Hunter and Brysbaert (2008) noted stronger and more stable visual field differences when stimuli were presented bilaterally relative to those where only one stimulus was presented either in the LVF or in the RVF (Boles, 1987, 1990, 1994; see also Iacoboni & Zaidel, 1996). Hunter and Brysbaert argued that this is the result of stimuli competing during bilateral presentation, enhancing the advantage to the stimulus presented in the language dominant hemisphere. Reliability and validity also depend on there being a sufficient number of trials and brief stimulus presentation to prevent eye movements. When accounting for these methodological aspects, the validity of visual half-field tasks seems promising. For example, Hunter and Brysbaert (2008) used two visual half-field tasks, word naming (192 trials) and picture naming (160 trials) in which stimuli were bilaterally presented and masked at offset. The two tasks correlated strongly (*r*= .8, 95% CI .598-.956) in a sample of 26 left-handers. Encouragingly, the LIs from these visual half-field tasks also correlated positively with laterality from functional Magnetic Resonance Imaging (fMRI) on a word generation task in 10 left-handers. However, the small sample size meant that the confidence intervals around these estimates were very wide: word naming, *r*= .63 (95% CI = .001-.902), picture naming, *r*= .77 (95% CI = .272-.943). More recently, however, Van der Haegen, Cai, Seurinck, and Brysbaert (2011) reported highly similar findings in a somewhat larger sample of 50 participants. Again, participants completed behavioural word and picture naming visual half-field tasks and then a word generation task under fMRI. It is reassuring that the LIs for the behavioural measures were correlated with the fMRI LI: word naming, *r* = .64, picture naming, *r* = .65. Van der Haegen et al. also report a set of analyses involving 250 participants who completed the behavioural visual half-field tasks while their eye movements were monitored. Two sets of LIs were calculated; one controlling for fixation error and one that did not. Importantly, the LIs which did and did not control for fixation error were highly correlated for word naming, *r* = .94, and picture naming,*r* =.98, indicating that the inclusion of eye movement control adds little additional value when a visual half-field task employs mechanisms to encoruage central fixation and bilateral presentation.  

A promising line of work has emerged which further highlights the potential for well designed visual half-field tasks to assess language lateralisation. First introduced by Willemin et al. (2016), the translingual lexical decision task involves participants viewing letter stings either side of fixation and judging whether the left, right, or neither of the letter strings was a valid word. With 100 participants completing 256 trials, Willemin et al. reported a RVF advantage at the population level. Since then this effect has been replicated in a sample of 496 participants covering six international languages, with evidence of a RVF for each language studied. Not only does this task show validity, it seems reliable given Brederoo et al.'s (2020) observation that the task yields good split-half reliability when tested with 122 participants, *r* = 0.86 for error rates and *r* = 0.80 for response times.

#### Lateralised auditory verbal processing

Simultaneous presentation of different auditory stimuli to left and right ears for immediate recall was a method originally used in studies of attention, but it became evident that there was usually an advantage for verbal stimuli presented to the right ear (Kimura, 1967). Both ears project to both hemispheres, but the weaker ipsilateral pathways appear to be suppressed when the two sides compete, and so the right ear, with a contralateral projection to the left hemisphere, will have an advantage in tasks that involve language processing. 

Over the years, various dichotic listening paradigms have been used (Bryden, 1988; Westerhausen, 2019). As with the visual half-field paradigm, the test-retest reliability of dichotic listening paradigms has been far from optimal (Voyer, 1998; Kelley & Littenberg, 2019). However, recent data from Westerhausen and Samuelsen (2020) indicated that when designed optimally, the dichotic listening paradigm can be reliable. First, based on a review of the published literature, Westerhausen and Samuelsen outlined eight design features that should be used in an optimal dichotic listening paradigm and explained their justification for each. Their recommendations were: (1) stop consonant-vowel (CV) syllables as stimulus materials; (2) CV stimulus pairs from the same voicing category; (3) alternating trials of voiced and unvoiced stimulus pairs; (4) free-recall instruction; (5) one stimulus pair per trial; (6) a paradigm length of 120 dichotic trials; (7) all stimulus pairs presented at equal frequency to the two sides; and (8) inclusion of binaural (homonymic) trials. Putting these criteria into practice, Westerhausen and Samuelsen administered a modified dichotic listening paradigm using both a verbal and manual response format to 50 right-handers. Interestingly, the full paradigm yielded test-retest reliability of *r*= .93 for verbal responses and *r*= .91 for manual responses. Thus, the dichotic listening task provides a promising paradigm for those wanting to investigate language lateralisation without reliance on visual stimuli.

To date, little work has been conducted online with visual stimuli. By contrast, the dichotic listening paradigm has been implemented online with considerable success. Bless et al. (2013) developed a mobile device version of the consonant-vowel dichotic listening paradigm, with 36 simultaneous sound pairs. Under laboratory conditions, with a sample of 76 (33 Norwegian, 43 Austrialian) participants, they reported a test-retest reliability of *r*= 0.78 when using the mobile app. Furthermore, both subgroups of participants showed clear right ear advantages at the population level. In a subsequent large-scale study, Bless et al. (2015) administered the same application to a sample of over 4,000 participants with more than 60 different language backgrounds. Again Bless et al. (2015) reported a clear right ear advanatge at the population-level. They then used the large dataset to examine cultural/lingusitic effects on the degree on lateralisation; reporting that the degree of lateralization appears to be modulated by linguistic background. Together these studies demonstrate the potential for online laterality research to generate large amounts of data while maintaining a tolerable degree of reliability.

#### Lateralised face processing

In studies of face processing, it is possible to use a modification of the visual half-field paradigm in which single stimuli are viewed, composed of vertically split chimeric faces, where each half displays a different emotion or identity. Our focus here is on emotion detection in chimeric faces, where bias is usually found towards reporting the emotion shown in the left hemiface. 

The reliability of the chimeric faces tasks seems promising. Early work by Levy et al. (1983) using two vertically presented chimeric faces, found split-half reliability of *r*= .93. The validity of the chimeric faces task has been demonstrated using behavioural and fMRI data but in a task of recognising facial identity rather than emotion. In Yovel, Tambini, and Brandman’s (2008) study, participants had to recognise centrally presented chimeric faces, which showed different identities in the right and left visual fields. It is encouraging to note that the behavioural measure significantly correlated with the fMRI laterality index (LI) calculated from on activation in the fusiform face area (*r*= .49). However, the sample size used here was small: with 17 participants, the 95% confidence interval around the observed correlation of .49 ranged from .012 to .786.

### Behavioural laterality tasks and (a)typical lateralisation

The studies reviewed so far have indicated consistent population biases in lateralisation on behavioural tasks, but also there are also substantial individual differences. One factor that has been associated with the degree of lateralisation is handedness (for a comprehensive review, see Carey & Johnstone, 2014). Neuroimaging data indicate that for language tasks these differences in lateralisation primarily reflect the contribution of a subset of strong left-handers who are right hemisphere dominant for language, rather than indicating that this relationship operates on a continuum (Mazoyer et al., 2014). This association can be used to validate behavioural measures of lateralisation: we would expect to see a departure from typical lateralisation in strong left-handers.

With regards to visual half-field tasks for studying language lateralisation, there is evidence that the visual field advantage varies with handedness (Elias, Bulman-Fleming, & McManus, 1999; Weekes, Capetillo-Cunliffe, Rayman, Iacoboni, & Zaidel, 1999). However, a relatively well-powered study involving 100 participants, conducted by Willemin et al. (2016), reported no hint of any effect of handedness, when coded as left and right, or when divided into left (N = 19), mixed (N = 24) and right-handed (N = 57) groups, on the visual field advantage during a lexical decision task. This result illustrates the recurring challenge of interpreting null results in this field: do they reflect a true lack of relationship, inadequate power to detect small effects, or specific methodological factors? Brederoo et al. (2020) reported good split-half reliability for this task, suggesting the lack of handedness effect is unlikely to be due solely to measurement error. We may note that Willemin et al. asked participants to respond via manual response, whereas other studies have involved an active speech production component; manual responding could possibly interact with handedness to influence the laterality index on this task.

On dichotic listening tasks, the clear right ear (i.e. left hemisphere) advantage that is noted at the population level (see Hugdahl et al., 2009, and Westerhausen, 2019, for a review) is reduced in left-handers (Bethmann, Tempelmann, De Bleser, Scheich, & Brechmann, 2007; Bryden, 1970, 1988; Hugdahl, 2003). More recently, Karlsson, Johnstone, and Carey (2019) employed a consonant-vowel version of the dichotic listening task where participants reported which one of six syllables that they heard most clearly. In study 1, 87% of right-handers and 78% of non-right-handers showed a right ear advantage. For study 2, 85% of right-handers and 79% of non-right-handers showed a right ear advantage.

For chimeric faces tasks, which typically show a left visual field advantage, there again appears to be a greater departure from the typical pattern of laterality for left-handers (e.g. Gilbert & Bakan, 1973; Levy et al., 1983; Rozkowski & Snelbecker, 1982). This was also studied by Karlsson et al. (2019). When viewing a single face with a different emotion shown in either hemiface, 75% of right-handers and 60% of non-right-handers showed a leftwards bias. For the second chimeric faces task that involved two chimeric faces arranged vertically, a similar pattern emerged. 73% of right-handers and 57% of non-right-handers showed a leftwards bias.

From the above-reviewed studies, it appears that handedness is related to laterality across a range of tasks (for further discussion see Carey & Johnstone, 2014). This relationship points towards a general laterality factor which influences lateralisation across tasks and behaviours, as predicted by several theoretical accounts (Behrmann & Plaut, 2015; Hellige, 1993; Kosslyn, 1987). For example, the causal complementarity principle proposes that the lateralisation of processes involving the same hemisphere will be lateralised to the homologue in the opposite hemisphere. With reference to language processing and face emotionality processing, it would be predicted that language processing would be left lateralised and face processing would be right lateralised, and an increase of one co-occurs with an increase of another. Indeed, several studies have reported such patterns. In support, Brederoo et al. (2020) and Dundas, Plaut, and Behrmann (2015) have reported significant correlations between LIs for word and face processing. In a study of left-handers using fMRI with five tasks, Gerrits, Verhelst, and Vingerhoets (2020) found that the just under half the participants showed either standard laterality (left-lateralised for language and praxis, right-lateralised for face memory, line-bisection and vocal emotion) or a complete reversal of this pattern, providing clear evidence against the idea that these functions are lateralised independently. Nevertheless, the data indicated that this association is far from perfect (Badzakova-Trajkov, Haberling, Roberts, & Corballis, 2010) and some studies have found no correlation between laterality indices (Bryden, Hecaen, & Deagostini, 1983; Rosch, Bishop, & Badcock, 2012; Whitehouse & Bishop, 2009; van der Haegen & Brysbaert, 2018). Our ultimate goal is to unpick whether dissociations between laterality indices are evidence of multiple independent lateral biases across tasks, or whether there is a more prosaic explanation in terms of poor reliability or validity of tasks.

To date the focus has been in testing whether lateralisation shows  complementarity across tasks that are usually mediated by left and right hemispheres, especially whether there is a relationship between language vs visuospatial functioning. However, emerging lines of evidence have suggested that even within domains there may be dissociated patterns of lateralisation across similar tasks. Woodhead, Bradshaw, Wilson, Thompson, and Bishop (2019) reported data for 37 participants engaged in six language tasks under transcranial Doppler sonography (fTCD) and examined the factorial structure of lateralisation across tasks using structural equation modeling. They pitted two models against each other. The first assumed that language laterality is a unidimensional trait and a single factor was used to model covariance. The second assumed that that two laterality factors underlie the pattern of covariance. The results supported a two factor model at the population level. However, further examination of the data revealed that this was driven by seven left-handers. Woodhead, Thompson, Karlsson, and Bishop (2020) examined this factor structure in an extended sample of 74 participants with 43 right-handers and 31 left-handers. The data this time indicated that a two factor model was preferred for both right- and left-handers, with the preference for a two factor model being stronger for left-handers. Together, this indicated that even with the domain of language laterality indices may be dissociated.

### The current study

The principal goal of the current study was to evaluate the reliability and validity of an online behavioural laterality battery. Specifically, we examined whether it is possible to observe the usual laterality biases at the population level in tests of language and emotion processing and whether it is possible to achieve test-retest reliability of *r*= .65 or above using online behaviour research methods. This is an arbitrary cutoff, selected to represent a lower bound of reliability for a measure to be potentially useful for analysing individual differences. In addition, for tasks where satisfactory reliability was achieved, we considered how many trials were needed to achieve this. The tasks included in the battery were a novel rhyme decision visual half-field task, a consonant-vowel dichotic listening task, a chimeric faces visual half-field task, and a novel finger tapping task. These behavioural tasks were completed twice on two different occasions.

When selecting specific tasks in our online battery we were strongly guided by pragmatic considerations, i.e. how feasible would it be to administer the task remotely via an online platform. We aimed to include at least two language measures, one tapping into receptive language and one expressive, in order to test the notion that language laterality can dissociate across different tasks. We also aimed to include a task that involved face processing so that we could test for complementarity of lateralisation across tasks that usually lateralise to left and right hemispheres. Finally, a behavioural measure of motor laterality was included, to potentially provide an online analogue of relative hand skill similar to that used by Annett (1970).  

Ultimately we aimed to develop tasks that would meet three criteria.  First, the task should show good test-retest reliability. Second, it would have to show validity as demonstrated by showing significant lateralisation at the population level. Third, it should be sensitive to the subtle differences in laterality that have been reported between right- and non-right-handers.

For receptive language, we selected the dichotic listening paradigm, which has already been shown to yield reliable results when used online via a mobile app (Bless et al., 2013, 2015). Furthermore, Karlsson et al. (2019) have shown that this paradigm is sensitive to the subtle differences in language asymmetry between right and non-right handers, making it an obvious choice for inclusion.  

For expressive language we aimed to use a visual half-field task. While the task reported by Brysbaert and colleagues looked promising, it involved overt verbal responses which would be difficult to accommodate in an online format. Thus we decided to develop a new rhyme judgement task that was designed to meet the limitations of online testing, and which would require covert naming of stimuli presented in the two half-fields (see below for details).  

Given that numerous studies looking at the relationship lateralisation on language and non-language tasks have focused on the use of face stimuli (e.g. Brederoo et al., 2020), we chose to include a face task to conduct similar comparisons. Regarding the chimeric faces, Levy et al. (1983) reported good split-half reliability while Karlsson et al. had reported that, like the dichotic listening task, the the chimeric faces task is sensitive to the differences in perceptual asymmetry in right- and non-right-handers. 

Our final online measure was a finger-tapping test used as an online alternative to the well-known Annett (1970) pegboard task. There is suggestive evidence that a continuous measure of relative skill of the two hands may be more effective than more conventional hand preference measures for capturing individual differences in motor laterality that relate to language lateralisation (Annett, 2002; Flowers & Hudson, 2013). Performance measures such as this can provide a continuous measure of subtle variation in relative hand skill, and also correlate well with measures of hand preference (e.g. Steenhuis & Bryden, 1999). The pegboard task is one of the most widely used performance tasks (see Hodgson & Hudson, 2016, for discussion), but the requirement for apparatus makes it unfeasible as an online test. We therefore took the opportunity to explore the reliability and validity of a finger-tapping task that required the participant to repeatedly tap a short sequence on the computer keyboard with the index finger of the preferred or nonpreferred hand, which capture one aspect of pegmoving, namely precise aiming of sequential movements.

Our first set of predictions (hypothesis 1) concerned the validity of the tasks as indicators of cerebral lateralisation. Based on previous work, we predicted that at the population level: (1) the laterality indices for rhyme decision would show a RVF advantage (indicating left hemisphere dominance for language processing); (2) the laterality indices for the dichotic listening task would show a right ear advantage (indicating left hemisphere dominance for language processing); and (3) the laterality indices for chimeric faces would show a LVF advantage (indicating right hemisphere dominance for face or emotion processing). Predictions regarding the finger tapping task were less clear; our goal was to evaluate a test of relative hand skill that might provide an online surrogate for the kind of peg-moving task used by Annett (1970). Validity of the task would be demonstrated if a  right-hand advantage was found in right-handers, and a left-hand advantage in left-handers.  (Note that direct comparison with performance on a pegboard was not feasible as the study was conducted during a pandemic when in-person testing could not be done).  

Our second prediction (hypothesis 2) related to handedness and atypical lateralisation. We predicted that strong left-handers (i.e. those with laterality quotients of -90 or less on the Edinburgh Handedness Inventory; Oldfield, 1971) would be more likely to show atypical laterality (i.e. laterality in the opposite direction to our population-level predictions) than right-handers. This prediction followed from observations by Mazoyer et al. (2014, p. 1) who studied a large group of left- and right-handers using fMRI to measure language laterality. They concluded, “concordance of hemispheric dominance for hand and for language occurs barely above the chance level, except in a group of rare individuals (less than 1% in the general population) who exhibit strong right hemisphere dominance for both language and their preferred hand”.  

Our final prediction (hypothesis 3) related to the inter-relationships between laterality indices. With online testing, there is the opportunity to test inter-relationships between laterality indices with an adequately powered sample using measures of known reliability. Prior studies have been inconclusive because it has been difficult to gather large amounts of data to establish test-retest reliability. For instance, van der Haegen and Brysbaert (2018), found that language laterality did not correlate with face laterality in visual half-field tasks. However, their study was restricted to left-handers, who may be atypical in this regard, and they noted that lack of association was hard to interpret because it may be due to unreliability of the individual measures. In the pre-registration for our current study, we predicted that for right-handers, a model where the two language tasks are correlated with each other but not with the chimeric faces (model A) would be the best fit to the data, compared to either a model in which laterality indices are correlated between the language and chimeric face tasks (model B), or a base model where each task is independently lateralised (model C). Given our previous findings using fTCD to study dissociations in language laterality (Woodhead, Bradshaw, Wilson, Thompson, & Bishop, 2019), we further predicted that model fit may differ for right- and left-handers, with more dissociation between tasks in the latter group.  

## Method  

This project was pre-registered on the Open Science Framework (OSF) before the start of data collection. The registration form along with all task materials, analysis scripts and anonymised data can be found on the OSF at https://osf.io/qsxcv/. Working versions of the dichotic listening, chimeric faces, and finger tapping tasks are available on Gorilla Open Materials: https://gorilla.sc/openmaterials/104636.

### Participants

As our ultimate goal is to use these measures in individual differences research, we aimed to optimise the task to achieve observed test-retest reliability of at least *r*= .65. Our initial power analysis showed that to achieve sufficient precision around the estimate of reliability, we would require 300 participants. Out of the 300 participants, we originally specified that 80 would be left-handers. This would give us power to apply our planned model-fitting analysis to left-handers as a separate group.  In practice, our final sample exceeded 300, because we discarded participants from individual tasks for failing to meet prespecified criteria (see below).  
In total, 441 native English speakers were initially recruited through Prolific Academic (www.prolific.co) with all these participants completing both sessions,  Prolific is a platform for recruiting and screening paid research participants according to experimenter-specified criteria. Participants were 18- to 50-years-old, had normal or corrected-to-normal vision and reported no history of neurological disease (e.g. head injury, brain tumour, stroke) or significant hearing loss or impairment. 

This study was approved by the University of Oxford's Medical Sciences Inter-Divisional Research Ethics Committee (reference number: R66638/RE002) and conducted following the principles of the Declaration of Helsinki. Participants gave informed consent and were paid £15 for their participation.

### Online behavioural laterality battery

The battery included four measures of background information and four experimental assessments of behavioural laterality that were built and administered using the Gorilla Experiment Builder (www.gorilla.sc), a cloud-based tool for collecting data in the behavioural sciences (Anwyl-Irvine, Massonnié, Flitton, Kirkham, & Evershed, 2020). Each task is described below.

#### Basic demographics questionnaire 

The basic demographics questionnaire asked participants to report age, gender, years in education, and whether they were bilingual. We also asked questions about handedness and footedness. For handedness, we asked: which is your dominant hand (i.e. which hand do you prefer to use for tasks such as writing, cutting, and catching a ball?). For footedness, we asked: which foot do you normally use to step up on a ladder/step? For both questions, participants could answer "left", "right", or "no preference / Don't know".

#### Tests of ocular dominance

Adapted versions of the Miles test (Miles, 1929) and the Porta test (Porac & Coren, 1976) were used to determine each participant’s eye dominance in central gaze (i.e., when looking straight ahead). Each test classified participants as being either left or right eye dominant. We did not have specific predictions about ocular dominance, but gathered this information to further characterise behavioural laterality of the sample. In practice, the two tests agreed perfectly, so we report here just the Miles test. 

#### Edinburgh Handedness Inventory 

The Edinburgh Handedness Inventory (EHI; Oldfield, 1971) was administered to quantify handedness on a continuum. For 10 everyday activities, participants indicated their preferred hand use on a 5-step scale (right hand strongly preferred, right hand preferred, no preference, left hand preferred, left hand strongly preferred). The EHI was scored in the standard way, which involves combining information about direction and exclusiveness of hand preference. For simple contrast between left- and right-handers, we treated indices greater than 0 as right-handed, and indices less than 0 as left-handed. For analysis of extreme left-handers, we focussed on left-handers with an index of -90 or less, which corresponds to near-exclusive use of the left hand. 

#### LexTALE 

The Lexical Test for Advanced Learners of English (LexTALE; Lemhöfer & Broersma, 2012) was used to screen for normal-range language ability. Participants saw 60 letter strings and had to indicate which words they knew. Of the 60 strings, 40 were actual English words and 20 were non-words. LexTALE scores were corrected for the unequal proportion of words and non-words by averaging the percentages corrected for these two item types (e.g., ((number of words correct/40 x 100) + (number of nonwords correct/20 x 100))/2). Accordingly, the LexTALE scores ranged from 0 to 100. 

#### Rhyme decision task

The rhyme decision task was developed for this project as a novel visual half-field technique designed to engage lateralised language processes. On each trial, participants were asked to decide whether a foveally presented letter string rhymed with the name of an image shown in either the LVF or RVF. With online presentation, a particular concern is a potential for eye movements away from fixation. We relied on the fact that participants had to focus initially on the central written word to do the task, and thus the task encouraged fixation to a central location at the start of the trial. We subsequently displayed pictures under brief bilateral presentation, which has been shown to give adequate control for eye movements in previous visual half-field experiments with verbal naming (Beaumont, 1982). Studies that directly monitored eye movements in this setting reported failures of fixation on only 0.5% of trials (Geffen, Bradshaw & Nettleton, 1972; but see also Bourne, 2006). Pictures of familiar objects were presented for rhyme matching to the written word, to ensure that the participant would have to covertly name the picture, thereby engaging left hemisphere speech processing. We used covert rather than overt naming (cf. Hunter & Brysbaert, 2008) to make the task suitable for online presentation. This obviated the need for measuring latencies of oral responses, which would be challenging in the online context, both in terms of need for a high-quality microphone, and possible intrusion of background noises interfering with recording. Furthermore, the evaluation of oral responses would require additional scoring following data collection which would be a taxing procedure for researchers. It would also require additional ethical approvals with regards to the storing and processing of the data.

##### Materials

Twenty-six monosyllabic words were presented in foveal vision. Each word was 3-4 letters in length (*mean*= 3.8; *SD*= 0.40) and had an average Zipf frequency [log10(frequency per million words) + 3] of 4.4 (*SD*= 0.72) when using the SUBTLEX-UK database (van Heuven, Mandera, Keuleers, & Brysbaert, 2014). Each foveal word was paired with an image that corresponded to one of 26 rhyming monosyllabic words which had a mean Zipf frequency of 4.5 (*SD*= 0.48). For example, the word “bite” was paired with the image “kite” and the word “more” was paired with the image “door”. Each word-image pair was then paired with another word-image pair for which there was no inter-pair rhyme (i.e. bite-kite was paired with more-door). This resulted in 13 word-image couplets. For each of the foveally presented words in a given word-image couplet, the corresponding images could appear in either the LVF or RVF. Thus, for each of the 13 couplets, four combinations were possible. For the pairing of bite-kite and more-door the following stimuli were created: kite – bite – door, door – bite – kite, door – more – kite, and kite – more – door. In total, there were 52 unique stimuli. On a given trial, each image was displayed at 2.5 degrees eccentricity of the foveal word (see Figure 1).

Word stimuli were presented in black lowercase Tahoma font on a white background. Font was scaled to 250% equating to 28pt font. The image pairs were presented at approximately 2.5 degrees of visual angle either side of fixation. As screen size was likely to vary between participants, the size of the stimuli and eccentricity of images relative to fixation was maintained using Gorilla’s scaling tool.


![Figure 1. Schematic illustration of a trial on the rhyme decision task. In the example, the word “bite” is presented along with the two images “kite” and “door”. When making the correct judgement, participants would respond with by pressing ‘S’ to indicate that the rhyme was on the left.](Picture1.png){width=60%}


##### Procedure

The trials were preceded by a familiarisation phase in which each of the stimulus pictures was presented together with its written name. After familiarisation, 260 stimuli (52 unique stimuli each shown 5 times) were displayed across four blocks (65 items per block). Each of the four blocks also contained five items for which there was no rhyme. For example, the word “moon” was displayed with the images for kite and door: kite – moon – door. These foil items were included in an attempt to prevent participants from preferentially responding to items in either the LVF or RVF. These items were then pseudo-randomised such that identical image pairs could not appear one after the other.

Each trial began with a fixation cross presented centrally for 800 ms. Participants were instructed to keep their eyes on the central fixation point. Then a foveally presented word would appear for 200 ms. The bilaterally presented images were then presented for 150 ms. At stimulus offset, participants indicated whether the name of the image in the LVF or RVF rhymed with the foveally presented word. Participants were instructed to press ‘S’ if the written word rhymed with the image in the LVF, and ‘K’ if it rhymed with the image in the RVF. If participants did not detect a rhyme, they were instructed to press the space bar. The response triggered the next trial; note that the program waited until a response occurred: trials did not time-out after a predetermined duration. Accuracy and response times (RT) were recorded.

#### Dichotic listening task 

The consonant-vowel dichotic stimuli were taken from a dichotic listening task that was developed to work as a smartphone app, and shown to give high levels of test-retest reliability (Bless et al., 2013). These stimuli were the same as those used by Karlsson et al (2019) and were used with the kind permission of Professor Kenneth Hugdahl. 

##### Materials

The consonant-vowel stimuli were formed by pairing six stop-consonants (/b/, /d/, /g/, /p/, /t/, /k/) with the vowel /a/. Each of the six consonant-vowel stimuli (/ba/, /da/, /ga/, /pa/, /ta/, /ka/) were paired and played in each sound channel (e.g. /ba/-/da/), resulting in 36 pairings including homonyms. 

##### Procedure

As the dichotic listening task demands the use of stereo-headphones, participants were screened at the start of each session. Screening consisted of two tasks. The first involved participants judging which of three pure tones was quietest, and is described by Woods, Siegel, Traer, and McDermott (2017) in full detail. This sound discrimination task was designed to be easy to achieve when using headphones but difficult over loudspeakers due to phase-cancellation. Participants were removed from the study if they failed to correctly discriminate the quietest sound on at least five out of six trials, indicating that they were unlikely to be using headphones. The second check involved participants hearing a sound presented in only one of the two channels. Participants were removed if they failed to correctly identify which channel the sound was played on five out of six trials, indicating that they were not using stereo-headphones [^1].

Participants completed four blocks of the dichotic listening task. In each block, participants heard each of the 36 stimuli once. Across the four blocks, they responded to 144 stimuli. At the start of each trial, participants saw a fixation cross for 250 ms, after which a stimulus was played. After hearing each stimulus, participants were instructed to report the syllable they heard or if it seemed like they heard two different sounds, the one they heard most clearly by clicking a button corresponding to one of the six syllables. The response triggered the start of the next trial; trials did not time-out after a predetermined duration. Accuracy and response times (RT) were recorded.

#### Chimeric faces task

The chimeric faces stimuli were kindly provided by Dr Michael Burt, and have been reported elsewhere (Burt & Perrett, 1997; Innes, Burt, Birch, & Hausmann, 2016; Karlsson et al., 2019). 

##### Materials

The faces consisted of symmetrical averaged images created from four male and four female faces. Four emotional expressions were used: anger, disgust, happiness, and sadness. The faces were split vertically down the middle and paired so that one emotive hemiface was attached to another and blended at the midline (see Figure 2 for an example). These were paired in all possible combinations creating 16 individual stimuli. Four stimuli showed identical emotions in each hemiface.


![Figure 2. An example stimulus from the chimeric faces task. In the example, “happiness” is shown on the left and “sadness” on the right. A participant who is right lateralised for emotional processing would be more likely to perceive the emotion in the left hemifield and would, therefore, respond “happiness”.](chim_example.png){width=20%}


##### Procedure

Participants completed four blocks of the chimeric faces task. In each block, participants viewed each stimulus twice. Thus, they viewed 32 stimuli per block and 128 in total. At the start of each trial, participants fixated a cross for 1000 ms. A chimeric face was then displayed for 400 ms. Participants then reported the emotion seen in the face by clicking a button corresponding to one of the four emotions. The response triggered the start of the next trial; trials did not time-out after a predetermined duration. Accuracy and response times (RT) were recorded.

#### Finger tapping task

The finger tapping task is a novel behavioural task that we designed as a quantitative index of handedness analogous to a peg-moving task. Participants were required to either press the ‘W’, ‘R’, ‘V’, and ‘X’ keys with their left hand or the ‘T’, 'U', ‘M’, ‘B’ keys with their right hands in sequence as many times as possible within a 30-second window. Participants completed four blocks of the finger tapping task in total. Each block required participants to complete the task for both their dominant and non-dominant hand. Each keypress was recorded along with its timestamp relative to the beginning of the trial.

### General Procedure

The current study implemented a test-retest, within-subjects design across two sessions. Each session was three to 10 days apart. During session 1, participants completed the full battery of tasks. Self-report measures were completed first, followed by the behavioural laterality tasks. During session 2, participants completed only the behavioural laterality tasks. Hence, each participant provided data for the rhyme decision, dichotic listening, chimeric faces, and finger tapping tasks twice. The two sessions lasted approximately 45 minutes and 35 minutes respectively. 

When completing the behavioural tasks, participants were instructed to sit approximately 50 cm from the screen. Gorilla’s scaling tool, which requires the participant to hold a credit card on the screen while adjusting size to match an image on the screen, was utilised such that stimuli size and eccentricity was maintained across tasks and participants. During each task participants were instructed to respond as fast and accurately as possible. Stimuli from each task were repeated across four blocks. Within each block, participants completed 70 trials of the rhyme detection task (R); 36 trials of the dichotic listening task (D); 32 trials of the chimeric face task (C); and 2 trials of the finger tapping task (F) for both their dominant and non-dominant hand. The order of tasks with each block was determined as follows RDCF, DCFR, CFRD, FRDC, and the order of tasks remained consistent across blocks for each participant. For each task, trial order was randomised, except for the finger tapping task where participants responded with their dominant hand followed by their non-dominant hand.

### Data analysis

```{r read_dat, echo- FALSE, include= FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggpubr)
library(corrr)
library(flextable)
library(cocor)
options(knitr.kable.NA = '') #should suppress NA in tables
# read in data from csv
#LIs <- read.csv('https://osf.io/x5jd2/download',stringsAsFactors = F)
#We will replace with read from OSF, but better stick with LIs to ensure final version is the one we use 
allsum <- read.csv('./data/allsum.csv',stringsAsFactors = F)

```

```{r prepdat,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
# remove those without day 2 to make LIs file - we will just use this
# reformat NA
allsum$day2.complete <- ifelse(is.na(allsum$day2.complete), 0, allsum$day2.complete)
LIs <- allsum[allsum$day2.complete == 1,]

# remove
LIs_c <- LIs[LIs$day2.complete == 1,]

# now remove them from LI
LIs <- LIs[LIs$lexOut == "keep",]
# table of counts for footed and sigh
short_dat <- dplyr::select(LIs, "subject", "handedness", "footedness", "miles", "porta")
long_dat <- tidyr::gather(short_dat, task, response, footedness:porta, factor_key=TRUE)
# make table
tab <- as.data.frame(table(long_dat$handedness, long_dat$task, long_dat$response))
tab <- tab %>% 
  rename(
    Handedness = Var1,
    Task = Var2,
    Response= Var3,
    Count= Freq
    )
split <- ggplot(data=tab, aes(x=Response, y=Count, fill=Handedness)) +
  geom_bar(stat="identity", position=position_dodge()) + facet_grid(.~Task) +
    geom_text(aes(label=Count), vjust=-0.3, position = position_dodge(0.9), size=3.5)+
  theme_bw() + theme(legend.position = "top") + ylab("Count") + xlab("") + ylim(0,220)
ggsave(
  "handed_sight.png",
  plot = split,
  width = 6, height = 4,
  dpi = 300
)
#Add a category of handedness that distinguishes extreme left from other left-handers
#In preregistration, extreme left defined as EHI laterality -90 or less.
LIs$handed3 <- LIs$handedness
w<-which(LIs$index_EHI<(-89))
LIs$handed3[w]<-'Extreme.left'
```

Out of 441 participants recruited, `r nrow(LIs_c)` (`r round(nrow(LIs_c)/441*100, 1)`%) completed both sessions. From the `r nrow(LIs_c)` participants who completed both sessions, `r nrow(LIs_c)-nrow(LIs)` (`r round((nrow(LIs_c)-nrow(LIs))/nrow(LIs_c)*100, 1)`%) were removed as their lexTALE score was below 80, indicating that their level of vocabulary knowledge was below the cut off for lower advanced proficiency. This left a sample of `r nrow(LIs)` participants. 

##### Data cleaning

For each task, we adopted the following data cleaning procedures. First, for all tasks, we removed trials in which response times were shorter than 200 ms. Response times were log-transformed to reduce skew, as specified in our pre-registration. Outlier response times were identified using Hoaglin and Iglewicz’s (1987) procedure, whereby outliers are defined as response times that are 1.65 times the difference between the first and third quantiles (1.65 * (Q3-Q1)) below or above the first and third quantile values (e.g: lower limit = Q1 – 1.65 x (Q3-Q1); upper limit = Q3 + 1.65 x (Q3-Q1)). This criterion was applied to all responses, before subdivision into left- and right-sided responses. Our differences criterion was set to 1.65 instead of the typical 2.2 because we expected to obtain asymmetric distributions for response time, with most outliers in one tail of the distribution. The Hoaglin and Iglewicz procedure was applied to each participant's data separately. After applying each data trimming procedure, participants left with less than 80% of trials were removed. 

At the next stage, we excluded participants who failed to meet the pre-registered criteria for inclusion. Applying each of these procedures meant that the number of participants left in the final analyses could vary by task. For the chimeric faces task, we removed participants if they scored lower than 75% on trials in which an identical emotion was shown in each hemiface, and for the dichotic listening task, we removed those who scored less than 75% correct on trials where the same sound was played to each ear. These data trimming procedures left data for `r nrow(LIs)-nrow(LIs[LIs$exclude== 1 | LIs$exclude== 12,])` participants on the chimeric faces and `r nrow(LIs)-nrow(LIs[LIs$exclude== 2 | LIs$exclude== 12,])` participants on the dichotic listening task. An additional 7 cases had to be removed because of a technical error that meant they had less than 80 trials presented.

For the rhyme decision task, we removed participants who scored less than 50% accuracy (chance level) in either visual field. Furthermore, we removed participants who scored less than 75% accuracy on the catch trials (trials in which there was no rhyme). These trimming procedures left data for `r nrow(LIs[LIs$exRDT== 0,])` participants on this task. We considered recruiting further participants to achieve our target sample size of 300 participants. This seemed uneconomic as we could already see that with close to 300 cases, the test-retest reliability of the rhyme detection task was unsatisfactory. With 241 participants, the test-retest reliability was *r* = .63, which is smaller than the *r* = 0.65 that we pre-registered as our criterion for a reliable task. We plan to evaluate modified versions of this task in future but decided to stop data collection at this point and so we present here data from those participants with usable data.

For the finger tapping task, we added a data-cleaning step that had not been pre-registered, to remove participants where there were more than 20 keypresses across left and right hands that did not correspond to the intended sequence. This could reflect that the individual had forgotten the target sequence, or was not co-operating with instructions, but scrutiny of cases where this occurred suggested that it usually arose because of technical problems. For instance, some individuals had repeated recording of the same keypress at short intervals, suggestive of a sticky keyboard. The cut-off of 20 was arbitrarily selected and was successful in excluding cases with abnormally low scores in one session.

The final group consisted of `r nrow(LIs)` participants (`r nrow(LIs[LIs$gender== "Female",])` female) who had complete data on at least one of the behavioural tasks. They had a mean age of `r round(mean(LIs$age, na.rm= TRUE), 1)` years (*SD*= `r round(sd(LIs$age, na.rm= TRUE), 2)` and included `r nrow(LIs[LIs$handedness== "Left",])` left-handers (`r nrow(LIs[LIs$handedness== "Left" & LIs$gender== "Female",])` female). `r nrow(LIs[LIs$handedness== "Right" & LIs$bilingual== "Yes",])` right-handers were bilingual and `r nrow(LIs[LIs$handedness== "Left" & LIs$bilingual== "Yes",])` left-handers were bilingual. 

##### Methods for calculating laterality indices, reliability, and population-level analysis

We pre-registered that we would calculate LIs in two ways: (1) traditionally (100 x (Right – Left)/(Right + Left)); (2) a standardised LI that involved computing a *z*-score that represented, for each individual, a comparison between left- and right-sided responses. In fact, for RT data we specified a *t*-score, but *t* and *z* converge when sample size exceeds 30, and for simplicity, we refer to these as LI_z scores. These LI_z scores are very highly correlated with the traditional LI measures (correlations typically exceed .95) but can be used to provide a common metric for RT and accuracy measures when identifying significantly lateralised individuals. For example, using a conventional 2-sided alpha of .05, we can categorise individuals with an absolute LI_z greater than 1.96 as significantly lateralised. 

For the rhyme task, we pre-registered that we would calculate LIs based on log RT data, as accuracy during piloting was at ceiling. To obtain LI_z we ran a *t*-test comparing accurate log RTs for left- and right-sided stimuli for each person. 

For the dichotic listening and chimeric faces, we specified that LI calculations would be based on trials in which participants correctly identified a stimulus. The count of correct responses that corresponded to each side was used to generate an accuracy LI in two ways: (1) in the traditional fashion (100 x (Right – Left)/(Right + Left)); (2) as a *z*-statistic for each participant, using z = (pR-.5)/sqrt(pR x pL/n), where pR is the proportion of correct responses in the RVF, pL is the proportion of L responses in the LVF, and n is total LVF and RVF responses. This method can yield extreme z-scores (for instance, if 83/89 responses are to the right, then z = 15.92), so scores were censored to be in the range -5 to +5. Finally, LIs for the finger tapping task were calculated in the same manner, using the number of sequences generated by the left and right hand as opposed to the proportion of correct responses in each visual field.

To address hypothesis 1 and examine the laterality at the population level, we conducted a series of one-sample *t*-tests to compare mean LIs of the whole sample against zero for each task, using session 1 data.

For the reliability assessment, we first checked LIs for normality using a Shapiro-Wilk test. As most LIs were non-normal, we used a series of Spearman’s correlations to examine the correlation of coefficients for session 1 versus session 2. We also conducted an analysis to determine the optimal test length. For tasks where the test-retest reliability was above .75, considered how many trials were needed to achieve satisfactory reliability (i.e. *r*>= .65). This was accomplished by recalculating LIs using 1 to n trials, where n is the total number of trials on a task. This was of interest in indicating the most efficient way to administer these tasks in future while retaining good reliability. However, the full data (including all trials) was used for all subsequent analyses. 

##### Handedness and atypical laterality

To address hypothesis 2, that extreme left-handers will be more likely to show atypical laterality than right-handers, we categorised participants as extreme left-handers if they scored less than -90 on the EHI and right-handers if they scored greater than zero on the EHI. Following our pre-registration, atypicality was defined according to whether the participant's LI_z was significantly lateralised (with alpha = .05) in the opposite direction from the majority. Chi-square tests were then used to examine the association between handedness and atypicality on the rhyme decision, dichotic listening, and chimeric faces tasks. In our pre-registration we had planned to look at cases who were atypical on the language tasks and the chimeric faces. We did not conduct this analysis because few participants showed atypical lateralisation across multiple tasks. In our Supplementary Materials we do, however, compare laterality indices between extreme left-handers and right-handers to further examine the link between handedness and atypical lateralisation.

##### Relationship between language and non-language LIs

We examined the relationship between LIs on the rhyme decision, dichotic listening, and chimeric faces tasks by modelling covariances using a simplified version of Structural Equation Modeling (SEM) that used the sum of LIs from the two sessions of each task to represent each of three factors, minimising the impact of measurement error. In this approach, we constrain particular covariance patterns and report ‘best’ model fit according to AIC weights (Wagenmakers & Farrell, 2004). Akaike weights are transformations of the AIC values, which can be directly interpreted as conditional probabilities for each model, with the best-fitting model being selected. We  compared three models: 

-	Model A, where the two language tasks are correlated with each other but not with the chimeric faces 

-	Model B, where all LIs are correlated, and  

-	Model C, a base model where the LIs are unrelated.  

This was completed separately for right- and left-handers, as well as for the whole combined group. 

## Results

Descriptive data on foot and eye preference characteristics of the sample after exclusions as noted above are shown in Table 1.  As these aspects of laterality are not a focus of this study, we will not elaborate further on these data.

```{r simplifiedlatdescriptives, echo- FALSE, include= FALSE}
#Miles and Porta are identical so only report one.
short_dat$cat3<-'R'
short_dat$cat3[short_dat$handedness=='Left']<-'L'
short_dat$temp<-'R'
short_dat$temp[short_dat$footedness=='Left']<-'L'
short_dat$temp[short_dat$footedness=="Don't know"]<-'X'
short_dat$cat3<-paste0(short_dat$cat3,short_dat$temp)
short_dat$temp<-'R'
short_dat$temp[short_dat$miles=='Left']<-'L'
short_dat$temp[short_dat$miles=="Don't know"]<-'X'
short_dat$cat3<-paste0(short_dat$cat3,short_dat$temp)
t<-table(short_dat$cat3)
lattab<-data.frame(matrix(NA,nrow=6,ncol=5))
colnames(lattab)<-c('Foot.Eye','R.handers.N','R.handers.%','L.handers.N','L.handers.%')
lattab$Foot.Eye<-c('RR','RL','LR','LL','Other','Total')
lattab$R.handers.N[6]<-sum(t[9:16])
lattab$R.handers.N[1:4]<-as.vector(t[c(13,12,10,9)])
lattab$R.handers.N[5]<-lattab$R.handers.N[6]-sum(lattab$R.handers.N[1:4])
lattab$L.handers.N[6]<-sum(t[1:8])
lattab$L.handers.N[1:4]<-as.vector(t[c(5,4,2,1)])
lattab$L.handers.N[5]<-lattab$L.handers.N[6]-sum(lattab$L.handers.N[1:4])
sumR<-lattab$R.handers.N[6]
sumL<-lattab$L.handers.N[6]
lattab$`R.handers.%`<-round(100*lattab$R.handers.N/sumR,1)
lattab$`L.handers.%`<-round(100*lattab$L.handers.N/sumL,1)
lattab$`R.handers.%`[6]<-"100"
lattab$`L.handers.%`[6]<-"100"
```


Table 1. Count of left- and right-handers who report left or right on self-reported footedness, and eyedness (Miles test).
```{r Tab1,echo=FALSE, comment=FALSE, warning=FALSE}
lattab<-lattab[,c(1,2,4,3,5)] #now reorder columns to make sense
colnames(lattab)<-c('Foot-Eye','Right hander (N)','Left hander (N)','Right hander (%)','Left hander (%)')
lattab <- flextable(lattab)
lattab <- align(lattab, align = "center", j= 2:5)
autofit(lattab, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```
*Note*. RR: right foot, right eye; RL: right foot, left eye; LR: left foot, right eye; LL: left foot, left eye. 'Other' includes those who responded 'No preference / Don't know'.


```{r computepcorrRDT, echo=FALSE, comment=FALSE, warning=FALSE}
#revised this, as p.corr values now in allsum
RDT.short.dat<-allsum[allsum$exRDT==0,]
tempRDT <- dplyr::select(RDT.short.dat,RDT1.pcorrL,RDT1.pcorrR,RDT2.pcorrL,RDT2.pcorrR)
allmeanpcorr <- mean(colMeans(tempRDT,na.rm=T))
allsdpcorr <- sd(c(tempRDT$RDT1.pcorrL,tempRDT$RDT1.pcorrR,tempRDT$RDT2.pcorrL,tempRDT$RDT2.pcorrR),na.rm=T)
```

### The validity of each behavioural task
```{r altplotraw,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}

makerawplot <- function(tempLR,mysession,myname,mylim){
  colnames(tempLR)<-c('Left','Right','Handedness')
  tempLR<-tempLR[!is.na(tempLR$Handedness), ] #remove rows with missing data
  tempLR$Handedness<-as.factor(tempLR$Handedness)
  droplevels(tempLR$Handedness)
  levels(tempLR$Handedness)=c('Right','Left')
  #myalpha<-c(1,.75) #haven't been able to adjust cols or pch this way. alpha works but one is always v faint regardless of setting
  meanL<-mean(tempLR$Left,na.rm=T)
  meanR<-mean(tempLR$Right,na.rm=T)
  mytitle<-paste0(myname,"\n Session",mysession)
  myg <- ggplot(tempLR, aes(x=Left, y=Right,col=Handedness)) + geom_point(size=.5) +
    xlim(mylim)+ylim(mylim)+
    labs(title=mytitle)+
    geom_abline(intercept = 0, slope = 1, color="red", 
                linetype="dotted")+
    geom_hline(yintercept=meanR,linetype='dotted')+geom_vline(xintercept=meanL,linetype='dotted')+
    theme(legend.position = "none") + theme_bw() +
    theme(plot.title = element_text(size = 12)
    )
  #myg<-myg+ scale_color_manual(values=c("black","red"))
  return(myg)
}
```
```{r dorawplotfunction,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}

myname<-'Rhyme judge RT'
tempbit<-LIs[LIs$exRDT==0,]
tempLR<-dplyr::select(tempbit,RDTlog1.Lraw,RDTlog1.Rraw,handpch)
#convert back to raw time
tempLR[,1:2]<-exp(tempLR[,1:2])
session<-1
mylim<-c(500,1500)
myg1<-makerawplot(tempLR,session,myname,mylim)

tempLR<-dplyr::select(LIs[LIs$exRDT==0,],RDTlog2.Lraw,RDTlog2.Rraw,handpch)
tempLR[,1:2]<-exp(tempLR[,1:2]) #convert from log back to original scale for plot
session<-2
myg2<-makerawplot(tempLR,session,myname,mylim)

myname<-'Dichotic accuracy'
tempLR<-dplyr::select(LIs[LIs$exclude<2,],DL1.Lraw,DL1.Rraw,handpch)
session<-1
mylim<-c(0,100)
myg3<-makerawplot(tempLR,session,myname,mylim)
tempLR<-dplyr::select(LIs[LIs$exclude<2,],DL2.Lraw,DL2.Rraw,handpch)
session<-2
myg4<-makerawplot(tempLR,session,myname,mylim)

myname<-'Chimeric faces accuracy'
#LIs exclude of 1 or 12 indicates excluded from CF; retain exclude 0,2
tempLR<-dplyr::select(LIs[LIs$exclude %in% c(0,2),],CF1.Lraw,CF1.Rraw,handpch)
session<-1
mylim<-c(0,100)
myg5<-makerawplot(tempLR,session,myname,mylim)
tempLR<-dplyr::select(LIs[LIs$exclude %in% c(0,2),],CF2.Lraw,CF2.Rraw,handpch)
session<-2
myg6<-makerawplot(tempLR,session,myname,mylim)

myname<-'N finger sequences'
tempLR<-dplyr::select(LIs,finger.L1,finger.R1,handpch)
session<-1
mylim<-c(50,180)
myg7<-makerawplot(tempLR,session,myname,mylim)
tempLR<-dplyr::select(LIs,finger.L2,finger.R2,handpch)
session<-2
myg8<-makerawplot(tempLR,session,myname,mylim)


ggarrange(myg1,myg2,myg3,myg4,myg5,myg6,myg7,myg8, ncol = 2, nrow = 4,common.legend=T,legend="bottom")
ggsave(
  "./plots/all.raw.png",
  width = 5, height = 8,
  dpi = 300
)
```

Distributions of the raw data are shown in Figure 3. The scatterplots indicate scores on the left and right sides for each task, with self-reported handedness (left vs right) colour-coded. For each task, the mean for each side is shown as vertical and horizontal dotted lines, and equal performance on the two sides corresponds to the sloping red dotted line: thus an impression of whether the task is lateralised can be obtained by considering whether points cluster around the sloping lines symmetrically.  

\newpage

![Figure 3. Left side (L) vs right side (R) scores for sessions 1 and 2 for the behavioural laterality tasks. The diagonal dotted line shows the point of equality: points above this are higher for R than L, and points below are higher for L than R. Mean values for R and L are shown as horizontal and vertical dotted lines. The colour of the points indicates the participants’ handedness (pink = right-handed; blue = left-handed). ](./plots/all.raw.png){width=80%}

For the rhyme decision task, only correct responses were used for computing mean log RTs (shown transformed back to the original ms scale in the plot). Generally, accuracy on the rhyme decision task was high. For session 1, accuracy was `r round(mean(allsum$RDT1.pcorrL, na.rm= TRUE),1)`% (*SD* = `r round(sd(allsum$RDT1.pcorrL, na.rm= TRUE),1)`%) in the LVF and `r round(mean(allsum$RDT1.pcorrR, na.rm= TRUE),1)`% (*SD* = `r round(sd(allsum$RDT1.pcorrR, na.rm= TRUE),1)`%) in the RVF. For session 2, accuracy was `r round(mean(allsum$RDT2.pcorrL, na.rm= TRUE),1)`% (*SD* = `r round(sd(allsum$RDT2.pcorrL, na.rm= TRUE),1)`%) in the LVF and `r round(mean(allsum$RDT2.pcorrR, na.rm= TRUE),1)`% (*SD* = `r round(sd(allsum$RDT2.pcorrR, na.rm= TRUE),1)`%) in the RVF. For dichotic listening and chimeric faces, a correct response can be given from either side; it follows that there will be a negative correlation between the two sides reflecting the fact that the number of selections on the left will be inversely related to the number of correct responses on the right. For these tasks, it is evident by inspection that most responses for dichotic listening cluster above the dotted line, indicating a right ear advantage, whereas most responses on chimeric faces cluster below the dotted line, indicating a left hemi-face advantage. Finally, we show the number of correct sequences with each hand on the finger tapping task. Here, a strong impact of handedness is evident on inspection, with left-handers generally more accurate with the left hand, and right-handers more accurate with the right hand.  

The distribution of LIs can be used to quantify departures from symmetry. Recall that for all tasks, we computed LIs in a typical way: (100 x (Right – Left)/(Right + Left)), and that because of crossed pathways from hands, ears and eyes to the brain, a positive LI indicates left lateralisation and a negative LI indicates right lateralisation at the brain level. LIs on the rhyme task were calculated using log RTs for correct responses. LIs for the dichotic listening and chimeric faces were calculated using the count of correct responses for sounds/emotions in each ear/visual. LIs on the finger tapping task were calculated using the number of sequences generated for each hand. Table 2 shows these mean LIs, as well as a one-sample Wilcoxon test comparing the mean LI with zero. Wilcoxon tests were chosen as a series of Shapiro-Wilks tests showed a departure from normality for several tasks. It can be seen that all measures were significantly lateralised in the predicted direction at the population level, with left-hemisphere superiority for rhyme decision, dichotic listening and finger tapping, and right-hemisphere superiority for chimeric faces. 

```{r make.tab2,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
#Make a table to summarise LI means/distribution stats for 4 tasks
#This will gradually get populated as we go through each task
#Cells for each task are filled in course of plots.function chunk
LItable <- data.frame(matrix(NA,nrow=8,ncol=7))
colnames(LItable)<-c('Task','N','Mean','SD','One sample v','One sample p','Normality p')
LItable[,1]<-c('RD 1','RD 2','Dl 1','DL 2','CF 1','CF 2','FT 1','FT 2')

keynames <- c("Day1.RDT_RT_LI"  ,"Day2.RDT_RT_LI" ,"Day1_DL_acc_LI" , "Day2_DL_acc_LI",   "Day1_CF_acc_LI", "Day2_CF_acc_LI","Day1_finger_LI", "Day2_finger_LI"   )
for (i in 1:length(keynames)){
  keycol<-which(names(LIs)==keynames[i]) #find this column
#exclude appropriately
   if (i<7){
  thisdata <- LIs[LIs$exclude %in% c(0,1),]}
  if (i<5){
  thisdata <- LIs[LIs$exclude %in% c(0,2),]}
    if (i<3){
  thisdata <- LIs[LIs$exRDT==0,]}
  temp<-thisdata[!is.na(thisdata[,keycol]),keycol]

  LItable[i,2]<-length(temp)
  LItable[i,3]<-round(mean(temp),2)
  LItable[i,4]<-round(sd(temp),2)
  LItable[i,5]<-round(wilcox.test(temp)$statistic,2)
  pstring <- round(wilcox.test(temp)$p.value,3) # use wilcoxon
  ifelse(pstring<.001,pstring<-'<0.001',pstring<-char(pstring))
  
  LItable[i,6]<-pstring
  pstring <- round(shapiro.test(temp)$p.value,3)
  ifelse(pstring<.001,pstring<-'<0.001',pstring<-as.character(pstring))
 
  LItable[i,7]<-pstring
  
}
```


Table 2.  Mean LIs and results from one-sample t-tests and Shapiro-Wilks tests for departure from normality for the rhyme decision (RD), dichotic listening (DL), chimeric faces (CF), and finger tapping (FT) tasks at sessions 1 and 2.
```{r Tab2,echo=FALSE, comment=FALSE, warning=FALSE}
tab2 <- flextable(LItable)
tab2 <- align(tab2, j= 2:7, align= "center")
autofit(tab2, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```
*Note*. LIs are scored such that a positive value equates to left lateralisation at the brain level.


Table 3 shows data from the LI_z measures, which make it easier to compare different tasks on the same scale. The distributions of LI_z scores are shown graphically in the supplementary materials. For each task, those with LI_z scores greater than 1.96 are categorised as left-hemisphere dominant, and those with LI_z scores less than -1.96 are categorised as right-hemisphere dominant. If there were no population bias, we would expect around 2.5% of individuals to meet each of these criteria. It can be seen that for dichotic listening and chimeric faces, around 45% of individuals have hemispheric dominance in the predicted direction and around 9% have hemispheric dominance in the opposite direction. The proportions showing significant laterality are lower for the rhyme decision task (around 17% left-hemisphere dominant, and 5% right-hemisphere dominant), and for finger tapping, the proportions are only slightly greater than would be expected by chance, although there is a suggestion of increasing laterality on that task across the two sessions. Note, however, that we had oversampled left-handers for this study, and, as is evident from exploratory analyses presented below, finger-tapping was strongly influenced by handedness.

<!---this is also very evident from the scatterplot in Fig 3--->
```{r make.tab3,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
#Make a table to summarise LI means/distribution stats for 4 tasks this time using LI_z.
#This will gradually get populated as we go through each task
#Cells for each task are filled in course of plots.function chunk
LIztable <- data.frame(matrix(NA,nrow=8,ncol=6))
colnames(LIztable)<-c('Task','N','Mean','SD','L-lateralised %','R-lateralised %')
LIztable[,1]<-c('RD 1','RD 2','DL 1','DL 2','CF 1','CF 2','FT 1','FT 2')

keynames <- c("zlat_RDT_1"  ,"zlat_RDT_2" ,"Day1_Dich_acc_Z" , "Day2_Dich_acc_Z",   "Day1_CF_acc_Z", "Day2_CF_acc_Z","Day1_Finger_acc_Z", "Day2_Finger_acc_Z"   )
for (i in 1:length(keynames)){
  keycol<-which(names(LIs)==keynames[i]) #find this column
   if (i<7){
  thisdata <- LIs[LIs$exclude %in% c(0,1),]}
  if (i<5){
  thisdata <- LIs[LIs$exclude %in% c(0,2),]}
    if (i<3){
  thisdata <- LIs[LIs$exRDT==0,]}
  temp<-thisdata[!is.na(thisdata[,keycol]),keycol]

  LIztable[i,2]<-length(temp)
  LIztable[i,3]<-round(mean(temp),2)
  LIztable[i,4]<-round(sd(temp),2)
  LIztable[i,5]<-round(100*length(which(temp>1.96))/length(temp),1)
  LIztable[i,6]<-round(100*length(which(temp<(-1.96)))/length(temp),1)
}
```


Table 3. Mean LI_z and percentage of participants who were significantly left lateralised (z > 1.96) or right lateralised (z < -1.96) on the rhyme decision (RD), dichotic listening (DL), chimeric faces (CF), and finger tapping (FT) tasks at sessions 1 and 2.
```{r Tab3,echo=FALSE, comment=FALSE, warning=FALSE}
tab3 <- flextable(LIztable)
tab3 <- align(tab3, align= "center", j= 2:6)
autofit(tab3, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```
*Note*. LIs are scored such that a positive value equates to left lateralisation at the brain level.


### Test-retest reliability

The scatterplots depicting test-retest reliability are shown in Figure 4, with Spearman test-retest correlations in Table 4. These were based on LI_z values, but are essentially identical to values from unscaled LI values. Confidence intervals were estimated using the *spearman.ci()* function from the RVAideMemoire package (version 0.9-75; Hervé, 2020) with 10,000 iterations. For all but the rhyme decision task, we obtained good test-retest reliability that exceeded our pre-registered threshold of *r*= .65.

```{r make.combotablex,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
#Make a table to summarise results for all 4 tasks
#This will gradually get populated as we go through each task
#Cells for each task are filled in course of plots.function chunk
combotable <- data.frame(matrix(NA,nrow=4,ncol=3))
colnames(combotable)<-c('Task','Spearman r','95% CI')
combotable[,1]<-c('Rhyme Decision' ,'Dichotic Listening','Chimeric Faces','Finger Tapping ')
```

```{r plots.function, echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
# Adam's code here turned into generic function
# Also saving the scatterplots as png.
# Also computes spearmans with CI and returns these from function
densplots <- function(dat, time1,time2,name1,name2,scattername,y1, y2, x1, x2, ax, ay, remove, title, N){
  # plots
  dens1<-ggplot(dat, aes(x=time1))+geom_density(linetype="dashed")+theme_bw()+ggtitle(name1)
  dens1 <- dens1+ geom_vline(xintercept = 0)
  
  # day 2
  # plot density
  dens2<-ggplot(dat, aes(x=time2))+geom_density(linetype="dashed")+theme_bw()+ggtitle(name2)
  dens2 <- dens2+ geom_vline(xintercept = 0)
  
  
  # conduct Spearman's wth bootstrapped CI
  myspear<-RVAideMemoire::spearman.ci(time1, time2, nrep = 10000, conf.level = 0.95)
  
  myci <- paste0(round(myspear$conf.int[1],2),' - ',round(myspear$conf.int[2],2))
  
  # scatterplot time1 x time2
  # position for label set to 50%x and 90%y
  xpos <- max(time1,na.rm=T)*.5
  ypos <- max(time2,na.rm=T)*.9
  mycor<-cor.test(time1, time2, method = "spearman", alternative = "greater")$estimate
  #Make a label to show the correlation with 95%CI and N on the plot
  mycorlabel<-paste0('r = ',round(mycor,2),'\n95% CI: ',myci,'\nN = ',N)
  #Find position in top L corner for legend
  legposx <- .25 #not working - needs tweaking!
  legposy <- .85
  #censor extreme values for plotting only
  w<-which(time1<(-remove) )
  time1[w] <- (-remove)
  w<-which(time1>remove) 
  time1[w] <- (remove)
  w<-which(time2<(-remove) )
  time2[w] <- (-remove)
  w<-which(time2>remove) 
  time2[w] <- (remove)
  #now do the plot
  myscatter <<- ggplot(dat, aes(x= time1, y= time2)) +
    geom_hline(yintercept=0, color = "black") +
    geom_vline(xintercept=0, color = "black") +
    geom_point(aes(color= handed3)) + 
    geom_rug(aes(color= handed3)) +
    theme_bw(18) +
    ylab(name2) + 
    xlab(name1) +
    annotate("text", x = ax, y = ay, label = mycorlabel) +
    theme(legend.position = c(legposx,legposy), legend.title = element_blank()) + ylim(y1, y2) + xlim(x1, x2) +
    ggtitle(title) + theme(plot.title = element_text(hjust = 0.5))
  # Set relative size of marginal plots (main plot 10x bigger than marginals)
  # bigplot<-ggExtra::ggMarginal(myscatter, groupColour = TRUE, groupFill = TRUE)
  scattername<-paste0('./plots/',scattername,".png")
  ggsave(scattername,plot=myscatter,dpi = 300, width = 6, height = 6,)
  return(list(mycor,myci))
}
```

```{r do.plots,LI,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
#Add a category of handedness that distinguishes extreme left from other left-handers
#In preregistration, extreme left defined as EHI laterality -90 or less.
LIs$handed3 <- as.character(LIs$handedness)
w<-which(LIs$index_EHI<(-89))
LIs$handed3[w]<-'Extreme left-hander'
w<-which(LIs$handed3=='Left')
LIs$handed3[w]<-'Moderate left-hander'
w<-which(LIs$handed3=='Right')
LIs$handed3[w]<-'Right-hander'
# RHYME DECISION
# remove bad cases
RD.dat <- LIs[!is.na(LIs$handed3),]
RD.dat <- RD.dat[RD.dat$exRDT == 0,]
# now plot
dat <- RD.dat
time1<-RD.dat$zlat_RDT_1
time2<-RD.dat$zlat_RDT_2
name1<-"Rhyme decision LI_z (session 1)"
name2<-"Rhyme decision LI_z (session 2)"
scattername<-"RhymeDecisionScatter"
y1= -5
y2= 5
x1= -5
x2= 5
ax= 5*.67
ay= -5*.75
remove= 5
title= "(A)"
N=241
mycors<-densplots(RD.dat, time1,time2,name1,name2,scattername, y1, y2, x1, x2, ax, ay, remove, title, N) 
combotable[1,2]<-round(mycors[[1]],3)
combotable[1,3]<-mycors[[2]]
RDT.plot <- myscatter

# DICHOTIC LISTENING
# remove bad cases
DL.dat <- LIs[!is.na(LIs$handed3),]
DL.dat <- DL.dat[DL.dat$exclude == 0 | DL.dat$exclude == 1,]
# now plot
dat <- DL.dat
time1<-DL.dat$Day1_Dich_acc_Z
time2<-DL.dat$Day2_Dich_acc_Z
name1<-"Dichotic listening LI_z (session 1)"
name2<-"Dichotic listening LI_z (session 2)"
scattername<-"DichoticScatter"
title="(B)"
N=290
mycors<-densplots(DL.dat, time1,time2,name1,name2,scattername,y1, y2, x1, x2, ax, ay, remove,title,N)
combotable[2,2]<-round(mycors[[1]],3)
combotable[2,3]<-mycors[[2]]
DL.plot <- myscatter

# CHIMERIC FACES
# remove bad cases
CF.dat <- LIs[!is.na(LIs$handed3),]
CF.dat <- CF.dat[CF.dat$exclude == 0 | CF.dat$exclude == 2,]
# now plot
dat <- CF.dat
time1<-CF.dat$Day1_CF_acc_Z
time2<-CF.dat$Day2_CF_acc_Z
name1<-"Chimeric faces LI_z (session 1)"
name2<-"Chimeric faces LI_z (session 2)"
scattername<-"ChimericScatter"
title="(C)"
N=289
mycors<-densplots(CF.dat, time1,time2,name1,name2,scattername, y1, y2, x1, x2, ax, ay, remove,title,N)
combotable[3,2]<-round(mycors[[1]],3)
combotable[3,3]<-mycors[[2]]
CF.plot <- myscatter

# FINGER TAPPING
FT.dat <- LIs[!is.na(LIs$handed3),]
FT.dat <- FT.dat[!is.na(FT.dat$Day1_Finger_acc_Z),]
time1<-FT.dat$Day1_Finger_acc_Z
time2<-FT.dat$Day2_Finger_acc_Z
name1<-"Finger tapping LI_z (session 1)"
name2<-"Finger tapping LI_z (session 2)"
scattername<-"FingerScatter"
title="(D)"
N=288
mycors<-densplots(FT.dat, time1,time2,name1,name2,scattername, y1, y2, x1, x2, ax, ay, remove,title,N)
combotable[4,2]<-round(mycors[[1]],3)
combotable[4,3]<-mycors[[2]]
FT.plot <- myscatter

combine.plots <- ggarrange(RDT.plot, DL.plot, CF.plot, FT.plot)
ggsave("./plots/all_LIs.png", combine.plots, width = 12, height = 12)
```


Table 4. Test-retest reliability estimates and 95% CIs for the rhyme decision (RD), dichotic listening (DL), chimeric faces (CF), and finger tapping (FT) tasks.
```{r Tab4,echo=FALSE, comment=FALSE, warning=FALSE}
combotable$Task[1] <- "RD"
combotable$Task[2] <- "DL"
combotable$Task[3] <- "CF"
combotable$Task[4] <- "FT"

combotable$`95% CI`[3] <- "0.84 - 0.90"
combotable$`95% CI`[4] <- "0.68 - 0.80"

tab4 <- flextable(combotable)
tab4 <- align(tab4, align= "center", j= 2:3)
autofit(tab4, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```

\newpage

![Figure 4. Scatter plots for session 1 and session 2 data for LI_z scores on each laterality task: (A) rhyme decision, (B) dichotic listening, (C) chimeric faces, and (D) Finger tapping. Handedness is colour coded with extreme left-handers identified as those who have a score below -90 on the Edinburgh Handedness Inventory. Note that z-scores are censored at absolute values of 5.](./plots/all_LIs.png){width=80%}


### Optimising the tasks

The dichotic listening and chimeric faces tasks had test-retest reliability above *r* = .75, and so we investigated whether the tasks could be made more efficient by reducing the number of trials while retaining good test-retest reliability. Hence, we recalculated LIs for the dichotic listening and chimeric faces tasks using 1 to n trials, where n is the total number of trials on each task. The absolute test-retest correlation coefficients are shown in Figure 5. Peak reliability was reached in around 85 trials with dichotic listening, and a minimum of 60 trials was required to achieve a test-retest correlation of *r* = .65. For the chimeric faces task, peak reliability was achieved with around 36 trials, and a minimum of 25 trials was necessary to achieve test-retest reliability of *r* = .65. 


![Figure 5. Test-retest correlations for (A) the dichotic listening task and (B) the chimeric faces task when using a variable number of trials to calculate laterality indices. The red dashed line marks the test-retest correlation *r* = .65. The correlations coefficients are shown as absolute values.](./plots/all.cor.plot.png){width=70%}


### Atypical laterality and handedness

According to Mazoyer et al (2014), extreme left-handers are more likely than other handedness groups to have reversed laterality compared to the rest of the population. Our pre-registered analysis accordingly focused on comparing extreme left-handers (those with a score of -90 or below on the Edinburgh Handedness Inventory) with right-handers. We defined 'atypical laterality' as laterality that is in the opposite direction to the majority of participants, with an absolute LI_z value greater than 1.96. Although the focus of our planned analyses included only right-handers and extreme left-handers, we show data for the remaining left-handers for completeness in Table 5. 

```{r makecontingencies,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
#We start by using z-scores to make a 3-way categorisation into:
#1 sig bias in typical direction; 2: NS bias 3: in atypical direction with sig bias.
#
LIs$rhyme1.cut <- cut(LIs$zlat_RDT_1, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("AtypLat", "Nonlat", "TypLat"), 
                       right = FALSE)
LIs$dichotic1.cut <- cut(LIs$Day1_Dich_acc_Z, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("AtypLat", "Nonlat", "TypLat"), 
                       right = FALSE)
LIs$chimeric1.cut <- cut(LIs$Day1_CF_acc_Z, 
                       breaks =  c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("AtypLat", "Nonlat", "TypLat"), 
                       right = FALSE)
mytabr <- table(LIs$rhyme1.cut)
mytabd <- table(LIs$dichotic1.cut)
mytabc <- table(LIs$chimeric1.cut)
mytabc<-mytabc[c(3,2,1)]
mytab2 <-rbind(mytabr,mytabd,mytabc)
row.names(mytab2)<-c('Rhyme decision','Dichotic','Chimeric Faces')
mytab2<-data.frame(mytab2)

#mytab2%>%
#  kable() %>%
#  kable_styling("condensed")

tabr <- table(LIs$handed3,LIs$rhyme1.cut)
#chisq.test(tabr)

tabd <- table(LIs$handed3,LIs$dichotic1.cut)
#chisq.test(tabd)

tabc <- table(LIs$handed3,LIs$chimeric1.cut)
#chisq.test(tabc)

#Planned test omitted group 'Left' and column Nonlat.
chi.r<-chisq.test(tabr[c(1,3),c(1,3)])

chi.d<-chisq.test(tabd[c(1,3),c(1,3)])
chi.c<-chisq.test(tabc[c(1,3),c(1,3)])

#ignore the headings of these tables!
```


Table 5. Frequencies of laterality typicality for extreme left-handers, moderate left-handers and right-handers across the rhyme decision (RD), dichotic listening (DL), and chimeric faces (CF) tasks.
```{r Table2,echo=FALSE, comment=FALSE, warning=FALSE}
tabr<-cbind(tabr,round(100*prop.table(tabr,1),1))
tabd<-cbind(tabd,round(100*prop.table(tabd,1),1) )
tabc<-cbind(tabc,round(100*prop.table(tabc,1),1)) #add percentages
latcats <- as.data.frame(rbind(tabr,tabd,tabc))

row.names(latcats) <- c() #remove rownames as they make problems for printing

#Instead have a new column with these
latcats$nucol <- c('Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander',
                   'Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander',
                   'Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander')
latcats$nucol2 <- c('RD',
                   ' ',
                   ' ',
                   'DL',
                   ' ',
                   ' ',
                   'CF',
                   ' ',
                   ' ')

latcats<-latcats[,c(8,7,3,2,1,6,5,4)] #now reorder columns to make sense
colnames(latcats)<-c('Task','Sub-group','Left N','Non N','Right N','Left %','Non %','Right %')

myft2 <- flextable(latcats)
#NB This table needs formatting - has formatted all numbers to 3 decimal places, which is not what we want. Code below achieves this

num_keys <- c("Left %","Non %","Right %")
int_keys <- c("Left N","Non N","Right N")

ft <- colformat_num(x = myft2, col_keys = num_keys, digits = 1)
ft <- colformat_int(x = ft, col_keys = int_keys, big.mark = ",")
autofit(ft)
```
*Note*. N is the count of participants. % is the percentage of participants.


```{r pformatfunction, echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
pformat<-function(pvalue){
  pp <- "*p* < .001" #default value
  if (pvalue>.001) {
    pp<-paste0("*p* = ",round(pvalue,3))
  }
  return(pp)
}
```

The rhyme decision task has few individuals who are significantly lateralised in either direction. We will therefore not consider it further, as our analyses are only justified if the task is an indicator of cerebral lateralisation. Both dichotic listening and chimeric faces, on the other hand, have a high proportion of strongly lateralised individuals. The planned analyses, comparing typically lateralised with atypically lateralised individuals, and extreme left vs right-handed individuals, show a significant association between extreme left-handedness and atypical laterality on a chi-square test. For dichotic listening, chi-square = `r round(chi.d$statistic,2)`, d.f. = 1, `r pformat(p.adjust(chi.d$p.value, method= "bonferroni", n=2))`; for chimeric faces, chi-square = `r round(chi.c$statistic,2)`, d.f. = 1, `r pformat(p.adjust(chi.c$p.value, method= "bonferroni", n=2))`. These data provide statistical support for the prediction from Mazoyer et al (2014) that extreme left-handers have an increased rate of atypical cerebral lateralisation.

```{r contingency2tasks,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
tab2task <- table(LIs$dichotic1.cut,LIs$chimeric1.cut)
chi2task<-chisq.test(tab2task)
w1<-which(LIs$chimeric1.cut=='TypLat') #this is confusingnly mislabelled
w2<-which(LIs$dichotic1.cut=='AtypLat')
w3<-intersect(w1,w2)
atypical2<-LIs$handed3[w3] #this is hardcoded in the text below
```

The planned analysis looking at cases who were atypical on both dichotic listening and chimeric faces was hampered by the fact that the two tasks were not associated (see below), and consequently, there were only four cases in this category. Nevertheless, it was noteworthy that two of these were extreme left-handers and the other two were less extreme left-handers.

### Relationship between LIs from different tasks

Our final question was whether the laterality indices from the language and faces laterality tasks correlated. Specifically, we had predicted that in right-handers the two language tasks would correlate together, but the chimeric faces would form a separate factor. In left-handers, we predicted that the language tasks would fractionate so that none of the three tasks would correlate.

Initial scrutiny of Spearman correlations between LI_z scores suggests weak associations between LI_z values for the two language measures (rhyme decision and dichotic listening), but no association between either of these measures and LI_z on chimeric faces. Note, however, that correlations will be influenced by test reliability; disattenuated correlations (divided by the square root of the product of the reliabilities of the two measures) will be higher (Muchinsky, 1996).

```{r bigcorrmatrix,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}

# create subset of data frame for analysis - I used LI_z measures, as they are on similar scale
interRR <- dplyr::select(LIs, 'zlat_RDT_1', 'zlat_RDT_2', 'Day1_Dich_acc_Z',
                         'Day2_Dich_acc_Z', 'Day1_CF_acc_Z', 'Day2_CF_acc_Z','handedness')
# rename
interRR <- interRR %>% 
  rename(
    "Rhyme_1" = zlat_RDT_1,
    "Chimeric_1" = Day1_CF_acc_Z,
    "Dichotic_1" = Day1_Dich_acc_Z,
     "Rhyme_2" = zlat_RDT_2,
    "Chimeric_2" = Day2_CF_acc_Z,
    "Dichotic_2" = Day2_Dich_acc_Z
    )

#remove cases with missing values
interRR<-na.omit(interRR)
# subset into right and left handers
left_dat <- subset(interRR, handedness== "Left")
right_dat <- subset(interRR, handedness== "Right")
left_dat<-left_dat[,1:6]
right_dat<-right_dat[,1:6]
totcorr<-correlate(interRR[,1:6],method='spearman')
Rcorr <- correlate(right_dat,method='spearman')
Lcorr <- correlate(left_dat,method='spearman')

#Change so we have one matrix with R handers above diagonal and L handers below
Lcorr<-as.data.frame(Lcorr[,2:7])
Rcorr <- as.data.frame(Rcorr[,2:7])
allcorr<-Lcorr
for (i in 1:6){
  for (j in i:6){
    allcorr[i,j]<-Rcorr[i,j]

  }
}
allcorr<- round(allcorr,3)
row.names(allcorr)<-colnames(allcorr)

NL<-nrow(left_dat)
NR<-nrow(right_dat)
#for left_dat N = 66
# right_dat
```


Table 6. Spearman correlations between the LI_z scores for the different tasks in two Sessions. The upper diagonal shows correlations for the `r NR` right-handers (black font), and the values of the lower diagonal show for the `r NL` left-handers (red font).
```{r tab 5, echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
allcorr2 <- cbind(Row.Names = list(rownames(allcorr)), allcorr, stringsAsFactors = FALSE)

# rename columns
names(allcorr2)[1] <- " "
allcorr2$` `[1] <- "RD 1"
allcorr2$` `[2] <- "RD 2"
allcorr2$` `[3] <- "DL 1"
allcorr2$` `[4] <- "DL 2"
allcorr2$` `[5] <- "CF 1"
allcorr2$` `[6] <- "CF 2"

# rename rows
names(allcorr2)[2] <- "RD 1"
names(allcorr2)[3] <- "RD 2"
names(allcorr2)[4] <- "DL 1"
names(allcorr2)[5] <- "DL 2"
names(allcorr2)[6] <- "CF 1"
names(allcorr2)[7] <- "CF 2"

# replace blanks with '.'
#allcorr2$`RD 1`[1] <- "."
#allcorr2$`RD 2`[2] <- "."
#allcorr2$`DL 1`[3] <- "."
#allcorr2$`DL 2`[4] <- "."
#allcorr2$`CF 1`[5] <- "."
#allcorr2$`CF 2`[6] <- "."

myft5<- flextable(allcorr2)
myft5 <- colformat_num(myft5, digits= 3)

myft5<-color(myft5, i = c(2,3,4,5, 6), j = "RD 1", color= "red")
myft5<-color(myft5, i = c(3,4,5, 6), j = "RD 2", color= "red")
myft5<-color(myft5, i = c(4,5, 6), j = "DL 1", color= "red")
myft5<-color(myft5, i = c(5, 6), j = "DL 2", color= "red")
myft5<-color(myft5, i = c(6), j = "CF 1", color= "red")

autofit(myft5, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```
*Note*. For right-handers, an absolute value of .16 is significant at the .05 level, and a value of .22 is significant at the .01 level. For left-handers, a value of .25 is significant at the .05 level and a value of .32 is significant at the .01 level.


In a more formal test, we compared three models: (a) where the two language tasks are correlated with each other but not with the chimeric faces (i.e. a language laterality factor); (b) all LIs are correlated (i.e. a single laterality factor); and (c) a base model where the LIs are unrelated (i.e. independent functions). We departed from our pregistered analysis in two respects on the basis of reviewer recommendations. First we show results for the full sample as well as for separate handedness groups; second we adopt an alternative approach to the Akaike weights analysis that takes measurement error into account by creating factor scores based on the summed scores for the two test sessions.

```{r prepareKievit, echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
library(lavaan)
library(tidyverse)
library(MASS)
library(qpcR)
# created handedness data
# now create subset of data frame for analysis
interRR <- dplyr::select(LIs, split.RDT.1.1, split.RDT.1.2, split.RDT.2.1, split.RDT.2.2,
                              split.DL.1.1, split.DL.1.2, split.DL.2.1, split.DL.2.2,
                              split.chim.1.1, split.chim.1.2, split.chim.2.1, split.chim.2.2, handedness)
# rename, and reverse sign for CF
interRR <- interRR %>% 
  rename(
    "rhyme11" = split.RDT.1.1,
    "faces11" = split.chim.1.1,
    "dichotic11" = split.DL.1.1,
     "rhyme12" = split.RDT.1.2,
    "faces12" = split.chim.1.2,
    "dichotic12" = split.DL.1.2,
      "rhyme21" = split.RDT.2.1,
    "faces21" = split.chim.2.1,
    "dichotic21" = split.DL.2.1,
     "rhyme22" = split.RDT.2.2,
    "faces22" = split.chim.2.2,
    "dichotic22" = split.DL.2.2
    )

#remove cases with missing values
interRR<-na.omit(interRR)
interRR$faces11 <- (-interRR$faces11) 
interRR$faces12 <- (-interRR$faces12)
interRR$faces21 <- (-interRR$faces21) 
interRR$faces22 <- (-interRR$faces22)
# subset into right and left handers
left_dat <- subset(interRR, handedness== "Left")
right_dat <- subset(interRR, handedness== "Right")

```

As shown in Table 7, the Akaike weights favoured model B for both left-handers and right-handers, as well as for both groups combined, confirming that there is association for laterality indices for the two language tasks, but not between language latearlity and laterality for face processing of emotion.  


Table 7. Akaike weights for the language model, independent base model, and laterality model.
```{r disattenuateR, ,echo=FALSE, comment=FALSE, warning=FALSE}
# First check range of scores on all variables for left and right-handers to address point re restriction of range
rangedf <- data.frame(matrix(NA,nrow=3,ncol=4))
colnames(rangedf)<-c('Llower','Lupper','Rlower','Rupper')
rownames(rangedf)<-c('Rhyme','Dichotic','Chimeric')
thisrow<-0
for (myc in c(1,3,5)){
  thisrow<-thisrow+1
  rangedf[thisrow,1:2]<-range(left_dat[myc:(myc+1)])
  rangedf[thisrow,3:4]<-range(right_dat[myc:(myc+1)])
}

#Now for combined handedness group, compute disattenuated correlations
#We already have computed totcorr as symmetric matrix
totcorr<-as.data.frame(totcorr)
r.rhyme<-totcorr[2,2]
r.dich<-totcorr[4,4]
r.chim<-totcorr[6,6]

nutot<-totcorr
for (c in 2:3){ #col 1 is name of task
  for (r in 3:4){
    nutot[r,c]<-totcorr[r,c]/sqrt(r.rhyme*r.dich)
  }
    for (r in 5:6){
    nutot[r,c]<-totcorr[r,c]/sqrt(r.rhyme*r.chim)
  }
}
for (c in 4:5){
  for (r in 5:6){
    nutot[r,c]<-totcorr[r,c]/sqrt(r.dich*r.chim)
  }
}

#nutot shows disattenuated correlations below diagonal
```

```{r newAkaike_factor,echo=FALSE, comment=FALSE, warning=FALSE}
#New version of Akaike test combines 2 test scores for each into a factor to deal with measurement error

#Model 1:all correlated
    model1F<-"
    rhymeFACTOR =~ NA*rhyme11 + rhyme12 + rhyme21 + rhyme 22
    dichoticFACTOR =~ NA*dichotic11 + dichotic12 + dichotic21 + dichotic22
    facesFACTOR =~ NA*faces11 +faces12 + faces21 +faces22
    
    rhymeFACTOR~~1*rhymeFACTOR
    dichoticFACTOR~~1*dichoticFACTOR
    facesFACTOR~~1*facesFACTOR
    
    rhymeFACTOR~~dichoticFACTOR
    rhymeFACTOR~~facesFACTOR
    dichoticFACTOR~~facesFACTOR
    "

#Model 2: language tasks are correlated
    model2F<-"
    rhymeFACTOR =~ NA*rhyme11 + rhyme12 + rhyme21 + rhyme 22
    dichoticFACTOR =~ NA*dichotic11 + dichotic12 + dichotic21 + dichotic22
    facesFACTOR =~ NA*faces11 +faces12 + faces21 +faces22
    
    rhymeFACTOR~~1*rhymeFACTOR
    dichoticFACTOR~~1*dichoticFACTOR
    facesFACTOR~~1*facesFACTOR
    
    rhymeFACTOR~~dichoticFACTOR
    rhymeFACTOR~~0*facesFACTOR
    dichoticFACTOR~~0*facesFACTOR
    "
 #Model 3 all independent
    model3F<-"
    
    rhymeFACTOR =~ NA*rhyme11 + rhyme12 + rhyme21 + rhyme 22
    dichoticFACTOR =~ NA*dichotic11 + dichotic12 + dichotic21 + dichotic22
    facesFACTOR =~ NA*faces11 +faces12 + faces21 +faces22
    
    rhymeFACTOR~~1*rhymeFACTOR
    dichoticFACTOR~~1*dichoticFACTOR
    facesFACTOR~~1*facesFACTOR
    
    rhymeFACTOR~~0*dichoticFACTOR
    rhymeFACTOR~~0*facesFACTOR
    dichoticFACTOR~~0*facesFACTOR
    "
#Make a little dataframe for AIC weights
AICdf <- data.frame(matrix(NA,nrow=3,ncol=4))
AICdf[,1]<-c('Whole sample','Right-handers','Left-handers')
colnames(AICdf)<-c('Handedness','Model 1F','Model 2F','Model 3F')
for (myhand in 1:3) {
  mydat<-interRR
   if(myhand==2) {mydat<-right_dat}
  if(myhand==3) {mydat<-left_dat}

 #Using data from this handedness type, test all 3 models
fit1A <- cfa(model1F, data=mydat,auto.fix.first=FALSE)
fit2A <- cfa(model2F, data=mydat,auto.fix.first=FALSE)
fit3A <- cfa(model3F, data=mydat,auto.fix.first=FALSE)
    aic_vector1 <- c(fitMeasures(fit1A, "aic"),fitMeasures(fit2A, "aic"),fitMeasures(fit3A, "aic"))
   
    #Confirms that for each model, lowest AIC obtained when the simulated data do match the model
    # 
    # The AIC weights make massive difference for preferred model!
    AICweights<-akaike.weights(aic_vector1)$weights
    # 
 AICdf[myhand,2:4]<-round(AICweights,3)
 }
myft6 <- flextable(AICdf, col_keys = c("Handedness",
                                       "Model 1F",
                                       "Model 2F", 
                                       "Model 3F"))
autofit(myft6, add_w = 0.1, add_h = 0.1, part = c("body", "header"))
```


### Exploratory analyses

#### Finger tapping and Edinburgh Handedness Inventory

```{r fingerEHI,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
spearCI <- RVAideMemoire::spearman.ci(LIs$Day1_finger_LI, LIs$index_EHI, nrep = 10000, conf.level = 0.95)
spearCI2 <- RVAideMemoire::spearman.ci(LIs$Day2_finger_LI, LIs$index_EHI, nrep = 10000, conf.level = 0.95)
# spearman's test
speartest <- cor.test(LIs$Day1_finger_LI, LIs$index_EHI, method = "spearman", alternative = "greater")
speartest2 <- cor.test(LIs$Day2_finger_LI, LIs$index_EHI, method = "spearman", alternative = "greater")
```

To examine the relationship between the finger tapping task and a conventional hand preference battery, we computed Spearman's rank correlation between LIs produced on the finger tapping task and the Edinburgh Handedness Inventory. For session 1 data, the relationship between the tasks was moderate, *r* = `r round(speartest$estimate, 2)`, *95% CI* [`r round(spearCI$conf.int[1], 2)`, `r round(spearCI$conf.int[2], 2)`], *p* < 0.001. For session 2, the correlation was *r* = `r round(speartest2$estimate, 2)`, *95% CI* [`r round(spearCI2$conf.int[1], 2)`, `r round(spearCI2$conf.int[2], 2)`], *p* < 0.001. This suggests that the influence of hand preference on the tapping task may increase with practice. 

<!--- Based on reviewer's comments. Haven't added in yet, but holding it here --->

```{r makecontingencies_tasks,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
#We start by using z-scores to make a 3-way categorisation into:
#1 sig bias in typical direction; 2: NS bias 3: in atypical direction with sig bias.
#
LIs$rhyme1.cat <- cut(LIs$zlat_RDT_1, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("R.Right", "R.Bilat", "R.Left"), 
                       right = FALSE)
LIs$dichotic1.cat <- cut(LIs$Day1_Dich_acc_Z, 
                       breaks = c(-Inf, -1.96, 1.96, Inf), 
                       labels = c("D.Right", "D.Bilat", "D.Left"), 
                       right = FALSE)
LIs$chimeric1.cat <- cut(LIs$Day1_CF_acc_Z, 
                       breaks =  c(-Inf, 0, 1.96, Inf), 
                       labels = c("C.Right", "C.Bilat", "C.Right"), 
                       right = FALSE)
mytabr <- table(LIs$rhyme1.cat)
mytabd <- table(LIs$dichotic1.cat)
mytabc <- table(LIs$chimeric1.cat)
mytabc<-mytabc[c(3,2,1)]
mytab2 <-rbind(mytabr,mytabd,mytabc)
row.names(mytab2)<-c('Rhyme decision','Dichotic','Chimeric Faces')
mytab2<-data.frame(mytab2)
mytab2$R.Right[3] <- 0

# rhyme vs dichotic
tab.R.D <- table(LIs$rhyme1.cat,LIs$dichotic1.cat)
tab.R.D
chisq.test(tab.R.D)

# rhyme vs chimeric
tab.R.C <- table(LIs$rhyme1.cat,LIs$chimeric1.cat)
tab.R.C
chisq.test(tab.R.C)

# dichotic vs chimeric
tab.D.C <- table(LIs$dichotic1.cat,LIs$chimeric1.cat)
tab.D.C
```


```{r Table_reviews,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
tabr<-cbind(tabr,round(100*prop.table(tabr,2),1))
tabd<-cbind(tabd,round(100*prop.table(tabd,2),1) )
tabc<-cbind(tabc,round(100*prop.table(tabc,2),1)) #add percentages
blankrow<-c(NA,NA,NA,NA,NA,NA)
latcats <- as.data.frame(rbind(blankrow,tabr,blankrow,tabd,blankrow,tabc))

row.names(latcats) <- c() #remove rownames as they make problems for printing

#Instead have a new column with these
latcats$nucol <- c('Rhyme decision',
                   'Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander',
                   'Dichotic listening',
                   'Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander',
                   'Chimeric faces',
                   'Extreme left-hander',
                   'Moderate left-hander',
                   'Right-hander')

latcats<-latcats[,c(7,3,6,2,5,1,4)] #now reorder columns to make sense
colnames(latcats)<-c(' ','Left N','Left %','Non N','Non %','Right N','Right %')

myft2 <- flextable(
  latcats)
#NB This table needs formatting - has formatted all numbers to 3 decimal places, which is not what we want. Code below achieves this

num_keys <- c("Left %","Non %","Right %")
int_keys <- c("Left N","Non N","Right N")

ft <- colformat_num(x = myft2, col_keys = num_keys, digits = 1)
ft <- colformat_int(x = ft, col_keys = int_keys, big.mark = ",")

#autofit(ft)
```

#### Vocabulary knowledge and laterality

```{r exploreA, echo= FALSE, comment=FALSE, warning=FALSE}
# make sure we have good cases
interR <- LIs_c[LIs_c$exclude == 0,]
DL.lex<-RVAideMemoire::spearman.ci(interR$Day1_Dich_acc_Z, interR$lexTALE, nrep = 10000, conf.level = 0.95)
DL.lex.est<-cor.test(interR$Day1_Dich_acc_Z, interR$lexTALE, method = "spearman")
DL.lex1<-RVAideMemoire::spearman.ci(interR$Day2_Dich_acc_Z, interR$lexTALE, nrep = 10000, conf.level = 0.95)
DL.lex.est1<-cor.test(interR$Day2_Dich_acc_Z, interR$lexTALE, method = "spearman")
```

The LexTALE vocabulary measure had been included largely for data exclusion, but we had planned to explore correlations between LexTALE score and the laterality index on the rhyme decision task. However, as the rhyme task was less reliable than other measures, and showed only small asymmetries, we chose to examine the relationship between the LexTALE and the other verbal laterality measure, dichotic listening, instead. For these exploratory analyses we included participants scoring less than 80 on the LexTALE in order to reduce the effect of a restricted range on the correlational analyses. There was no correlation between the LexTALE score and LIs on the dichotic listening at session 1, *r*= `r round(DL.lex.est$estimate, 2)`, *95% CI*= [`r round(DL.lex$conf.int[1], 2)`, `r round(DL.lex$conf.int[2], 2)`], *p*= `r round(p.adjust(DL.lex.est$p.value[1], n= 2, method= "bonferroni"), 3)`, or session 2, *r*= `r round(DL.lex.est1$estimate, 2)`, *95% CI*= [`r round(DL.lex1$conf.int[1], 2)`, `r round(DL.lex1$conf.int[2], 2)`], *p*= `r round(p.adjust(DL.lex.est1$p.value[1], n= 2, method= "bonferroni"), 3)`.

## Discussion

With the advancement of online behaviour research methods, it has become possible to test large samples of participants outside the laboratory. In the current study, we introduced an online behavioural laterality battery that was administered to a relatively large sample of right- and left-handers. In addition to completing self-report measures of handedness, footedness, and sightedness, participants completed a visual half-field rhyme decision task, a dichotic listening task, a chimeric faces task, and a finger tapping task twice. Thus, we were able to examine the test-retest reliability of each task. We also examined the association between handedness and atypical lateralisation and examined the intercorrelations between LIs on the dichotic listening, rhyme judgement and chimeric faces tasks.

Each behavioural task yielded a hemispheric advantage in the expected direction, but the size of asymmetries and the test-retest reliability of the different tasks varied. A relatively small proportion of individuals showed significant asymmetry on the rhyme decision task, despite the population as a whole being significantly left lateralised. This pattern of results indicates that while very few participants showed statistically better performance for images in the right visual field (i.e. LI_z showed scores above |1.96|), many showed more subtle RVF advantages and had corresponding LI_z scores that were not statistically different from zero at the individual level. When comparing LI_z scores to zero at the population there will have been sufficient power to determine whether these small differences were different from zero.  This task also yielded the poorest test-retest reliability, just falling short of our target minimum cutoff of *r* = .65. Compared to early studies (e.g. Krach et al., 2006) the rhyme decision task used here was more reliable but, compared to other visual half-field tasks, it was far from optimal. Van der Haegen and Brysbaert (2018) have reported that, under lab conditions, visual half-field paradigms can yield test-retest reliabilities of *r* = .77 when using pictures and *r* = .83 when using words. Our study was well-powered, so the relatively poor task validity and reliability are likely to be due to methodological factors. 

One key difference between van der Haegen and Brysbaert’s and our study was that their language-based visual half-field tasks involved overt naming. Speech production is highly lateralised (e.g. Knecht et al., 2000), and requiring speech production should yield a hemispheric advantage. Our task was designed to require covert speech, but an active speech production component might reveal stronger lateralisation. This would, however, be logistically difficult to implement online. The speech requirement may not, however, be a key factor, given that recent studies have reported robust right visual-field advantages on a lexical decision task that does not require active speech production (Brederoo et al., 2020; Hausmann et al., 2019; Willemin et al., 2019).

An alternative explanation for the poor validity and reliability of the rhyme task relates to the control viewing conditions. The visual half-field method depends critically on presenting lateralised visual stimuli that project to one hemisphere. Although we were able to calibrate screen size at the start of the session and to request participants to sit a certain distance from the screen, it is plausible this was not sufficient to achieve adequately lateralised presentation. While we can format images to be consistent across displays, we cannot control participants’ behaviour. Outside of the lab, participants can freely move their head which will influence the size of images on the retina, and it is difficult to ensure that images are shown exclusively in parafoveal vision. If on a subset of images are not equally displaced in parafoveal vision it could mean that processing is more efficient for the image in its corresponding visual field, reducing the validity of the task and adding considerable noise to response time estimates in each visual field. Without stict monitoring of eye-movements here it is not possible to control for this. In future work we plan to explore the use of images presented in peripheral vision, as it is unlikely that small head movements would result in the image shifting from peripheral vision. This would increase difficultly in the processing of information in this region, which may also result in stronger visual field advantages.

In contrast to rhyme decision, the other verbal task, dichotic listening, showed excellent validity and reliability. Participants showed a clear right-ear advantage at the population level, and the task exceeded our pre-registered reliability cut-off of *r*= .65. Indeed, the test-retest correlation of the dichotic listening task, r = .78, was identical to that reported by Bless et al. (2013) using the iDichotic application, and numerically higher than that reported for the same dichotic listening task when run under lab conditions (Bless et al., 2013). We further showed (see Figure 5) that there was little decline in reliability with 85 trials, and with as few as 60 trials, the current implementation of the dichotic listening task yielded a test-retest correlation higher than *r* = .65, suggesting that those who wish to use this paradigm in the future could use a smaller number of trials. It would be of interest to extend this line of work to use the modified version of dichotic listening described by Westerhausen and Samuelsen (2020), which had even higher reliability. Of course, it is important to screen for adequate use of stereo headphones when devising online versions of the task.

Like the dichotic listening task, the chimeric faces task showed impressive levels of both validity and reliability, this time with a strong right hemisphere bias at the population level. The task has previously been shown to have high split-half reliability (Levy et al., 1983), we show that it can meet the higher standard of achieving a high test-retest correlation. Our subsequent analysis showed that acceptable levels of reliability can be achieved with this task using very few trials: reliability did not suffer when only 35 trials were used, and test-retest reliability of *r*= .65 could be found with 25 trials. It seems likely that one reason for the success of the chimeric faces task online is the task’s simplistic nature. From the perspective of the participant, it is a straightforward task of reporting the emotion expressed in a single face and does not require any explicit comparison. The finding that good test-retest reliability could be observed with a reduced number of trials will also be welcome for future studies, where there are constraints on testing time.

We also introduced a novel finger tapping task, which we designed to quantify handedness behaviourally. This produced a right-hand advantage at the population level, and test-retest reliability of the LIs was good. The asymmetries were small in absolute terms, but this in part reflected the high proportion of the left-handers in the sample: our exploratory analysis indicated that LIs from this task correlated reasonably well with the Edinburgh Handedness Inventory (see also Figure 3). Previous studies have reported correlations between hand preference and measures of relative hand skill, but different hand skill measures typically are weakly intercorrelated (Bishop, 1990), and it seems that asymmetries may vary depending on particular aspects of planning and execution of motor coordination that is involved. It would be of interest to see how far LIs resemble that from tasks such as the pegboard task (e.g. Hodgson, Hirst, & Hudson, 2016), which is widely used in neuropsychological assessment. Future work should also examine how other factors such as the complexity of key combinations and reach across the midline influence the task.

In addition to assessing lateralisation of the task using traditional LIs, we also examined the potential to use individual z-scores to quantify lateralisation on each task. This method of calculating LIs is perhaps more useful for those interested in looking at atypical lateralisation, or for cases where there is a need to compare laterality from different tasks on a common scale. Rather than selecting those who fall either side of an arbitrary cut-off, the LI_z score allows researchers to assess whether participants are consistently and statistically lateralised in either a typical or atypical manner. The availability of an online measure means that a researcher who is interested in studying the correlates of atypical language lateralisation could assess participants with our battery to identify those with LI_z scores > 1.96 or < 1.96 before inviting them into the lab for more detailed in-person testing. This has the potential to save time and effort by screening participants to identify a sample that is enriched for rare cases of reversed cerebral lateralisation.

As well as validating the battery and establishing its test-retest reliability, we addressed two theoretically motivated questions related to handedness and atypicality and intercorrelations between the dichotic listening and chimeric faces task. In our pre-registered analysis of handedness, we categorised participants into right-, left-, and extreme left-handers. The data are consistent in showing that extreme left-handers showed increased atypicality on both the dichotic listening and chimeric faces task. Mazoyer et al. (2014) reported a relationship between the strength of lateralisation and hand preference, which was largely driven by the existence of a group with strong left-hand preference and strong right hemisphere dominance for language. They further claimed that this right hemisphere language dominance may be exclusively present in left-handers. Although strong left-handers were over-represented in this category in our data, we did also observe cases of right-handers with right language dominance on the dichotic listening task. This raises the question of whether right language dominance on dichotic listening is equivalent to right language dominance on more direct measures of brain lateralisation, such as fMRI.

A common mechanism that co-determines lateralisation on a range of skills, extending beyond handedness and language, has been a hotly debated topic in the laterality literature. Several researchers have postulated complementary lateralisation for left hemisphere and right hemisphere brain asymmetries, predicting that LIs on verbal and nonverbal tasks should be inversely correlated (Behrmann & Plaut, 2015; Hellige, 1993; Kosslyn, 1987). On this view, a person with atypical right hemisphere language representation should have atypical left hemisphere representation for nonverbal domains such as face processing. However, several studies have reported no such association, or only a weak relationship (Bradzakova-Trajkov et al., 2010; Bryden et al.,1983; Rosch et al., 2012; Whitehouse & Bishop, 2009; van der Haegen & Brysbaert, 2018). Data from the current work supports a view in which laterality on each task is independent. Not only was our study well powered to examine this relationship, our sample included a large number of left-handers who showed increased variability in their LIs. Specifically, we found no association between the LI_z indices for the two language tasks and chimeric faces. There was a weak but measureable association between the two language tasks, rhyme decision and dichotic listening, found in both handedness groups. This is of particular interest given the different  demands of the two tasks - speech perception using dichotic presentation for the dichotic listening task, vs covert naming of a picture and comparison to the phonology of a written word in the rhyme judgement task. The current result suggests there could be interest in replicating this comparison of the two tasks using a visual-half-field language task that has better reliability and validity. The lack of association between dichotic listening and chimeric faces is, however, much more convincing, given that both tasks show strong lateralisation at the population level and high test-retest reliability. This is consistent with the view that, at least for some functions, lateralisation is determined by independent biases: the left-hemisphere population bias for language is unrelated to the right-hemisphere bias for facial expressions of emotion. Given the range of evidence now available, it may be time to abandon hypotheses that predict that different lateralised skills are either wholly interdependent or wholly independent. Evidence such as that from Gerrits et al. (2020) confirms that lateralisation of different functions is associated far more than expected by chance, yet cases of dissociation are not uncommon. Research in future might explore which functions are associated, and to what extent, rather than making a simple contrast between models that postulate a general answer to explain all of laterality.

This conclusion is supported by recent work from Brederoo et al. (2020), who reported data for 122 participants. In their study, participants completed a variety of visual half-field tasks covering a range of domains such as word processing, face processing, and spatial frequency processing. At the population level Brederoo et al. reported lateralisation in the expected direction for the majority of tasks. For left handers and those with right hemisphere dominant speech, there was evidence of a deviation from typical lateralisation. Contrary to the current study, Brederoo et al. reported partial evidence to suggest that processes recruiting similar resources will lateralise to homologue areas to promote intra-hemispheric proximity to other cortical areas within their processing hierarchies. In one analysis they found the lateralisation of faces and word recognition to be correlated but when they looked at lateralisation in those who were right handed versus those with right dominant language processing there was considerably less evidence for causal complementarity. However, Brederoo et al. reported consistent evidence within the visual domain, where lateralisation of low and high frequency information processing was associated, but independent of   lateralisation on other tasks. So it would appear by comparing tasks of a wider variety and considering laterality across domains, we may elucidate the issue of colateralisation and identify how far individual differences in lateralisation depend on task demands and shared processing resources.

To conclude, the present study introduced an online behaviour laterality battery that can be used to examine laterality for speech perception, facial emotion perception, and manual preference with good test-retest reliability. The battery of tasks was administered to a large sample of participants with relative ease and enabled us to examine several questions related to lateralisation. We find evidence of increased atypical lateralisation in extreme left-handers relative to right-handers. However, we find no support for a unitary model of cerebral lateralisation that postulates simple complementarity between left- and right-sided brain lateralisation in individuals. 

\newpage
## Data accessibility

This project was pre-registered on the Open Science Framework (OSF) before the start of data collection. The registration form along with all task materials, analysis scripts and anonymised data can be found on the OSF at https://osf.io/qsxcv/. Working versions of the dichotic listening, chimeric faces, and finger tapping tasks are available on Gorilla Open Materials: https://gorilla.sc/openmaterials/104636.

\newpage
## Competing Interests

We declare we have no competing interests.

\newpage
## Funding 

This study was supported by an Advanced Grant from the European Research Council (694189).

\newpage
## Acknowledgements

First, we would like to thank Mike Burt for providing stimuli for the chimeric faces task and Kenneth Hugdahl for providing stimuli for the dichotic listening task. Second, we would like to thank Marco Hirnstein, Marc Brysbaert, and Sanne Brederoo for their helpful comments on the original manuscript of this paper. Third, we would like to thank Rogier Kievit for his advice regarding the modeling of covariances. Portions of this work were presented at the Online Meeting of the Experimental Psychology Society in July 2020. 

\newpage
## References

Annett, M. (1970). The growth of manual preference and speed. *British Journal of Psychology*, *61*, 545-558. doi: 10.1111/j.2044-8295.1970.tb01274.x  

Annett, M. (1998). Handedness and cerebral dominance: The right shift theory. *Journal of Neuropsychiatry and Clinical Neuroscience*, *10*, 459-469.

Annett, M. (2002). *Handedness and Brain Asymmetry; the right shift theory*. Hove, Sussex; Psychology Press

Anwyl-Irvine, A. L., Massonnié, J., Flitton, A., Kirkham, N., & Evershed, J. K. (2020). Gorilla in our midst: An online behavioral experiment builder. *Behavior Research Methods*, *52*, 388-407.

Badzakova-Trajkov, G., Häberling, I. S., Roberts, R. P., & Corballis, M. C. (2010). Cerebral asymmetries: complementary and independent processes. *PloS One*, *5*, e9682.

Beaton, A. A., & Moseley, L. G. (1984). Anxiety and the measurement of handedness. *British Journal of Psychology*, *75*, 275-278.

Beaumont, J. G. (1982). Studies with verbal stimuli. In J. G. Beaumont (Ed.), *Divided visual field studies of cerebral organisation* (pp. 58–86). London: Academic Press. 

Behrmann, M., & Plaut, D. C. (2015). A vision of graded hemispheric specialization. *Annals of the New York Academy of Sciences*, *1359*, 30-46.

Bethmann, A., Tempelmann, C., De Bleser, R., Scheich, H., & Brechmann, A. (2007). Determining language laterality by fMRI and dichotic listening. *Brain Research*, *1133*, 145-157.

Bishop, D. V. M. (2013). Cerebral asymmetry and language development: cause, correlate, or consequence? *Science*, *340*, 1230531.

Bishop, D. V. (1990). *Handedness and developmental disorder*. Cambridge University Press.

Bishop, D. V. M. (2017) *Which neuroimaging measures are useful for individual differences research? * [Blog post]. Retrieved from: http://deevybee.blogspot.be/2017/05/whichneuroimaging-measures-are-useful.html?m=1

Bless, J. J., Westerhausen, R., Arciuli, J., Kompus, K., Gudmundsen, M., & Hugdahl, K. (2013). “Right on all occasions?”–On the feasibility of laterality research using a smartphone dichotic listening application. *Frontiers in Psychology*, *4*, 42.

Bless, J. J., Westerhausen, R., Torkildsen, J. V. K., Gudmundsen, M., Kompus, K., & Hugdahl, K. (2015). Laterality across languages: Results from a global dichotic listening study using a smartphone application. *Laterality: Asymmetries of Body, Brain and Cognition*, *20*, 434-452.

Boles, D. B. (1987). Reaction time asymmetry through bilateral versus unilateral stimulus presentation. *Brain and Cognition*, *6*, 321–333.

Boles, D. B. (1990). What bilateral displays do. *Brain and Cognition*, *12*, 205– 228.

Boles, D. B. (1994). An experimental comparison of stimulus type, display type and input variable contributions to visual field asymmetry. *Brain and Cognition*, *24*, 184–197. 

Bourne, V. J. (2006). The divided visual field paradigm: Methodological considerations. *Laterality*, *11*, 373–393.

Brederoo, S. G., Nieuwenstein, M. R., Cornelissen, F. W., & Lorist, M. M. (2019). Reproducibility of visual-field asymmetries: Nine replication studies investigating lateralization of visual information processing. *Cortex*, *111*, 100-126.

Brederoo, S. G., Van der Haegen, L., Brysbaert, M., Nieuwenstein, M. R., Cornelissen, F. W., & Lorist, M. M. (2020). Towards a unified understanding of lateralized vision: A large-scale study investigating principles governing patterns of lateralization using a heterogeneous sample. *Cortex*. https://doi.org/10.1016/j.cortex.2020.08.029

Bryden, M. P. (1970). Laterality effects in dichotic listening: relations with handedness and reading ability in children. *Neuropsychologia*, *8*, 443-450.

Bryden, M. P. (1988). An overview of the dichotic listening procedure and its relation to cerebral organization. In K. Hugdahl (Ed.), *Handbook of dichotic listening: Theory, methods and researc*h (p. 1–43). John Wiley & Sons.

Bryden, M. P., Hécaen, H., & DeAgostini, M. (1983). Patterns of cerebral organization. *Brain and Language*, *20*, 249-262.

Burt, D. M., & Perrett, D. I. (1997). Perceptual asymmetries in judgements of facial attractiveness, age, gender, speech and expression. *Neuropsychologia*, *35*, 685-693.

Carey, D. P., & Johnstone, L. T. (2014). Quantifying cerebral asymmetries for language in dextrals and adextrals with random-effects meta analysis. *Frontiers in Psychology*, *5*, 1128.

Dundas, E. M., Plaut, D. C., & Behrmann, M. (2015). Variable left-hemisphere language and orthographic lateralization reduces right-hemisphere face lateralization. *Journal of Cognitive Neuroscience*, *27*, 913-925.

Elias, L. J., Bulman-Fleming, M. B., & McManus, I. C. (1999). Visual temporal asymmetries are related to asymmetries in linguistic perception. *Neuropsychologia*, *37*, 1243-1249.

Geffen, G., Bradshaw, J. L., & Nettleton, N. C. (1972). Hemispheric asymmetry: verbal and spatial encoding of visual stimuli. *Journal of Experimental Psychology*, *95*, 25-31.

Gerrits, R., Verhelst, H., & Vingerhoets, G. (2020). Mirrored brain organization: Statistical anomaly or reversal of hemispheric functional segregation bias? *Proceedings of the National Academy of Sciences*, *117*, 14057-14065.

Gilbert, C., & Bakan, P. (1973). Visual asymmetry in perception of faces. *Neuropsychologia*, *11*, 355-362.

Hausmann, M., Brysbaert, M., van der Haegen, L. J., Specht, K., Hirnstein, M., Willemin, J., . . . Mohr, C. (2019). Language lateralisation measured across linguistic and national boundaries. *Cortex*, *111*, 134-147. doi:10.1016/j.cortex.2018.10.020  

Hellige, J. B. (1993). *Hemispheric asymmetry: what’s right and what’s left*. Perspectives in Cognitive Neuroscience. Cambridge, MA: Harvard Univeristy Press.

Hervé, M. (2020). *RVAideMemoire: Testing and Plotting Procedures for Biostatistics*. R package version 0.9-75.https://CRAN.R-project.org/package=RVAideMemoire

Hoaglin, D. C., & Iglewicz, B. (1987). Fine-tuning some resistant rules for outlier labeling. *Journal of the American Statistical Association*, *8*, 1147-1149.

Hodgson, J. C., Hirst, R. J., & Hudson, J. M. (2016). Hemispheric speech lateralisation in the developing brain is related to motor praxis ability. *Developmental Cognitive Neuroscience*, *22*, 9-17.

Hodgson, J. C., & Hudson, J. M. (2018). Speech lateralization and motor control. In G. S. Forrester, W. D. Hopkins, K. Hudry, & A. Lindell (Eds). *Progress in Brain Research* (pp. 145-178). Elsevier.

Hugdahl, K. (2000). Lateralization of cognitive processes in the brain. *Acta Psychologica*, *105*, 211-235.

Hugdahl, K. (2003). Dichotic listening in the study of auditory laterality. In K. Hugdahl and R. J. Davidson (Eds.), *The asymmetrical brain* (pp. 441–476). Cambridge, MA: MIT Press.

Hugdahl, K., Westerhausen, R., Alho, K., Medvedev, S., Laine, M., & Hämäläinen, H. (2009). Attention and cognitive control: unfolding the dichotic listening story. *Scandinavian Journal of Psychology*, *50*, 11-22.

Hunter, Z. R., & Brysbaert, M. (2008). Visual half-field experiments are a good measure of cerebral language dominance if used properly: Evidence from fMRI. *Neuropsychologia*, *46*, 316–325.

Iacoboni, M., & Zaidel, E. (1996). Hemispheric independence in word recognition: Evidence from unilateral and bilateral presentations. *Brain and Language*, *53*, 121–140.

Innes, B. R., Burt, D. M., Birch, Y. K., & Hausmann, M. (2016). A leftward bias however you look at it: Revisiting the emotional chimeric face task as a tool for measuring emotion lateralization. *Laterality: Asymmetries of Body, Brain and Cognition*, *21*, 643-661.

Karlsson, E. M., Johnstone, L. T., & Carey, D. P. (2019). The depth and breadth of multiple perceptual asymmetries in right handers and non-right handers. *Laterality: Asymmetries of Body, Brain and Cognition*, *24*, 707-739.

Kelley KS, Littenberg B. (2019). Dichotic Listening Test–retest reliability in children. *Journal of Speech, Language, and Hearing Research*, *62*, 169-76.

Kimura, D. (1967). Functional asymmetry of the brain in dichotic listening. *Cortex*, *3*, 163-178.

Kosslyn, S. M. (1987). Seeing and imagining in the cerebral hemispheres: a computational approach. *Psychological Review*, *94*, 148.

Knecht, S., Dräger, B., Deppe, M., Bobe, L., Lohmann, H., Flöel, A., Ringelstein, E. B., & Henningsen, H. (2000). Handedness and hemispheric language dominance in healthy humans. *Brain*, *123*, 2512-2518.

Krach, S., Chen, L. M., & Hartje, W. (2006). Comparison between visual halffield performance and cerebral blood flow changes as indicators of language dominance. *Laterality*, *11*, 122-140.

Lemhöfer, K., & Broersma, M. (2012). Introducing LexTALE: A quick and valid lexical test for advanced learners of English. *Behavior Research Methods*, *44*, 325-343.

Levy, J., Heller, W., Banich, M. T., & Burton, L. A. (1983). Asymmetry of perception in free viewing of chimeric faces. *Brain and Cognition*, *2*, 404-419.

Mazoyer, B., Zago, L., Jobard, G., Crivello, F., Joliot, M., Perchey, G., ... & Tzourio-Mazoyer, N. (2014). Gaussian mixture modeling of hemispheric lateralization for language in a large sample of healthy individuals balanced for handedness. *PloS one*, *9*, e101165.

Miles, W. R. (1929). Ocular dominance demonstrated by unconscious sighting. *Journal of Experimental Psychology*, *12*, 113.

Mishkin, M., & Forgays, D. G. (1952). Word recognition as a function of retinal locus. *Journal of Experimental Psychology*, *43*, 43.

Muchinsky, P. (1996). The correction for attenuation. *Educational and Psychological Measurement*, *56*(1), 63-75. doi:https://doi.org/10.1177/0013164496056001004

Ocklenburg, S., & Güntürkün, O. (2018). *The lateralized brain: The neuroscience and evolution of hemispheric asymmetries*. London: Academic Press. 

Oldfield, R. C. (1971). The assessment and analysis of handedness: the Edinburgh inventory. *Neuropsychologia*, *9*, 97-113.  

Parsons, S., Kruijt, A., & Fox, E. (2019). Psychological science needs a standard practice of reporting the reliability of cognitive-behavioral measurements. *Advances in Methods and Practices in Psychological Science*. doi:10.1177/2515245919879695  

Porac, C., & Coren, S. (1976). The dominant eye. *Psychological Bulletin*, *83*, 880.

Rosch, R. E., Bishop, D. V., & Badcock, N. A. (2012). Lateralised visual attention is unrelated to language lateralisation, and not influenced by task difficulty–a functional transcranial Doppler study. *Neuropsychologia*, *50*, 810-815.

Roszkowski, M. J., & Snelbecker, G. E. (1982). Temporal stability and predictive validity of self-assessed hand preference with first and second graders. *Brain and Cognition*, *1*, 405-409.

Steenhuis, R. E., & Bryden, M. P. (1999). The relation between hand preference and hand performance: What you get depends on what you measure. *Laterality: Asymmetries of Body, Brain and Cognition*, *4*, 3-26.

Tiffin, J., & Asher, E., (1948). The Purdue pegboard; norms and studies of reliability and validity. *Journal of Applied Psychology*, *32*, 234-47.

Van der Haegen, L., & Brysbaert, M. (2018). The relationship between behavioral language laterality, face laterality and language performance in left-handers. *PloS one*, *13*, e0208696.

Van der Haegen, L., Cai, Q., Seurinck, R., & Brysbaert, M. (2011). Further fMRI validation of the visual half field technique as an indicator of language laterality: A large-group analysis. *Neuropsychologia*, *49*, 2879-2888.

Van Heuven, W. J., Mandera, P., Keuleers, E., & Brysbaert, M. (2014). SUBTLEX-UK: A new and improved word frequency database for British English. *Quarterly Journal of Experimental Psychology*, *67*, 1176-1190.

Voyer, D. (1998). On the reliability and validity of noninvasive laterality measures. *Brain & Cognition*, *36* , 209-36. 

Weekes, N. Y., Capetillo-Cunliffe, L., Rayman, J., Iacoboni, M., & Zaidel, E. (1996). Individual differences in the hemispheric specialization of dual route variables. *Brain and Language*, *67*, 110-133.

Westerhausen, R. (2019). A primer on dichotic listening as a paradigm for the assessment of hemispheric asymmetry. *Laterality: Asymmetries of Body, Brain and Cognition*, *24*, 740-771.

Westerhausen, R., & Samuelsen, F. (2020, January 31). An optimal dichotic-listening paradigm for the assessment of hemispheric dominance for speech processing. https://doi.org/10.31234/osf.io/tpjes

Whitehouse, A. J., & Bishop, D. V. (2009). Hemispheric division of function is the result of independent probabilistic biases. *Neuropsychologia*, *47*, 1938-1943.

Willemin, J., Hausmann, M., Brysbaert, M., Dael, N., Chmetz, F., Fioravera, A., Gieruc, K., & Mohr, C. (2016). Stability of right visual field advantage in an international lateralized lexical decision task irrespective of participants’ sex, handedness or bilingualism. *Laterality: Asymmetries of Body, Brain and Cognition*, *21*, 502-524.

Wagenmakers, E. J., & Farrell, S. (2004). AIC model selection using Akaike weights. *Psychonomic Bulletin & Review*, *11*, 192-196.

Woodhead Z. V. J., Bradshaw A. R., Wilson A. C., Thompson P. A. & Bishop D. V. M. (2019). Testing the unitary theory of language lateralization using functional transcranial Doppler sonography in adults. *Royal Society Open Science*, *6*, 181801.

Woodhead, Z. V. J., Thompson, P. A., Karlsson, E., & Bishop, D. V. M. (2020, September 9). Investigating multidimensionality of language lateralisation in left and right handed adults: an update on Woodhead et al. 2019. https://doi.org/10.31234/osf.io/mrkgf

Woods, K. J., Siegel, M. H., Traer, J., & McDermott, J. H. (2017). Headphone screening to facilitate web-based auditory experiments. *Attention, Perception, & Psychophysics*, *79*, 2064-2072.

Yovel, G., Tambini, A., & Brandman, T. (2008). The asymmetry of the fusiform face area is a stable individual characteristic that underlies the left-visual-field superiority for faces. *Neuropsychologia*, *46*, 3061-3068.

<!--- FOOTNOTESS --->
[^1]: Hugdahl et al. (2009) recommend excluding participants with a general hearing impairment of more than 20 dB for all frequencies tested, and/or an interaural hearing threshold difference of more than 10 dB as this can influence dichotic listening outcomes. It is important to note that this exclusion was not possible in the current study as we did not include a hearing test. With the current sample size, subtle hearing deficits in one ear will unlikely undermine the results. However, it will be important for future studies to incorporate hearing accuracy tests in order to exclude participants with these hearing related difficulties.


```{r dist_plots,echo=FALSE,include=FALSE, comment=FALSE, warning=FALSE}
# rename
RD.dat$handed3 <- as.factor(RD.dat$handed3)
  levels(RD.dat$handed3) <- c("Extreme LH", 'Moderate LH', "RH")
CF.dat$handed3 <- as.factor(CF.dat$handed3)
  levels(CF.dat$handed3) <- c("Extreme LH", 'Moderate LH', "RH")
DL.dat$handed3 <- as.factor(DL.dat$handed3)
  levels(DL.dat$handed3) <- c("Extreme LH", 'Moderate LH', "RH")
FT.dat$handed3 <- as.factor(FT.dat$handed3)
  levels(FT.dat$handed3) <- c("Extreme LH", 'Moderate LH', "RH")
# plot all
plota <- ggplot(RD.dat, aes(x=tlat_RDT_1, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Rhyme decision LI_z (session 1)') +
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-5,5) + ylim(0, 65)
plotb <- ggplot(RD.dat, aes(x=tlat_RDT_2, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Rhyme decision LI_z (session 2)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-5,5) + ylim(0, 65)
plotc <- ggplot(DL.dat, aes(x=Day1_Dich_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Dichotic listening LI_z (session 1)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-20,20) + ylim(0, 65)
plotd <- ggplot(DL.dat, aes(x=Day2_Dich_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Dichotic listening LI_z (session 2)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-20,20) + ylim(0, 65)
plote <- ggplot(CF.dat, aes(x=Day1_CF_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Chimeric faces LI_z (session 1)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-20,20) + ylim(0, 65)
plotf <- ggplot(CF.dat, aes(x=Day2_CF_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Chimeric faces LI_z (session 2)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-20,20) + ylim(0, 65)
plotg <- ggplot(FT.dat, aes(x=Day1_Finger_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Finger tapping LI_z (session 1)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-5,5) + ylim(0, 65)
ploth <- ggplot(FT.dat, aes(x=Day2_Finger_acc_Z, fill=handed3, color=handed3)) +
  geom_histogram(position="identity", alpha= .35) + theme_bw(20) +
  xlab('Finger tapping LI_z (session 2)') + 
  theme(legend.position = "top", legend.title = element_blank()) + xlim(-5,5) + ylim(0, 65)
# plot together
all.plots <- ggpubr::ggarrange(plota, plotb, plotc, plotd, plote, plotf, plotg, ploth, ncol = 2, nrow= 4)
ggsave("./plots/dist.plots.png", plot=all.plots,dpi = 300, width = 12, height = 24,)
```

\newpage

**Assessing the reliability of an online behavioural laterality battery: A pre-registered study.**

**Parker, A. J., Woodhead, Z. V. J., Thompson, P. A., Bishop, D. V. M.**

**Supplementary Materials**

In these Supplementary Materials we include the distribution of laterality indices for each behavioural laterality task across both testing sessions. We also include a series of t-tests examining the difference in LI_z scores between extreme left-handers and right-handers.

**LI_z distributions**

The distributions of LI_z scores are shown in Figure S1.

![Figure S1. Distribution of laterality indices on the behavioural tasks. The distributions of LI_z are show in pink for extreme left-handers, green for moderate left-handers, and blue for right-handers. Negative values indicates left lateralisation at the brain level and positive values indicate left lateralisation at the brain level.](./plots/dist.plots.png){width=60%}

**LI_z scores in extreme left-handers and right-handers**
```{r hand.corrs,echo=FALSE,include=TRUE, comment=FALSE, warning=FALSE}
comp_c <- ggplot(subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"),
  aes(x= handed3, y= Day1_CF_acc_Z, fill= handed3)) +
  geom_hline(yintercept=0) + 
  geom_hline(yintercept=1.96, linetype= "dashed", color= "red") +
  geom_hline(yintercept=-1.96, linetype= "dashed", color= "red") +
  geom_violin(alpha= .1, size= .5) +
  geom_jitter(width= .1, aes(color= handed3), alpha= .25) +
  geom_boxplot(width=0.1, position=position_dodge(0.9), size= .5 , notch = T, notchwidth = 0.4, varwidth =F,
               color= 'black', show.legend=FALSE, linetype= 'solid', outlier.color = NA) +
  ylab("Chimeric faces LI_z") + 
  xlab(" ") +
  ggtitle("(C)") + theme(plot.title = element_text(hjust = 0.5)) +
  ylim(-20, 20) +
  theme_bw(18) +
  theme(legend.position= "none") + theme(plot.title = element_text(hjust = 0.5))
comp_b <- ggplot(subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"),
  aes(x= handed3, y= Day1_Dich_acc_Z, fill= handed3)) +
  geom_hline(yintercept=0) + 
  geom_hline(yintercept=1.96, linetype= "dashed", color= "red") +
  geom_hline(yintercept=-1.96, linetype= "dashed", color= "red") +
  geom_violin(alpha= .1, size= .5) +
  geom_jitter(width= .1, aes(color= handed3), alpha= .25) +
  geom_boxplot(width=0.1, position=position_dodge(0.9), size= .5 , notch = T, notchwidth = 0.4, varwidth =F,
               color= 'black', show.legend=FALSE, linetype= 'solid', outlier.color = NA) +
  ylab("Dichotic listening LI_z") +
  xlab(" ") +
  ggtitle("(B)") + theme(plot.title = element_text(hjust = 0.5)) +
  ylim(-20, 20) +
  theme_bw(18) +
  theme(legend.position= "none") + theme(plot.title = element_text(hjust = 0.5))
comp_a <- ggplot(subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"),
  aes(x= handed3, y= tlat_RDT_1, fill= handed3)) +
  geom_hline(yintercept=0) + 
  geom_hline(yintercept=1.96, linetype= "dashed", color= "red") +
  geom_hline(yintercept=-1.96, linetype= "dashed", color= "red") +
  geom_violin(alpha= .1, size= .5) +
  geom_jitter(width= .1, aes(color= handed3), alpha= .25) +
  geom_boxplot(width=0.1, position=position_dodge(0.9), size= .5 , notch = T, notchwidth = 0.4, varwidth =F,
               color= 'black', show.legend=FALSE, linetype= 'solid', outlier.color = NA) +
  ylab("Rhyme decision LI_z") +
  xlab(" ") +
  ggtitle("(A)") + 
  ylim(-20, 20) +
  theme_bw(18) +
  theme(legend.position= "none") + theme(plot.title = element_text(hjust = 0.5))
t.plots <- ggpubr::ggarrange(comp_a, comp_b, comp_c, ncol = 1, nrow= 3)
ggsave("./plots/t.plots.png", plot=t.plots,dpi = 300, width = 5, height = 15,)
# tests
t1 <- wilcox.test(data= subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"), tlat_RDT_1~ handed3, alternate= "less",conf.int = TRUE, conf.level = 0.95)
t2 <- wilcox.test(data= subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"), Day1_DL_acc_LI~ handed3, alternate= "less",conf.int = TRUE, conf.level = 0.95)
t3 <- wilcox.test(data= subset(LIs, handed3== "Right-hander" | handed3=="Extreme left-hander"), Day1_CF_acc_Z~ handed3, alternate= "greater",conf.int = TRUE, conf.level = 0.95)
```

To further examine the link between handedness and atypical laterality, we conducted a series of one-tailed Mann-Whitney *U*-tests using session 1 data. The distribution of LI_z scores are shown separately in Figure S2. The Mann-Whitney test for the rhyme decision task indicated that LI_z scores did not differ between extreme left-handers and right-handers, *U*= `r round(t1$statistic, 2)`, *95% CI*= [`r round(t1$conf.int[1], 2)`, `r round(t1$conf.int[2], 2)`], *p*= `r round(t1$p.value, 3)`. This is not surprising given that very few participants were lateralised on this task. While LI_z scores did not differ between extreme left-handers and right-handers on the rhyme decision, they did on the dichotic listening, *U*= `r round(t2$statistic, 2)`, *95% CI*= [`r round(t2$conf.int[1], 2)`, `r round(t2$conf.int[2], 2)`], *p*= `r round(t2$p.value, 3)`, and chimeric faces, *U*= `r round(t3$statistic, 2)`, *95% CI*= [`r round(t3$conf.int[1], 2)`, `r round(t3$conf.int[2], 2)`], *p*= `r round(t3$p.value, 3)`, tasks. These differences demonstrate that, as a population, extreme left-handers were less lateralised.

![Figure S2. Violin plots showing the distribution of laterality indices on the behavioural tasks for extreme left-handers (in pink) and right-handers (in blue). The notch on the boxplot indicates the mean per condition. The red dashed lines are drawn at -1.96 and 1.96, indicating significant lateralisation to either the left or right hemisphere. Data points represent indiciaul participants' data.](./plots/t.plots.png){width=40%}